{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.13.0\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('./../')\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "# Helper libraries\n",
    "from tensorflow import keras\n",
    "from keras import mixed_precision\n",
    "import numpy as np\n",
    "import time\n",
    "import maxine\n",
    "import sys\n",
    "from maxine.layers import SoftMaxMin_Pruned_v02\n",
    "import keras.backend as k\n",
    "import pruning_tool_v2\n",
    "from maxine.tools import pruning_tool_MLP_v3\n",
    "from maxine.tools import pruning_tool_MLP_v4_1\n",
    "from maxine.tools import pruning_tool_MLP_v4_2\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping\n",
    "from scipy.io import loadmat\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD DATA\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "# rows, cols = 28, 28\n",
    "# x_train = x_train.reshape(x_train.shape[0], rows, cols, 1)\n",
    "# x_test = x_test.reshape(x_test.shape[0], rows, cols, 1)\n",
    "# input_shape = (rows, cols, 1)\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# convert to float and normalize\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# val_labels = y_train[-5000:]\n",
    "# train_labels = y_train[:-5000]\n",
    "# test_labels = y_test\n",
    "\n",
    "# one-hot encode the labels\n",
    "# y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "# y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "# Validation data\n",
    "x_val = x_train[-5000:]\n",
    "y_val = y_train[-5000:]\n",
    "\n",
    "x_train = x_train[:-5000]\n",
    "y_train = y_train[:-5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 13:10:20.533748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2031] Ignoring visible gpu device (device: 2, name: NVIDIA GeForce GT 1030, pci bus id: 0000:84:00.0, compute capability: 6.1) with core count: 3. The minimum required count is 8. You can adjust this requirement with the env var TF_MIN_GPU_MULTIPROCESSOR_COUNT.\n",
      "2023-12-29 13:10:21.886869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 23664 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:03:00.0, compute capability: 6.1\n",
      "2023-12-29 13:10:21.887477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 23664 MB memory:  -> device: 1, name: Tesla P40, pci bus id: 0000:04:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "baselineModel = tf.keras.models.load_model('../models/paper/MLP_MNIST_300_100_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 300)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baselineModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential',\n",
       " 'layers': [{'module': 'keras.layers',\n",
       "   'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 784),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'dense_input'},\n",
       "   'registered_name': None},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'dense',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 300,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': {'module': 'keras.regularizers',\n",
       "     'class_name': 'L2',\n",
       "     'config': {'l2': 9.999999747378752e-05},\n",
       "     'registered_name': None},\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 784)}},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'modelLayer_1_0',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 100,\n",
       "    'activation': 'relu',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': {'module': 'keras.regularizers',\n",
       "     'class_name': 'L2',\n",
       "     'config': {'l2': 9.999999747378752e-05},\n",
       "     'registered_name': None},\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 300)}},\n",
       "  {'module': 'keras.layers',\n",
       "   'class_name': 'Dense',\n",
       "   'config': {'name': 'modelLayer_2_1',\n",
       "    'trainable': True,\n",
       "    'dtype': 'float32',\n",
       "    'units': 10,\n",
       "    'activation': 'softmax',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None},\n",
       "     'registered_name': None},\n",
       "    'bias_initializer': {'module': 'keras.initializers',\n",
       "     'class_name': 'Zeros',\n",
       "     'config': {},\n",
       "     'registered_name': None},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None},\n",
       "   'registered_name': None,\n",
       "   'build_config': {'input_shape': (None, 100)}}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselineModel.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0628 - accuracy: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06277354061603546, 0.9818999767303467]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselineModel.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training morphological model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min (SoftMaxMin)   (55000, 300)              235200    \n",
      "                                                                 \n",
      " dense (Dense)               (55000, 10)               3000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238200 (930.47 KB)\n",
      "Trainable params: 238200 (930.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 13:13:45.188424: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x224a97b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-29 13:13:45.188514: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P40, Compute Capability 6.1\n",
      "2023-12-29 13:13:45.188531: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla P40, Compute Capability 6.1\n",
      "2023-12-29 13:13:45.204719: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-29 13:13:45.404831: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2023-12-29 13:13:45.524259: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-29 13:13:45.724797: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 - 11s - loss: 0.8458 - accuracy: 0.7674 - val_loss: 0.2657 - val_accuracy: 0.9310 - 11s/epoch - 7ms/step\n",
      "Epoch 2/30\n",
      "1719/1719 - 8s - loss: 0.2866 - accuracy: 0.9177 - val_loss: 0.1939 - val_accuracy: 0.9464 - 8s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1719/1719 - 8s - loss: 0.2211 - accuracy: 0.9376 - val_loss: 0.1664 - val_accuracy: 0.9540 - 8s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1719/1719 - 8s - loss: 0.1856 - accuracy: 0.9466 - val_loss: 0.1476 - val_accuracy: 0.9578 - 8s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1719/1719 - 8s - loss: 0.1623 - accuracy: 0.9525 - val_loss: 0.1243 - val_accuracy: 0.9670 - 8s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1719/1719 - 8s - loss: 0.1444 - accuracy: 0.9585 - val_loss: 0.1124 - val_accuracy: 0.9698 - 8s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1719/1719 - 8s - loss: 0.1317 - accuracy: 0.9621 - val_loss: 0.1155 - val_accuracy: 0.9656 - 8s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1719/1719 - 8s - loss: 0.1207 - accuracy: 0.9651 - val_loss: 0.1097 - val_accuracy: 0.9706 - 8s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1719/1719 - 8s - loss: 0.1107 - accuracy: 0.9685 - val_loss: 0.0948 - val_accuracy: 0.9752 - 8s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1719/1719 - 8s - loss: 0.1038 - accuracy: 0.9702 - val_loss: 0.1005 - val_accuracy: 0.9732 - 8s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1719/1719 - 8s - loss: 0.0976 - accuracy: 0.9723 - val_loss: 0.0904 - val_accuracy: 0.9756 - 8s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1719/1719 - 8s - loss: 0.0908 - accuracy: 0.9743 - val_loss: 0.0856 - val_accuracy: 0.9776 - 8s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1719/1719 - 8s - loss: 0.0863 - accuracy: 0.9755 - val_loss: 0.0799 - val_accuracy: 0.9802 - 8s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1719/1719 - 8s - loss: 0.0819 - accuracy: 0.9766 - val_loss: 0.0818 - val_accuracy: 0.9786 - 8s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1719/1719 - 8s - loss: 0.0777 - accuracy: 0.9778 - val_loss: 0.0837 - val_accuracy: 0.9776 - 8s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1719/1719 - 8s - loss: 0.0735 - accuracy: 0.9794 - val_loss: 0.0782 - val_accuracy: 0.9768 - 8s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "1719/1719 - 8s - loss: 0.0698 - accuracy: 0.9805 - val_loss: 0.0754 - val_accuracy: 0.9778 - 8s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1719/1719 - 8s - loss: 0.0665 - accuracy: 0.9817 - val_loss: 0.0713 - val_accuracy: 0.9800 - 8s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1719/1719 - 8s - loss: 0.0642 - accuracy: 0.9816 - val_loss: 0.0692 - val_accuracy: 0.9818 - 8s/epoch - 5ms/step\n",
      "Epoch 20/30\n",
      "1719/1719 - 8s - loss: 0.0616 - accuracy: 0.9833 - val_loss: 0.0780 - val_accuracy: 0.9784 - 8s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1719/1719 - 8s - loss: 0.0589 - accuracy: 0.9835 - val_loss: 0.0727 - val_accuracy: 0.9812 - 8s/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "1719/1719 - 8s - loss: 0.0563 - accuracy: 0.9849 - val_loss: 0.0754 - val_accuracy: 0.9800 - 8s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1719/1719 - 7s - loss: 0.0543 - accuracy: 0.9854 - val_loss: 0.0673 - val_accuracy: 0.9820 - 7s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1719/1719 - 7s - loss: 0.0525 - accuracy: 0.9854 - val_loss: 0.0738 - val_accuracy: 0.9786 - 7s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1719/1719 - 7s - loss: 0.0502 - accuracy: 0.9861 - val_loss: 0.0747 - val_accuracy: 0.9796 - 7s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1719/1719 - 7s - loss: 0.0486 - accuracy: 0.9869 - val_loss: 0.0777 - val_accuracy: 0.9790 - 7s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1719/1719 - 7s - loss: 0.0468 - accuracy: 0.9873 - val_loss: 0.0691 - val_accuracy: 0.9826 - 7s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1719/1719 - 7s - loss: 0.0452 - accuracy: 0.9877 - val_loss: 0.0679 - val_accuracy: 0.9802 - 7s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "1719/1719 - 8s - loss: 0.0440 - accuracy: 0.9882 - val_loss: 0.0691 - val_accuracy: 0.9814 - 8s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "1719/1719 - 8s - loss: 0.0423 - accuracy: 0.9883 - val_loss: 0.0705 - val_accuracy: 0.9800 - 8s/epoch - 4ms/step\n",
      "Pruning morphological model...\n",
      "\n",
      "Baseline test accuracy: \n",
      "20/20 [==============================] - 1s 24ms/step - loss: 0.0835 - accuracy: 0.9742\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 238200\n",
      "Weights that can be pruned: 221766\n",
      "Left parameters: 16434\n",
      "Unactive neurons: 0\n",
      "Parameter reduction of the model: 93%\n",
      "Parameter reduction of the morph layers: 94%\n",
      "\n",
      "Hard pruned model. Test acuraccy\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.9743\n",
      "Retraining MLP dense model...\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-29 13:19:18.292953: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. sequential/modelLayer_1_0/dropout/random_uniform/RandomUniform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 5s 28ms/step - loss: 0.6336 - accuracy: 0.8093 - val_loss: 0.2207 - val_accuracy: 0.9388\n",
      "Epoch 2/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2724 - accuracy: 0.9175 - val_loss: 0.1641 - val_accuracy: 0.9514\n",
      "Epoch 3/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2149 - accuracy: 0.9346 - val_loss: 0.1354 - val_accuracy: 0.9600\n",
      "Epoch 4/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1792 - accuracy: 0.9460 - val_loss: 0.1210 - val_accuracy: 0.9646\n",
      "Epoch 5/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1573 - accuracy: 0.9516 - val_loss: 0.1069 - val_accuracy: 0.9686\n",
      "Epoch 6/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1397 - accuracy: 0.9567 - val_loss: 0.0997 - val_accuracy: 0.9702\n",
      "Epoch 7/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1267 - accuracy: 0.9605 - val_loss: 0.0943 - val_accuracy: 0.9726\n",
      "Epoch 8/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1165 - accuracy: 0.9644 - val_loss: 0.0885 - val_accuracy: 0.9726\n",
      "Epoch 9/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1070 - accuracy: 0.9667 - val_loss: 0.0845 - val_accuracy: 0.9750\n",
      "Epoch 10/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9690 - val_loss: 0.0825 - val_accuracy: 0.9756\n",
      "Epoch 11/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0944 - accuracy: 0.9709 - val_loss: 0.0783 - val_accuracy: 0.9768\n",
      "Epoch 12/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0901 - accuracy: 0.9720 - val_loss: 0.0780 - val_accuracy: 0.9758\n",
      "Epoch 13/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0845 - accuracy: 0.9729 - val_loss: 0.0746 - val_accuracy: 0.9774\n",
      "Epoch 14/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0803 - accuracy: 0.9750 - val_loss: 0.0719 - val_accuracy: 0.9784\n",
      "Epoch 15/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0753 - accuracy: 0.9767 - val_loss: 0.0690 - val_accuracy: 0.9790\n",
      "Epoch 16/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.9775 - val_loss: 0.0706 - val_accuracy: 0.9782\n",
      "Epoch 17/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0695 - accuracy: 0.9780 - val_loss: 0.0681 - val_accuracy: 0.9818\n",
      "Epoch 18/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9787 - val_loss: 0.0675 - val_accuracy: 0.9812\n",
      "Epoch 19/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9798 - val_loss: 0.0648 - val_accuracy: 0.9812\n",
      "Epoch 20/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0582 - accuracy: 0.9809 - val_loss: 0.0647 - val_accuracy: 0.9818\n",
      "Epoch 21/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9816 - val_loss: 0.0639 - val_accuracy: 0.9812\n",
      "Epoch 22/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0558 - accuracy: 0.9828 - val_loss: 0.0635 - val_accuracy: 0.9824\n",
      "Epoch 23/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 0.9829 - val_loss: 0.0640 - val_accuracy: 0.9816\n",
      "Epoch 24/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9832 - val_loss: 0.0634 - val_accuracy: 0.9816\n",
      "Epoch 25/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9839 - val_loss: 0.0636 - val_accuracy: 0.9824\n",
      "Epoch 26/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9849 - val_loss: 0.0633 - val_accuracy: 0.9828\n",
      "Epoch 27/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0455 - accuracy: 0.9854 - val_loss: 0.0618 - val_accuracy: 0.9836\n",
      "Epoch 28/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9855 - val_loss: 0.0629 - val_accuracy: 0.9818\n",
      "Epoch 29/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0441 - accuracy: 0.9861 - val_loss: 0.0634 - val_accuracy: 0.9820\n",
      "Epoch 30/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0410 - accuracy: 0.9868 - val_loss: 0.0615 - val_accuracy: 0.9826\n",
      "Epoch 31/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9877 - val_loss: 0.0631 - val_accuracy: 0.9828\n",
      "Epoch 32/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9880 - val_loss: 0.0626 - val_accuracy: 0.9836\n",
      "Epoch 33/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0377 - accuracy: 0.9877 - val_loss: 0.0618 - val_accuracy: 0.9836\n",
      "Epoch 34/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0355 - accuracy: 0.9884 - val_loss: 0.0622 - val_accuracy: 0.9834\n",
      "Epoch 35/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0350 - accuracy: 0.9885 - val_loss: 0.0630 - val_accuracy: 0.9832\n",
      "Epoch 36/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0338 - accuracy: 0.9892 - val_loss: 0.0611 - val_accuracy: 0.9832\n",
      "Epoch 37/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0323 - accuracy: 0.9893 - val_loss: 0.0604 - val_accuracy: 0.9842\n",
      "Epoch 38/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0306 - accuracy: 0.9901 - val_loss: 0.0648 - val_accuracy: 0.9822\n",
      "Epoch 39/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9898 - val_loss: 0.0621 - val_accuracy: 0.9832\n",
      "Epoch 40/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0298 - accuracy: 0.9904 - val_loss: 0.0621 - val_accuracy: 0.9838\n",
      "Training morphological model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min (SoftMaxMin)   (55000, 100)              30000     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (55000, 10)               1000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31000 (121.09 KB)\n",
      "Trainable params: 31000 (121.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1719/1719 - 11s - loss: 1.1308 - accuracy: 0.7249 - val_loss: 0.5260 - val_accuracy: 0.8964 - 11s/epoch - 6ms/step\n",
      "Epoch 2/30\n",
      "1719/1719 - 7s - loss: 0.4778 - accuracy: 0.8907 - val_loss: 0.3406 - val_accuracy: 0.9284 - 7s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1719/1719 - 7s - loss: 0.3509 - accuracy: 0.9168 - val_loss: 0.2683 - val_accuracy: 0.9370 - 7s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1719/1719 - 7s - loss: 0.2894 - accuracy: 0.9293 - val_loss: 0.2299 - val_accuracy: 0.9442 - 7s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1719/1719 - 7s - loss: 0.2530 - accuracy: 0.9363 - val_loss: 0.2051 - val_accuracy: 0.9506 - 7s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1719/1719 - 7s - loss: 0.2279 - accuracy: 0.9412 - val_loss: 0.1882 - val_accuracy: 0.9486 - 7s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1719/1719 - 7s - loss: 0.2091 - accuracy: 0.9463 - val_loss: 0.1744 - val_accuracy: 0.9554 - 7s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1719/1719 - 7s - loss: 0.1944 - accuracy: 0.9495 - val_loss: 0.1657 - val_accuracy: 0.9556 - 7s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1719/1719 - 7s - loss: 0.1821 - accuracy: 0.9525 - val_loss: 0.1612 - val_accuracy: 0.9564 - 7s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1719/1719 - 7s - loss: 0.1721 - accuracy: 0.9551 - val_loss: 0.1517 - val_accuracy: 0.9592 - 7s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1719/1719 - 8s - loss: 0.1631 - accuracy: 0.9570 - val_loss: 0.1442 - val_accuracy: 0.9596 - 8s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1719/1719 - 7s - loss: 0.1557 - accuracy: 0.9594 - val_loss: 0.1422 - val_accuracy: 0.9606 - 7s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1719/1719 - 7s - loss: 0.1492 - accuracy: 0.9608 - val_loss: 0.1366 - val_accuracy: 0.9622 - 7s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1719/1719 - 7s - loss: 0.1432 - accuracy: 0.9609 - val_loss: 0.1329 - val_accuracy: 0.9624 - 7s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1719/1719 - 7s - loss: 0.1383 - accuracy: 0.9627 - val_loss: 0.1286 - val_accuracy: 0.9660 - 7s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1719/1719 - 7s - loss: 0.1336 - accuracy: 0.9637 - val_loss: 0.1289 - val_accuracy: 0.9634 - 7s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "1719/1719 - 7s - loss: 0.1295 - accuracy: 0.9651 - val_loss: 0.1261 - val_accuracy: 0.9638 - 7s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1719/1719 - 8s - loss: 0.1256 - accuracy: 0.9657 - val_loss: 0.1215 - val_accuracy: 0.9654 - 8s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1719/1719 - 7s - loss: 0.1218 - accuracy: 0.9666 - val_loss: 0.1206 - val_accuracy: 0.9654 - 7s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "1719/1719 - 7s - loss: 0.1188 - accuracy: 0.9669 - val_loss: 0.1197 - val_accuracy: 0.9652 - 7s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1719/1719 - 7s - loss: 0.1165 - accuracy: 0.9679 - val_loss: 0.1200 - val_accuracy: 0.9676 - 7s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1719/1719 - 7s - loss: 0.1138 - accuracy: 0.9679 - val_loss: 0.1143 - val_accuracy: 0.9676 - 7s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1719/1719 - 7s - loss: 0.1114 - accuracy: 0.9685 - val_loss: 0.1127 - val_accuracy: 0.9662 - 7s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1719/1719 - 7s - loss: 0.1089 - accuracy: 0.9696 - val_loss: 0.1128 - val_accuracy: 0.9674 - 7s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1719/1719 - 7s - loss: 0.1068 - accuracy: 0.9699 - val_loss: 0.1112 - val_accuracy: 0.9676 - 7s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1719/1719 - 7s - loss: 0.1046 - accuracy: 0.9702 - val_loss: 0.1131 - val_accuracy: 0.9672 - 7s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1719/1719 - 7s - loss: 0.1027 - accuracy: 0.9717 - val_loss: 0.1111 - val_accuracy: 0.9682 - 7s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1719/1719 - 7s - loss: 0.1017 - accuracy: 0.9711 - val_loss: 0.1091 - val_accuracy: 0.9698 - 7s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "1719/1719 - 7s - loss: 0.0996 - accuracy: 0.9725 - val_loss: 0.1073 - val_accuracy: 0.9700 - 7s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "1719/1719 - 7s - loss: 0.0981 - accuracy: 0.9720 - val_loss: 0.1084 - val_accuracy: 0.9696 - 7s/epoch - 4ms/step\n",
      "Pruning morphological model...\n",
      "\n",
      "Baseline test accuracy: \n",
      "20/20 [==============================] - 1s 21ms/step - loss: 0.1215 - accuracy: 0.9644\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 31000\n",
      "Weights that can be pruned: 27347\n",
      "Left parameters: 3653\n",
      "Unactive neurons: 0\n",
      "Parameter reduction of the model: 88%\n",
      "Parameter reduction of the morph layers: 91%\n",
      "\n",
      "Hard pruned model. Test acuraccy\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1215 - accuracy: 0.9644\n",
      "Retraining MLP dense model...\n",
      "Epoch 1/40\n",
      "108/108 [==============================] - 4s 23ms/step - loss: 0.6047 - accuracy: 0.8457 - val_loss: 0.2130 - val_accuracy: 0.9502\n",
      "Epoch 2/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2751 - accuracy: 0.9202 - val_loss: 0.1499 - val_accuracy: 0.9594\n",
      "Epoch 3/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2211 - accuracy: 0.9342 - val_loss: 0.1283 - val_accuracy: 0.9638\n",
      "Epoch 4/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1950 - accuracy: 0.9404 - val_loss: 0.1184 - val_accuracy: 0.9676\n",
      "Epoch 5/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1758 - accuracy: 0.9464 - val_loss: 0.1100 - val_accuracy: 0.9684\n",
      "Epoch 6/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1646 - accuracy: 0.9495 - val_loss: 0.1042 - val_accuracy: 0.9702\n",
      "Epoch 7/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1550 - accuracy: 0.9525 - val_loss: 0.1004 - val_accuracy: 0.9696\n",
      "Epoch 8/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1455 - accuracy: 0.9549 - val_loss: 0.0975 - val_accuracy: 0.9716\n",
      "Epoch 9/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1406 - accuracy: 0.9555 - val_loss: 0.0948 - val_accuracy: 0.9720\n",
      "Epoch 10/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1348 - accuracy: 0.9570 - val_loss: 0.0933 - val_accuracy: 0.9728\n",
      "Epoch 11/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.9591 - val_loss: 0.0905 - val_accuracy: 0.9716\n",
      "Epoch 12/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1261 - accuracy: 0.9601 - val_loss: 0.0894 - val_accuracy: 0.9738\n",
      "Epoch 13/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1211 - accuracy: 0.9617 - val_loss: 0.0884 - val_accuracy: 0.9726\n",
      "Epoch 14/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1163 - accuracy: 0.9627 - val_loss: 0.0866 - val_accuracy: 0.9732\n",
      "Epoch 15/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1161 - accuracy: 0.9635 - val_loss: 0.0860 - val_accuracy: 0.9744\n",
      "Epoch 16/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1124 - accuracy: 0.9642 - val_loss: 0.0844 - val_accuracy: 0.9744\n",
      "Epoch 17/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1074 - accuracy: 0.9656 - val_loss: 0.0839 - val_accuracy: 0.9750\n",
      "Epoch 18/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1065 - accuracy: 0.9658 - val_loss: 0.0831 - val_accuracy: 0.9748\n",
      "Epoch 19/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1054 - accuracy: 0.9665 - val_loss: 0.0842 - val_accuracy: 0.9744\n",
      "Epoch 20/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1010 - accuracy: 0.9675 - val_loss: 0.0820 - val_accuracy: 0.9754\n",
      "Epoch 21/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0999 - accuracy: 0.9678 - val_loss: 0.0816 - val_accuracy: 0.9748\n",
      "Epoch 22/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0989 - accuracy: 0.9681 - val_loss: 0.0815 - val_accuracy: 0.9754\n",
      "Epoch 23/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0960 - accuracy: 0.9696 - val_loss: 0.0820 - val_accuracy: 0.9752\n",
      "Epoch 24/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0932 - accuracy: 0.9702 - val_loss: 0.0826 - val_accuracy: 0.9750\n",
      "Epoch 25/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0941 - accuracy: 0.9695 - val_loss: 0.0809 - val_accuracy: 0.9756\n",
      "Epoch 26/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0929 - accuracy: 0.9711 - val_loss: 0.0818 - val_accuracy: 0.9754\n",
      "Epoch 27/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0916 - accuracy: 0.9706 - val_loss: 0.0807 - val_accuracy: 0.9758\n",
      "Epoch 28/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0912 - accuracy: 0.9701 - val_loss: 0.0791 - val_accuracy: 0.9760\n",
      "Epoch 29/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9713 - val_loss: 0.0804 - val_accuracy: 0.9766\n",
      "Epoch 30/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0872 - accuracy: 0.9721 - val_loss: 0.0794 - val_accuracy: 0.9760\n",
      "Epoch 31/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0844 - accuracy: 0.9729 - val_loss: 0.0786 - val_accuracy: 0.9760\n",
      "Epoch 32/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0844 - accuracy: 0.9727 - val_loss: 0.0793 - val_accuracy: 0.9766\n",
      "Epoch 33/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0848 - accuracy: 0.9725 - val_loss: 0.0799 - val_accuracy: 0.9768\n",
      "Epoch 34/40\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0832 - accuracy: 0.9723 - val_loss: 0.0776 - val_accuracy: 0.9762\n",
      "Epoch 35/40\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0810 - accuracy: 0.9739 - val_loss: 0.0781 - val_accuracy: 0.9772\n",
      "Epoch 36/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.9732 - val_loss: 0.0793 - val_accuracy: 0.9766\n",
      "Epoch 37/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0805 - accuracy: 0.9738 - val_loss: 0.0783 - val_accuracy: 0.9762\n",
      "Epoch 38/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0796 - accuracy: 0.9740 - val_loss: 0.0796 - val_accuracy: 0.9770\n",
      "Epoch 39/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0776 - accuracy: 0.9755 - val_loss: 0.0792 - val_accuracy: 0.9772\n",
      "Epoch 40/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9738 - val_loss: 0.0789 - val_accuracy: 0.9768\n",
      "Retraining MLP model...\n",
      "Epoch 1/10\n",
      "108/108 - 0s - loss: 0.0761 - accuracy: 0.9752 - val_loss: 0.0782 - val_accuracy: 0.9764 - 460ms/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "108/108 - 0s - loss: 0.0758 - accuracy: 0.9753 - val_loss: 0.0767 - val_accuracy: 0.9778 - 397ms/epoch - 4ms/step\n",
      "Epoch 3/10\n",
      "108/108 - 0s - loss: 0.0751 - accuracy: 0.9752 - val_loss: 0.0803 - val_accuracy: 0.9770 - 403ms/epoch - 4ms/step\n",
      "Epoch 4/10\n",
      "108/108 - 0s - loss: 0.0726 - accuracy: 0.9758 - val_loss: 0.0778 - val_accuracy: 0.9776 - 396ms/epoch - 4ms/step\n",
      "Epoch 5/10\n",
      "108/108 - 0s - loss: 0.0719 - accuracy: 0.9757 - val_loss: 0.0782 - val_accuracy: 0.9774 - 398ms/epoch - 4ms/step\n",
      "Epoch 6/10\n",
      "108/108 - 0s - loss: 0.0725 - accuracy: 0.9761 - val_loss: 0.0785 - val_accuracy: 0.9774 - 398ms/epoch - 4ms/step\n",
      "Epoch 7/10\n",
      "108/108 - 0s - loss: 0.0736 - accuracy: 0.9763 - val_loss: 0.0792 - val_accuracy: 0.9774 - 401ms/epoch - 4ms/step\n",
      "Epoch 8/10\n",
      "108/108 - 0s - loss: 0.0715 - accuracy: 0.9763 - val_loss: 0.0793 - val_accuracy: 0.9768 - 396ms/epoch - 4ms/step\n",
      "Epoch 9/10\n",
      "108/108 - 0s - loss: 0.0693 - accuracy: 0.9765 - val_loss: 0.0784 - val_accuracy: 0.9780 - 399ms/epoch - 4ms/step\n",
      "Epoch 10/10\n",
      "108/108 - 0s - loss: 0.0677 - accuracy: 0.9779 - val_loss: 0.0780 - val_accuracy: 0.9776 - 401ms/epoch - 4ms/step\n",
      "Accuracy of the MLP model:\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.0844 - accuracy: 0.9754\n",
      "# Parameters of the model: 266610\n",
      "# Parameters pruned: 249113\n",
      "# Parameters remaining: 17497\n",
      "Remaining weights (%): 6.562769588537565\n"
     ]
    }
   ],
   "source": [
    "pruned, model_hp1, model_ep1 = pruning_tool_MLP_v4_1.pruning_MLP(baselineModel, x_train, y_train, x_val, y_val, x_test, y_test, batch_size=512, morph_epochs=30, mlp_epochs=10, mlp_epochs_refit=40, p=0, optimizer_config=tf.optimizers.serialize(optimizer), extreme=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "430/430 [==============================] - 5s 8ms/step - loss: 0.1346 - accuracy: 0.9569 - val_loss: 0.1151 - val_accuracy: 0.9688\n",
      "Epoch 2/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1242 - accuracy: 0.9601 - val_loss: 0.1077 - val_accuracy: 0.9726\n",
      "Epoch 3/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1186 - accuracy: 0.9619 - val_loss: 0.1093 - val_accuracy: 0.9712\n",
      "Epoch 4/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1107 - accuracy: 0.9641 - val_loss: 0.1098 - val_accuracy: 0.9716\n",
      "Epoch 5/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1104 - accuracy: 0.9648 - val_loss: 0.1017 - val_accuracy: 0.9736\n",
      "Epoch 6/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1083 - accuracy: 0.9653 - val_loss: 0.1137 - val_accuracy: 0.9702\n",
      "Epoch 7/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1009 - accuracy: 0.9677 - val_loss: 0.1086 - val_accuracy: 0.9736\n",
      "Epoch 8/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1012 - accuracy: 0.9673 - val_loss: 0.1043 - val_accuracy: 0.9722\n",
      "Epoch 9/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0986 - accuracy: 0.9685 - val_loss: 0.1119 - val_accuracy: 0.9728\n",
      "Epoch 10/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1002 - accuracy: 0.9682 - val_loss: 0.1127 - val_accuracy: 0.9738\n",
      "Epoch 11/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0931 - accuracy: 0.9699 - val_loss: 0.1040 - val_accuracy: 0.9738\n",
      "Epoch 12/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0948 - accuracy: 0.9696 - val_loss: 0.1175 - val_accuracy: 0.9722\n",
      "Epoch 13/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0912 - accuracy: 0.9715 - val_loss: 0.1090 - val_accuracy: 0.9724\n",
      "Epoch 14/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0897 - accuracy: 0.9705 - val_loss: 0.1082 - val_accuracy: 0.9738\n",
      "Epoch 15/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0908 - accuracy: 0.9700 - val_loss: 0.0984 - val_accuracy: 0.9756\n",
      "Epoch 16/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0926 - accuracy: 0.9699 - val_loss: 0.1033 - val_accuracy: 0.9730\n",
      "Epoch 17/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0847 - accuracy: 0.9723 - val_loss: 0.1096 - val_accuracy: 0.9716\n",
      "Epoch 18/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0859 - accuracy: 0.9725 - val_loss: 0.1071 - val_accuracy: 0.9752\n",
      "Epoch 19/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0854 - accuracy: 0.9721 - val_loss: 0.1061 - val_accuracy: 0.9742\n",
      "Epoch 20/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0848 - accuracy: 0.9724 - val_loss: 0.1101 - val_accuracy: 0.9736\n",
      "Epoch 21/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0833 - accuracy: 0.9731 - val_loss: 0.1095 - val_accuracy: 0.9760\n",
      "Epoch 22/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0821 - accuracy: 0.9737 - val_loss: 0.1154 - val_accuracy: 0.9720\n",
      "Epoch 23/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0826 - accuracy: 0.9729 - val_loss: 0.1126 - val_accuracy: 0.9724\n",
      "Epoch 24/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0783 - accuracy: 0.9737 - val_loss: 0.1059 - val_accuracy: 0.9742\n",
      "Epoch 25/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0816 - accuracy: 0.9741 - val_loss: 0.1190 - val_accuracy: 0.9722\n",
      "Epoch 25: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f5976120430>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "pruned.compile(optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'],\n",
    "              jit_compile=True\n",
    "            ) #from logits = Ture if no activation function on the output\n",
    "pruned.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=40, batch_size=128, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1101 - accuracy: 0.9702\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11006674915552139, 0.9702000021934509]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pruned = 0.9431"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "activationCount_Mnist300_100_0 = np.load('./activationCount_Mnist300_100_0.npy')\n",
    "activationCount_Mnist300_100_1 = np.load('./activationCount_Mnist300_100_1.npy')\n",
    "activationCount_Mnist300_100_2 = np.load('./activationCount_Mnist300_100_2.npy')\n",
    "w_index_0 = np.arange(0, activationCount_Mnist300_100_0.size)\n",
    "w_index_1 = np.arange(0, activationCount_Mnist300_100_1.size)\n",
    "w_index_2 = np.arange(0, activationCount_Mnist300_100_2.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Lenet 300-100 for Mnist')"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(ncols=3, nrows=1, figsize=(12,4), sharey=True)\n",
    "axs[0].hist(activationCount_Mnist300_100_0.reshape(-1), log=True)\n",
    "axs[0].set_xlabel(\"Weights\")\n",
    "axs[0].set_ylabel(\"Count\")\n",
    "axs[0].set_title(\"Layer 0 (300)\")\n",
    "axs[1].hist(activationCount_Mnist300_100_1.reshape(-1), log=True)\n",
    "axs[1].set_xlabel(\"Weights\")\n",
    "axs[1].set_title(\"Layer 1 (100)\")\n",
    "axs[2].hist(activationCount_Mnist300_100_2.reshape(-1), log=True)\n",
    "axs[2].set_xlabel(\"Weights\")\n",
    "axs[2].set_title(\"Layer 2 (10)\")\n",
    "\n",
    "fig.suptitle(\"Lenet 300-100 for Mnist\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros of layer 0: 220420\n",
      "Number of zeros of layer 1: 22312\n",
      "Number of zeros of layer 2: 654\n"
     ]
    }
   ],
   "source": [
    "w_index_0_sorted = np.flip(np.argsort(activationCount_Mnist300_100_0.reshape(-1)))\n",
    "y0 = activationCount_Mnist300_100_0.reshape(-1)[w_index_0_sorted]\n",
    "x0 = w_index_0\n",
    "print(\"Number of zeros of layer 0: \" + str(activationCount_Mnist300_100_0.size - np.count_nonzero(activationCount_Mnist300_100_0.reshape(-1))))\n",
    "w_index_1_sorted = np.flip(np.argsort(activationCount_Mnist300_100_1.reshape(-1)))\n",
    "y1 = activationCount_Mnist300_100_1.reshape(-1)[w_index_1_sorted]\n",
    "x1 = w_index_1\n",
    "print(\"Number of zeros of layer 1: \" + str(activationCount_Mnist300_100_1.size - np.count_nonzero(activationCount_Mnist300_100_1.reshape(-1))))\n",
    "w_index_2_sorted = np.flip(np.argsort(activationCount_Mnist300_100_2.reshape(-1)))\n",
    "y2 = activationCount_Mnist300_100_2.reshape(-1)[w_index_2_sorted]\n",
    "x2 = w_index_2\n",
    "print(\"Number of zeros of layer 2: \" + str(activationCount_Mnist300_100_2.size - np.count_nonzero(activationCount_Mnist300_100_2.reshape(-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.1\n",
    "c0 = y0/y0.max() > p\n",
    "c0 = c0.astype(int)\n",
    "c1 = y1/y1.max() > p\n",
    "c1 = c1.astype(int)\n",
    "c2 = y2/y2.max() > p\n",
    "c2 = c2.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0.98, 'Lenet 300-100 for Mnist, p=10%')"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(12,4), sharey=True)\n",
    "axs[0].set_xscale('log')\n",
    "axs[0].set_yscale('log')\n",
    "axs[0].set_adjustable(\"datalim\")\n",
    "axs[0].scatter(x0, y0, c=c0)\n",
    "axs[0].set_ylabel(\"Count\")\n",
    "axs[0].set_xlabel(\"Index\")\n",
    "axs[0].set_title(\"Layer 0 (300)\")\n",
    "axs[1].set_xscale('log')\n",
    "axs[1].set_yscale('log')\n",
    "axs[1].set_adjustable(\"datalim\")\n",
    "axs[1].scatter(x1, y1, c=c1)\n",
    "axs[1].set_xlabel(\"Index\")\n",
    "axs[1].set_title(\"Layer 1 (100)\")\n",
    "\n",
    "axs[2].set_xscale('log')\n",
    "axs[2].set_yscale('log')\n",
    "axs[2].set_adjustable(\"datalim\")\n",
    "axs[2].scatter(x2, y2, c=c2)\n",
    "axs[2].set_xlabel(\"Index\")\n",
    "axs[2].set_title(\"Layer 2 (10)\")\n",
    "\n",
    "fig.suptitle(\"Lenet 300-100 for Mnist, p=10%\")\n",
    "# ax.set_xlim(1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training morphological model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min (SoftMaxMin)   (55000, 300)              235200    \n",
      "                                                                 \n",
      " dense (Dense)               (55000, 10)               3000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238200 (930.47 KB)\n",
      "Trainable params: 238200 (930.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 10:32:53.153152: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fee640043e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-05 10:32:53.153208: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P40, Compute Capability 6.1\n",
      "2023-12-05 10:32:53.153221: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla P40, Compute Capability 6.1\n",
      "2023-12-05 10:32:53.167580: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-05 10:32:53.645124: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2023-12-05 10:32:53.760400: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-05 10:32:53.957065: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 - 11s - loss: 0.8475 - accuracy: 0.7688 - val_loss: 0.2647 - val_accuracy: 0.9284 - 11s/epoch - 7ms/step\n",
      "Epoch 2/30\n",
      "1719/1719 - 8s - loss: 0.2854 - accuracy: 0.9179 - val_loss: 0.1894 - val_accuracy: 0.9478 - 8s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1719/1719 - 8s - loss: 0.2212 - accuracy: 0.9360 - val_loss: 0.1545 - val_accuracy: 0.9570 - 8s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1719/1719 - 8s - loss: 0.1845 - accuracy: 0.9470 - val_loss: 0.1386 - val_accuracy: 0.9612 - 8s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1719/1719 - 7s - loss: 0.1606 - accuracy: 0.9546 - val_loss: 0.1194 - val_accuracy: 0.9688 - 7s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1719/1719 - 8s - loss: 0.1435 - accuracy: 0.9596 - val_loss: 0.1063 - val_accuracy: 0.9732 - 8s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1719/1719 - 8s - loss: 0.1297 - accuracy: 0.9631 - val_loss: 0.1008 - val_accuracy: 0.9734 - 8s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1719/1719 - 8s - loss: 0.1195 - accuracy: 0.9658 - val_loss: 0.1086 - val_accuracy: 0.9704 - 8s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1719/1719 - 7s - loss: 0.1112 - accuracy: 0.9681 - val_loss: 0.0897 - val_accuracy: 0.9782 - 7s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1719/1719 - 8s - loss: 0.1035 - accuracy: 0.9703 - val_loss: 0.0929 - val_accuracy: 0.9730 - 8s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1719/1719 - 8s - loss: 0.0962 - accuracy: 0.9726 - val_loss: 0.0906 - val_accuracy: 0.9744 - 8s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1719/1719 - 8s - loss: 0.0904 - accuracy: 0.9744 - val_loss: 0.0942 - val_accuracy: 0.9742 - 8s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1719/1719 - 8s - loss: 0.0860 - accuracy: 0.9757 - val_loss: 0.0867 - val_accuracy: 0.9776 - 8s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1719/1719 - 8s - loss: 0.0818 - accuracy: 0.9772 - val_loss: 0.0912 - val_accuracy: 0.9750 - 8s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1719/1719 - 8s - loss: 0.0773 - accuracy: 0.9778 - val_loss: 0.0788 - val_accuracy: 0.9780 - 8s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1719/1719 - 7s - loss: 0.0728 - accuracy: 0.9797 - val_loss: 0.0808 - val_accuracy: 0.9778 - 7s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "1719/1719 - 7s - loss: 0.0700 - accuracy: 0.9804 - val_loss: 0.0753 - val_accuracy: 0.9782 - 7s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1719/1719 - 7s - loss: 0.0663 - accuracy: 0.9815 - val_loss: 0.0836 - val_accuracy: 0.9772 - 7s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1719/1719 - 8s - loss: 0.0640 - accuracy: 0.9824 - val_loss: 0.0724 - val_accuracy: 0.9802 - 8s/epoch - 5ms/step\n",
      "Epoch 20/30\n",
      "1719/1719 - 8s - loss: 0.0616 - accuracy: 0.9830 - val_loss: 0.0851 - val_accuracy: 0.9746 - 8s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1719/1719 - 8s - loss: 0.0588 - accuracy: 0.9837 - val_loss: 0.0787 - val_accuracy: 0.9794 - 8s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1719/1719 - 8s - loss: 0.0558 - accuracy: 0.9849 - val_loss: 0.0732 - val_accuracy: 0.9778 - 8s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1719/1719 - 8s - loss: 0.0542 - accuracy: 0.9852 - val_loss: 0.0714 - val_accuracy: 0.9802 - 8s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1719/1719 - 8s - loss: 0.0517 - accuracy: 0.9853 - val_loss: 0.0738 - val_accuracy: 0.9796 - 8s/epoch - 5ms/step\n",
      "Epoch 25/30\n",
      "1719/1719 - 8s - loss: 0.0504 - accuracy: 0.9863 - val_loss: 0.0829 - val_accuracy: 0.9774 - 8s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1719/1719 - 8s - loss: 0.0477 - accuracy: 0.9871 - val_loss: 0.0731 - val_accuracy: 0.9792 - 8s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1719/1719 - 8s - loss: 0.0465 - accuracy: 0.9874 - val_loss: 0.0765 - val_accuracy: 0.9784 - 8s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1719/1719 - 8s - loss: 0.0448 - accuracy: 0.9885 - val_loss: 0.0772 - val_accuracy: 0.9788 - 8s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "1719/1719 - 8s - loss: 0.0431 - accuracy: 0.9883 - val_loss: 0.0690 - val_accuracy: 0.9806 - 8s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "1719/1719 - 8s - loss: 0.0406 - accuracy: 0.9897 - val_loss: 0.0688 - val_accuracy: 0.9818 - 8s/epoch - 4ms/step\n",
      "Pruning morphological model...\n",
      "\n",
      "Baseline test accuracy: \n",
      "20/20 [==============================] - 1s 25ms/step - loss: 0.0766 - accuracy: 0.9759\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 238200\n",
      "Weights that can be pruned: 234341\n",
      "Left parameters: 3859\n",
      "Unactive neurons: 0\n",
      "Parameter reduction of the model: 98%\n",
      "Parameter reduction of the morph layers: 99%\n",
      "\n",
      "Extreme pruned model with a TEP threshold of 10% . Test acuraccy\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.3482 - accuracy: 0.8977\n",
      "Retraining MLP dense model...\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 10:38:25.918071: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. sequential/modelLayer_1_0/dropout/random_uniform/RandomUniform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 5s 28ms/step - loss: 1.1825 - accuracy: 0.6609 - val_loss: 0.4468 - val_accuracy: 0.8826\n",
      "Epoch 2/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4939 - accuracy: 0.8539 - val_loss: 0.2929 - val_accuracy: 0.9202\n",
      "Epoch 3/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3847 - accuracy: 0.8869 - val_loss: 0.2361 - val_accuracy: 0.9362\n",
      "Epoch 4/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.9013 - val_loss: 0.2041 - val_accuracy: 0.9434\n",
      "Epoch 5/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2936 - accuracy: 0.9107 - val_loss: 0.1820 - val_accuracy: 0.9490\n",
      "Epoch 6/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2648 - accuracy: 0.9212 - val_loss: 0.1636 - val_accuracy: 0.9578\n",
      "Epoch 7/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2436 - accuracy: 0.9276 - val_loss: 0.1480 - val_accuracy: 0.9610\n",
      "Epoch 8/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2262 - accuracy: 0.9320 - val_loss: 0.1382 - val_accuracy: 0.9628\n",
      "Epoch 9/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2114 - accuracy: 0.9359 - val_loss: 0.1301 - val_accuracy: 0.9656\n",
      "Epoch 10/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1978 - accuracy: 0.9407 - val_loss: 0.1228 - val_accuracy: 0.9686\n",
      "Epoch 11/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1879 - accuracy: 0.9423 - val_loss: 0.1165 - val_accuracy: 0.9678\n",
      "Epoch 12/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1787 - accuracy: 0.9456 - val_loss: 0.1107 - val_accuracy: 0.9694\n",
      "Epoch 13/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1668 - accuracy: 0.9497 - val_loss: 0.1089 - val_accuracy: 0.9712\n",
      "Epoch 14/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1630 - accuracy: 0.9502 - val_loss: 0.1060 - val_accuracy: 0.9722\n",
      "Epoch 15/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1562 - accuracy: 0.9526 - val_loss: 0.1002 - val_accuracy: 0.9732\n",
      "Epoch 16/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.9542 - val_loss: 0.0985 - val_accuracy: 0.9738\n",
      "Epoch 17/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1450 - accuracy: 0.9558 - val_loss: 0.0948 - val_accuracy: 0.9754\n",
      "Epoch 18/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1383 - accuracy: 0.9571 - val_loss: 0.0927 - val_accuracy: 0.9750\n",
      "Epoch 19/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1355 - accuracy: 0.9585 - val_loss: 0.0909 - val_accuracy: 0.9748\n",
      "Epoch 20/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1313 - accuracy: 0.9601 - val_loss: 0.0875 - val_accuracy: 0.9772\n",
      "Epoch 21/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.9621 - val_loss: 0.0863 - val_accuracy: 0.9770\n",
      "Epoch 22/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1222 - accuracy: 0.9622 - val_loss: 0.0844 - val_accuracy: 0.9782\n",
      "Epoch 23/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1192 - accuracy: 0.9638 - val_loss: 0.0818 - val_accuracy: 0.9774\n",
      "Epoch 24/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1161 - accuracy: 0.9645 - val_loss: 0.0834 - val_accuracy: 0.9782\n",
      "Epoch 25/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1125 - accuracy: 0.9647 - val_loss: 0.0812 - val_accuracy: 0.9778\n",
      "Epoch 26/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1084 - accuracy: 0.9663 - val_loss: 0.0782 - val_accuracy: 0.9806\n",
      "Epoch 27/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1063 - accuracy: 0.9677 - val_loss: 0.0762 - val_accuracy: 0.9802\n",
      "Epoch 28/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1032 - accuracy: 0.9678 - val_loss: 0.0751 - val_accuracy: 0.9812\n",
      "Epoch 29/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1014 - accuracy: 0.9683 - val_loss: 0.0747 - val_accuracy: 0.9812\n",
      "Epoch 30/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1003 - accuracy: 0.9690 - val_loss: 0.0723 - val_accuracy: 0.9828\n",
      "Epoch 31/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0962 - accuracy: 0.9695 - val_loss: 0.0726 - val_accuracy: 0.9820\n",
      "Epoch 32/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0959 - accuracy: 0.9711 - val_loss: 0.0706 - val_accuracy: 0.9828\n",
      "Epoch 33/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0928 - accuracy: 0.9699 - val_loss: 0.0718 - val_accuracy: 0.9824\n",
      "Epoch 34/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0911 - accuracy: 0.9716 - val_loss: 0.0721 - val_accuracy: 0.9822\n",
      "Epoch 35/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9715 - val_loss: 0.0701 - val_accuracy: 0.9820\n",
      "Epoch 36/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0875 - accuracy: 0.9721 - val_loss: 0.0678 - val_accuracy: 0.9824\n",
      "Epoch 37/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9735 - val_loss: 0.0668 - val_accuracy: 0.9818\n",
      "Epoch 38/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0849 - accuracy: 0.9731 - val_loss: 0.0667 - val_accuracy: 0.9832\n",
      "Epoch 39/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0823 - accuracy: 0.9741 - val_loss: 0.0666 - val_accuracy: 0.9838\n",
      "Epoch 40/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0798 - accuracy: 0.9747 - val_loss: 0.0660 - val_accuracy: 0.9834\n",
      "Training morphological model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min (SoftMaxMin)   (55000, 100)              30000     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (55000, 10)               1000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31000 (121.09 KB)\n",
      "Trainable params: 31000 (121.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1719/1719 - 11s - loss: 1.2113 - accuracy: 0.7055 - val_loss: 0.6409 - val_accuracy: 0.8606 - 11s/epoch - 6ms/step\n",
      "Epoch 2/30\n",
      "1719/1719 - 7s - loss: 0.5916 - accuracy: 0.8611 - val_loss: 0.4381 - val_accuracy: 0.9054 - 7s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1719/1719 - 7s - loss: 0.4630 - accuracy: 0.8868 - val_loss: 0.3577 - val_accuracy: 0.9198 - 7s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1719/1719 - 7s - loss: 0.3971 - accuracy: 0.8995 - val_loss: 0.3124 - val_accuracy: 0.9274 - 7s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1719/1719 - 7s - loss: 0.3562 - accuracy: 0.9085 - val_loss: 0.2818 - val_accuracy: 0.9342 - 7s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1719/1719 - 7s - loss: 0.3270 - accuracy: 0.9145 - val_loss: 0.2592 - val_accuracy: 0.9378 - 7s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1719/1719 - 7s - loss: 0.3056 - accuracy: 0.9191 - val_loss: 0.2406 - val_accuracy: 0.9428 - 7s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1719/1719 - 7s - loss: 0.2884 - accuracy: 0.9232 - val_loss: 0.2283 - val_accuracy: 0.9464 - 7s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1719/1719 - 7s - loss: 0.2743 - accuracy: 0.9253 - val_loss: 0.2282 - val_accuracy: 0.9440 - 7s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1719/1719 - 7s - loss: 0.2630 - accuracy: 0.9292 - val_loss: 0.2113 - val_accuracy: 0.9482 - 7s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1719/1719 - 7s - loss: 0.2532 - accuracy: 0.9306 - val_loss: 0.2053 - val_accuracy: 0.9484 - 7s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1719/1719 - 7s - loss: 0.2457 - accuracy: 0.9325 - val_loss: 0.2003 - val_accuracy: 0.9500 - 7s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1719/1719 - 7s - loss: 0.2387 - accuracy: 0.9337 - val_loss: 0.1951 - val_accuracy: 0.9480 - 7s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1719/1719 - 7s - loss: 0.2321 - accuracy: 0.9359 - val_loss: 0.1915 - val_accuracy: 0.9484 - 7s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1719/1719 - 7s - loss: 0.2266 - accuracy: 0.9364 - val_loss: 0.1854 - val_accuracy: 0.9514 - 7s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1719/1719 - 7s - loss: 0.2212 - accuracy: 0.9386 - val_loss: 0.1790 - val_accuracy: 0.9522 - 7s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "1719/1719 - 7s - loss: 0.2170 - accuracy: 0.9393 - val_loss: 0.1785 - val_accuracy: 0.9544 - 7s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1719/1719 - 7s - loss: 0.2124 - accuracy: 0.9398 - val_loss: 0.1724 - val_accuracy: 0.9568 - 7s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1719/1719 - 7s - loss: 0.2080 - accuracy: 0.9415 - val_loss: 0.1695 - val_accuracy: 0.9574 - 7s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "1719/1719 - 7s - loss: 0.2049 - accuracy: 0.9422 - val_loss: 0.1669 - val_accuracy: 0.9578 - 7s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1719/1719 - 7s - loss: 0.2014 - accuracy: 0.9438 - val_loss: 0.1620 - val_accuracy: 0.9594 - 7s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1719/1719 - 7s - loss: 0.1977 - accuracy: 0.9444 - val_loss: 0.1626 - val_accuracy: 0.9580 - 7s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1719/1719 - 7s - loss: 0.1948 - accuracy: 0.9447 - val_loss: 0.1592 - val_accuracy: 0.9592 - 7s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1719/1719 - 7s - loss: 0.1919 - accuracy: 0.9459 - val_loss: 0.1562 - val_accuracy: 0.9600 - 7s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1719/1719 - 7s - loss: 0.1892 - accuracy: 0.9464 - val_loss: 0.1534 - val_accuracy: 0.9620 - 7s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1719/1719 - 7s - loss: 0.1870 - accuracy: 0.9468 - val_loss: 0.1586 - val_accuracy: 0.9576 - 7s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1719/1719 - 7s - loss: 0.1845 - accuracy: 0.9479 - val_loss: 0.1515 - val_accuracy: 0.9620 - 7s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1719/1719 - 7s - loss: 0.1821 - accuracy: 0.9485 - val_loss: 0.1522 - val_accuracy: 0.9594 - 7s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "1719/1719 - 7s - loss: 0.1796 - accuracy: 0.9491 - val_loss: 0.1477 - val_accuracy: 0.9616 - 7s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "1719/1719 - 7s - loss: 0.1776 - accuracy: 0.9498 - val_loss: 0.1529 - val_accuracy: 0.9608 - 7s/epoch - 4ms/step\n",
      "Pruning morphological model...\n",
      "\n",
      "Baseline test accuracy: \n",
      "20/20 [==============================] - 1s 20ms/step - loss: 0.1799 - accuracy: 0.9470\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 31000\n",
      "Weights that can be pruned: 29731\n",
      "Left parameters: 1269\n",
      "Unactive neurons: 0\n",
      "Parameter reduction of the model: 95%\n",
      "Parameter reduction of the morph layers: 99%\n",
      "\n",
      "Extreme pruned model with a TEP threshold of 10% . Test acuraccy\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.2731 - accuracy: 0.9105\n",
      "Retraining MLP dense model...\n",
      "Epoch 1/40\n",
      "108/108 [==============================] - 4s 23ms/step - loss: 1.9238 - accuracy: 0.3922 - val_loss: 1.4951 - val_accuracy: 0.7446\n",
      "Epoch 2/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.2867 - accuracy: 0.6784 - val_loss: 0.8443 - val_accuracy: 0.8324\n",
      "Epoch 3/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8859 - accuracy: 0.7531 - val_loss: 0.5564 - val_accuracy: 0.8706\n",
      "Epoch 4/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7129 - accuracy: 0.7886 - val_loss: 0.4373 - val_accuracy: 0.8862\n",
      "Epoch 5/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6266 - accuracy: 0.8088 - val_loss: 0.3759 - val_accuracy: 0.8994\n",
      "Epoch 6/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5726 - accuracy: 0.8248 - val_loss: 0.3400 - val_accuracy: 0.9062\n",
      "Epoch 7/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5377 - accuracy: 0.8355 - val_loss: 0.3132 - val_accuracy: 0.9150\n",
      "Epoch 8/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5134 - accuracy: 0.8429 - val_loss: 0.2940 - val_accuracy: 0.9190\n",
      "Epoch 9/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4902 - accuracy: 0.8498 - val_loss: 0.2779 - val_accuracy: 0.9226\n",
      "Epoch 10/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4741 - accuracy: 0.8533 - val_loss: 0.2671 - val_accuracy: 0.9254\n",
      "Epoch 11/40\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.8594 - val_loss: 0.2574 - val_accuracy: 0.9278\n",
      "Epoch 12/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8645 - val_loss: 0.2489 - val_accuracy: 0.9274\n",
      "Epoch 13/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8677 - val_loss: 0.2420 - val_accuracy: 0.9294\n",
      "Epoch 14/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.8689 - val_loss: 0.2340 - val_accuracy: 0.9322\n",
      "Epoch 15/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4138 - accuracy: 0.8728 - val_loss: 0.2291 - val_accuracy: 0.9338\n",
      "Epoch 16/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4056 - accuracy: 0.8753 - val_loss: 0.2231 - val_accuracy: 0.9354\n",
      "Epoch 17/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3968 - accuracy: 0.8777 - val_loss: 0.2195 - val_accuracy: 0.9362\n",
      "Epoch 18/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3900 - accuracy: 0.8789 - val_loss: 0.2135 - val_accuracy: 0.9392\n",
      "Epoch 19/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3883 - accuracy: 0.8806 - val_loss: 0.2111 - val_accuracy: 0.9392\n",
      "Epoch 20/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3785 - accuracy: 0.8828 - val_loss: 0.2068 - val_accuracy: 0.9408\n",
      "Epoch 21/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.8842 - val_loss: 0.2040 - val_accuracy: 0.9420\n",
      "Epoch 22/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3722 - accuracy: 0.8851 - val_loss: 0.2010 - val_accuracy: 0.9440\n",
      "Epoch 23/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3676 - accuracy: 0.8865 - val_loss: 0.1982 - val_accuracy: 0.9462\n",
      "Epoch 24/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3624 - accuracy: 0.8897 - val_loss: 0.1960 - val_accuracy: 0.9448\n",
      "Epoch 25/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3583 - accuracy: 0.8891 - val_loss: 0.1931 - val_accuracy: 0.9466\n",
      "Epoch 26/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3594 - accuracy: 0.8886 - val_loss: 0.1909 - val_accuracy: 0.9476\n",
      "Epoch 27/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3555 - accuracy: 0.8898 - val_loss: 0.1894 - val_accuracy: 0.9468\n",
      "Epoch 28/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3522 - accuracy: 0.8910 - val_loss: 0.1863 - val_accuracy: 0.9474\n",
      "Epoch 29/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3502 - accuracy: 0.8922 - val_loss: 0.1861 - val_accuracy: 0.9486\n",
      "Epoch 30/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3485 - accuracy: 0.8930 - val_loss: 0.1829 - val_accuracy: 0.9502\n",
      "Epoch 31/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.8938 - val_loss: 0.1819 - val_accuracy: 0.9502\n",
      "Epoch 32/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3424 - accuracy: 0.8934 - val_loss: 0.1814 - val_accuracy: 0.9492\n",
      "Epoch 33/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.8945 - val_loss: 0.1785 - val_accuracy: 0.9508\n",
      "Epoch 34/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3392 - accuracy: 0.8943 - val_loss: 0.1793 - val_accuracy: 0.9508\n",
      "Epoch 35/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3344 - accuracy: 0.8961 - val_loss: 0.1769 - val_accuracy: 0.9522\n",
      "Epoch 36/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3341 - accuracy: 0.8964 - val_loss: 0.1760 - val_accuracy: 0.9512\n",
      "Epoch 37/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3367 - accuracy: 0.8956 - val_loss: 0.1732 - val_accuracy: 0.9518\n",
      "Epoch 38/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3332 - accuracy: 0.8981 - val_loss: 0.1753 - val_accuracy: 0.9512\n",
      "Epoch 39/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3314 - accuracy: 0.8979 - val_loss: 0.1722 - val_accuracy: 0.9520\n",
      "Epoch 40/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3310 - accuracy: 0.8980 - val_loss: 0.1723 - val_accuracy: 0.9518\n",
      "Retraining MLP model...\n",
      "Epoch 1/30\n",
      "108/108 - 0s - loss: 0.3270 - accuracy: 0.8984 - val_loss: 0.1722 - val_accuracy: 0.9526 - 447ms/epoch - 4ms/step\n",
      "Epoch 2/30\n",
      "108/108 - 0s - loss: 0.3263 - accuracy: 0.8985 - val_loss: 0.1691 - val_accuracy: 0.9528 - 390ms/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "108/108 - 0s - loss: 0.3270 - accuracy: 0.9005 - val_loss: 0.1700 - val_accuracy: 0.9518 - 399ms/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "108/108 - 0s - loss: 0.3234 - accuracy: 0.8992 - val_loss: 0.1690 - val_accuracy: 0.9526 - 395ms/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "108/108 - 0s - loss: 0.3220 - accuracy: 0.9011 - val_loss: 0.1695 - val_accuracy: 0.9520 - 394ms/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "108/108 - 0s - loss: 0.3223 - accuracy: 0.8992 - val_loss: 0.1679 - val_accuracy: 0.9524 - 408ms/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "108/108 - 0s - loss: 0.3210 - accuracy: 0.9019 - val_loss: 0.1677 - val_accuracy: 0.9530 - 397ms/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "108/108 - 0s - loss: 0.3210 - accuracy: 0.9010 - val_loss: 0.1670 - val_accuracy: 0.9532 - 406ms/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "108/108 - 0s - loss: 0.3185 - accuracy: 0.9032 - val_loss: 0.1666 - val_accuracy: 0.9524 - 399ms/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "108/108 - 0s - loss: 0.3176 - accuracy: 0.9015 - val_loss: 0.1669 - val_accuracy: 0.9532 - 398ms/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "108/108 - 0s - loss: 0.3186 - accuracy: 0.9013 - val_loss: 0.1647 - val_accuracy: 0.9538 - 403ms/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "108/108 - 0s - loss: 0.3151 - accuracy: 0.9032 - val_loss: 0.1661 - val_accuracy: 0.9538 - 452ms/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "108/108 - 0s - loss: 0.3178 - accuracy: 0.9026 - val_loss: 0.1650 - val_accuracy: 0.9530 - 396ms/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "108/108 - 0s - loss: 0.3176 - accuracy: 0.9018 - val_loss: 0.1642 - val_accuracy: 0.9542 - 399ms/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "108/108 - 0s - loss: 0.3156 - accuracy: 0.9022 - val_loss: 0.1641 - val_accuracy: 0.9536 - 400ms/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "108/108 - 0s - loss: 0.3077 - accuracy: 0.9045 - val_loss: 0.1626 - val_accuracy: 0.9554 - 395ms/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "108/108 - 0s - loss: 0.3146 - accuracy: 0.9028 - val_loss: 0.1636 - val_accuracy: 0.9548 - 393ms/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "108/108 - 0s - loss: 0.3141 - accuracy: 0.9024 - val_loss: 0.1630 - val_accuracy: 0.9548 - 412ms/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "108/108 - 0s - loss: 0.3128 - accuracy: 0.9027 - val_loss: 0.1647 - val_accuracy: 0.9522 - 401ms/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "108/108 - 0s - loss: 0.3110 - accuracy: 0.9042 - val_loss: 0.1621 - val_accuracy: 0.9562 - 391ms/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "108/108 - 0s - loss: 0.3102 - accuracy: 0.9046 - val_loss: 0.1615 - val_accuracy: 0.9556 - 395ms/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "108/108 - 0s - loss: 0.3120 - accuracy: 0.9027 - val_loss: 0.1618 - val_accuracy: 0.9542 - 395ms/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "108/108 - 0s - loss: 0.3086 - accuracy: 0.9049 - val_loss: 0.1618 - val_accuracy: 0.9538 - 394ms/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "108/108 - 0s - loss: 0.3085 - accuracy: 0.9040 - val_loss: 0.1609 - val_accuracy: 0.9552 - 400ms/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "108/108 - 0s - loss: 0.3096 - accuracy: 0.9049 - val_loss: 0.1622 - val_accuracy: 0.9544 - 421ms/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "108/108 - 0s - loss: 0.3099 - accuracy: 0.9045 - val_loss: 0.1618 - val_accuracy: 0.9542 - 405ms/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "108/108 - 0s - loss: 0.3072 - accuracy: 0.9051 - val_loss: 0.1603 - val_accuracy: 0.9558 - 403ms/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "108/108 - 0s - loss: 0.3068 - accuracy: 0.9049 - val_loss: 0.1604 - val_accuracy: 0.9542 - 406ms/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "108/108 - 0s - loss: 0.3061 - accuracy: 0.9053 - val_loss: 0.1598 - val_accuracy: 0.9560 - 404ms/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "108/108 - 0s - loss: 0.3056 - accuracy: 0.9062 - val_loss: 0.1599 - val_accuracy: 0.9560 - 405ms/epoch - 4ms/step\n",
      "Accuracy of the MLP model:\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.2015 - accuracy: 0.9407\n",
      "# Parameters of the model: 266610\n",
      "# Parameters pruned: 264072\n",
      "Remaining weights (%): 0.009519522898615957\n"
     ]
    }
   ],
   "source": [
    "pruned, model_hp1, model_ep1 = pruning_tool_MLP_v4_1.pruning_MLP(baselineModel, x_train, y_train, x_val, y_val, x_test, y_test, batch_size=512, morph_epochs=30, mlp_epochs=30, mlp_epochs_refit=40, p=10, optimizer_config=tf.optimizers.serialize(optimizer), extreme=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " modelLayer_0_1 (Dense)      (None, 300)               235500    \n",
      "                                                                 \n",
      " modelLayer_1_1 (Dropout)    (None, 300)               0         \n",
      "                                                                 \n",
      " modelLayer_2_1 (Dense)      (None, 100)               30100     \n",
      "                                                                 \n",
      " modelLayer_3_1 (Dropout)    (None, 100)               0         \n",
      "                                                                 \n",
      " modelLayer_4_1 (Dense)      (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "pruned.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros mdoelo sin prunar: 266610\n",
      "Parámetros mdoelo prunado: 2575\n",
      "Pesos restantes: 0.9658302389257717%\n"
     ]
    }
   ],
   "source": [
    "w0 = pruned.layers[0].get_weights()[0]\n",
    "w1 = pruned.layers[2].get_weights()[0]\n",
    "params_prunedModel = pruned.count_params() - (w0.size - np.count_nonzero(w0) + w1.size - np.count_nonzero(w1))\n",
    "print(\"Parámetros mdoelo sin prunar: \" + str(pruned.count_params()))\n",
    "print(\"Parámetros mdoelo prunado: \" + str(params_prunedModel))\n",
    "print(\"Pesos restantes: \" + str(params_prunedModel/pruned.count_params()*100) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "pruned.compile(optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'],\n",
    "              jit_compile=True\n",
    "            ) #from logits = Ture if no activation function on the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.3804 - accuracy: 0.8837 - val_loss: 0.2156 - val_accuracy: 0.9334\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3792 - accuracy: 0.8823 - val_loss: 0.2150 - val_accuracy: 0.9338\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3780 - accuracy: 0.8825 - val_loss: 0.2155 - val_accuracy: 0.9334\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3819 - accuracy: 0.8814 - val_loss: 0.2155 - val_accuracy: 0.9324\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3803 - accuracy: 0.8823 - val_loss: 0.2154 - val_accuracy: 0.9330\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3847 - accuracy: 0.8816 - val_loss: 0.2156 - val_accuracy: 0.9332\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3786 - accuracy: 0.8817 - val_loss: 0.2158 - val_accuracy: 0.9338\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3778 - accuracy: 0.8836 - val_loss: 0.2152 - val_accuracy: 0.9326\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3785 - accuracy: 0.8825 - val_loss: 0.2154 - val_accuracy: 0.9332\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3814 - accuracy: 0.8827 - val_loss: 0.2152 - val_accuracy: 0.9340\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f28c80cec40>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2498 - accuracy: 0.9238\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24978134036064148, 0.923799991607666]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineModel = tf.keras.models.load_model('../models/MLP_MNIST_300_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min_2 (SoftMaxMin  (55000, 300)              235200    \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_4 (Dense)             (55000, 10)               3000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238200 (930.47 KB)\n",
      "Trainable params: 238200 (930.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1719/1719 - 10s - loss: 0.8448 - accuracy: 0.7675 - val_loss: 0.2625 - val_accuracy: 0.9314 - 10s/epoch - 6ms/step\n",
      "Epoch 2/20\n",
      "1719/1719 - 8s - loss: 0.2836 - accuracy: 0.9182 - val_loss: 0.1917 - val_accuracy: 0.9460 - 8s/epoch - 4ms/step\n",
      "Epoch 3/20\n",
      "1719/1719 - 8s - loss: 0.2181 - accuracy: 0.9369 - val_loss: 0.1561 - val_accuracy: 0.9572 - 8s/epoch - 4ms/step\n",
      "Epoch 4/20\n",
      "1719/1719 - 8s - loss: 0.1838 - accuracy: 0.9472 - val_loss: 0.1335 - val_accuracy: 0.9626 - 8s/epoch - 4ms/step\n",
      "Epoch 5/20\n",
      "1719/1719 - 8s - loss: 0.1591 - accuracy: 0.9544 - val_loss: 0.1241 - val_accuracy: 0.9672 - 8s/epoch - 4ms/step\n",
      "Epoch 6/20\n",
      "1719/1719 - 8s - loss: 0.1422 - accuracy: 0.9596 - val_loss: 0.1134 - val_accuracy: 0.9694 - 8s/epoch - 4ms/step\n",
      "Epoch 7/20\n",
      "1719/1719 - 8s - loss: 0.1295 - accuracy: 0.9625 - val_loss: 0.1001 - val_accuracy: 0.9730 - 8s/epoch - 5ms/step\n",
      "Epoch 8/20\n",
      "1719/1719 - 8s - loss: 0.1186 - accuracy: 0.9660 - val_loss: 0.0977 - val_accuracy: 0.9762 - 8s/epoch - 5ms/step\n",
      "Epoch 9/20\n",
      "1719/1719 - 8s - loss: 0.1098 - accuracy: 0.9683 - val_loss: 0.1014 - val_accuracy: 0.9712 - 8s/epoch - 5ms/step\n",
      "Epoch 10/20\n",
      "1719/1719 - 8s - loss: 0.1020 - accuracy: 0.9708 - val_loss: 0.0875 - val_accuracy: 0.9772 - 8s/epoch - 5ms/step\n",
      "Epoch 11/20\n",
      "1719/1719 - 8s - loss: 0.0952 - accuracy: 0.9728 - val_loss: 0.0871 - val_accuracy: 0.9786 - 8s/epoch - 5ms/step\n",
      "Epoch 12/20\n",
      "1719/1719 - 8s - loss: 0.0893 - accuracy: 0.9751 - val_loss: 0.0872 - val_accuracy: 0.9740 - 8s/epoch - 5ms/step\n",
      "Epoch 13/20\n",
      "1719/1719 - 8s - loss: 0.0853 - accuracy: 0.9760 - val_loss: 0.0875 - val_accuracy: 0.9762 - 8s/epoch - 4ms/step\n",
      "Epoch 14/20\n",
      "1719/1719 - 8s - loss: 0.0801 - accuracy: 0.9775 - val_loss: 0.0789 - val_accuracy: 0.9796 - 8s/epoch - 5ms/step\n",
      "Epoch 15/20\n",
      "1719/1719 - 8s - loss: 0.0762 - accuracy: 0.9783 - val_loss: 0.0763 - val_accuracy: 0.9794 - 8s/epoch - 5ms/step\n",
      "Epoch 16/20\n",
      "1719/1719 - 8s - loss: 0.0728 - accuracy: 0.9793 - val_loss: 0.0762 - val_accuracy: 0.9788 - 8s/epoch - 5ms/step\n",
      "Epoch 17/20\n",
      "1719/1719 - 8s - loss: 0.0697 - accuracy: 0.9804 - val_loss: 0.0831 - val_accuracy: 0.9772 - 8s/epoch - 5ms/step\n",
      "Epoch 18/20\n",
      "1719/1719 - 8s - loss: 0.0662 - accuracy: 0.9821 - val_loss: 0.0809 - val_accuracy: 0.9768 - 8s/epoch - 5ms/step\n",
      "Epoch 19/20\n",
      "1719/1719 - 8s - loss: 0.0629 - accuracy: 0.9825 - val_loss: 0.0777 - val_accuracy: 0.9792 - 8s/epoch - 5ms/step\n",
      "Epoch 20/20\n",
      "1719/1719 - 8s - loss: 0.0599 - accuracy: 0.9835 - val_loss: 0.0725 - val_accuracy: 0.9806 - 8s/epoch - 5ms/step\n",
      "\n",
      "Baseline test accuracy: \n",
      "20/20 [==============================] - 1s 19ms/step - loss: 0.0830 - accuracy: 0.9737\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 238200\n",
      "Weights that can be pruned: 234696\n",
      "Left parameters: 3504\n",
      "Unactive neurons: 11\n",
      "Parameter reduction of the model: 98%\n",
      "Parameter reduction of the morph layers: 99%\n",
      "\n",
      "Extreme pruned model with a TEP threshold of 20% . Test acuraccy\n",
      "20/20 [==============================] - 0s 7ms/step - loss: nan - accuracy: 0.0980\n",
      "Epoch 1/30\n",
      "108/108 [==============================] - 3s 20ms/step - loss: 2.5314 - accuracy: 0.2367 - val_loss: 1.8539 - val_accuracy: 0.3954\n",
      "Epoch 2/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.6582 - accuracy: 0.4513 - val_loss: 1.3804 - val_accuracy: 0.5544\n",
      "Epoch 3/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.2880 - accuracy: 0.5765 - val_loss: 1.0920 - val_accuracy: 0.6456\n",
      "Epoch 4/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.0922 - accuracy: 0.6461 - val_loss: 0.9320 - val_accuracy: 0.7054\n",
      "Epoch 5/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.9738 - accuracy: 0.6853 - val_loss: 0.8380 - val_accuracy: 0.7348\n",
      "Epoch 6/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.9004 - accuracy: 0.7089 - val_loss: 0.7880 - val_accuracy: 0.7440\n",
      "Epoch 7/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8526 - accuracy: 0.7237 - val_loss: 0.7404 - val_accuracy: 0.7606\n",
      "Epoch 8/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.8141 - accuracy: 0.7376 - val_loss: 0.7196 - val_accuracy: 0.7682\n",
      "Epoch 9/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7852 - accuracy: 0.7475 - val_loss: 0.6846 - val_accuracy: 0.7830\n",
      "Epoch 10/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7632 - accuracy: 0.7543 - val_loss: 0.6689 - val_accuracy: 0.7848\n",
      "Epoch 11/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7390 - accuracy: 0.7612 - val_loss: 0.6524 - val_accuracy: 0.7900\n",
      "Epoch 12/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7230 - accuracy: 0.7665 - val_loss: 0.6330 - val_accuracy: 0.7968\n",
      "Epoch 13/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7067 - accuracy: 0.7722 - val_loss: 0.6326 - val_accuracy: 0.7930\n",
      "Epoch 14/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6912 - accuracy: 0.7769 - val_loss: 0.6075 - val_accuracy: 0.8056\n",
      "Epoch 15/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6786 - accuracy: 0.7812 - val_loss: 0.5976 - val_accuracy: 0.8104\n",
      "Epoch 16/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6679 - accuracy: 0.7837 - val_loss: 0.5901 - val_accuracy: 0.8114\n",
      "Epoch 17/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6560 - accuracy: 0.7885 - val_loss: 0.5750 - val_accuracy: 0.8180\n",
      "Epoch 18/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.7951 - val_loss: 0.5673 - val_accuracy: 0.8176\n",
      "Epoch 19/30\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.6322 - accuracy: 0.7980 - val_loss: 0.5526 - val_accuracy: 0.8244\n",
      "Epoch 20/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6203 - accuracy: 0.8022 - val_loss: 0.5448 - val_accuracy: 0.8274\n",
      "Epoch 21/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6097 - accuracy: 0.8065 - val_loss: 0.5377 - val_accuracy: 0.8268\n",
      "Epoch 22/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5998 - accuracy: 0.8087 - val_loss: 0.5247 - val_accuracy: 0.8332\n",
      "Epoch 23/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5931 - accuracy: 0.8113 - val_loss: 0.5196 - val_accuracy: 0.8380\n",
      "Epoch 24/30\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.5865 - accuracy: 0.8125 - val_loss: 0.5181 - val_accuracy: 0.8348\n",
      "Epoch 25/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5791 - accuracy: 0.8153 - val_loss: 0.5122 - val_accuracy: 0.8366\n",
      "Epoch 26/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5721 - accuracy: 0.8177 - val_loss: 0.5056 - val_accuracy: 0.8372\n",
      "Epoch 27/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5652 - accuracy: 0.8205 - val_loss: 0.4964 - val_accuracy: 0.8414\n",
      "Epoch 28/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5588 - accuracy: 0.8213 - val_loss: 0.4947 - val_accuracy: 0.8456\n",
      "Epoch 29/30\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.5525 - accuracy: 0.8240 - val_loss: 0.4922 - val_accuracy: 0.8436\n",
      "Epoch 30/30\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5464 - accuracy: 0.8263 - val_loss: 0.4781 - val_accuracy: 0.8506\n",
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min_3 (SoftMaxMin  (55000, 100)              30000     \n",
      " )                                                               \n",
      "                                                                 \n",
      " dense_6 (Dense)             (55000, 10)               1000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31000 (121.09 KB)\n",
      "Trainable params: 31000 (121.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "1719/1719 - 10s - loss: 1.6881 - accuracy: 0.5017 - val_loss: 1.2459 - val_accuracy: 0.6762 - 10s/epoch - 6ms/step\n",
      "Epoch 2/20\n",
      "1719/1719 - 7s - loss: 1.1510 - accuracy: 0.6723 - val_loss: 0.9933 - val_accuracy: 0.7300 - 7s/epoch - 4ms/step\n",
      "Epoch 3/20\n",
      "1719/1719 - 7s - loss: 0.9999 - accuracy: 0.7032 - val_loss: 0.8816 - val_accuracy: 0.7466 - 7s/epoch - 4ms/step\n",
      "Epoch 4/20\n",
      "1719/1719 - 7s - loss: 0.9187 - accuracy: 0.7208 - val_loss: 0.8203 - val_accuracy: 0.7556 - 7s/epoch - 4ms/step\n",
      "Epoch 5/20\n",
      "1719/1719 - 7s - loss: 0.8683 - accuracy: 0.7339 - val_loss: 0.7709 - val_accuracy: 0.7740 - 7s/epoch - 4ms/step\n",
      "Epoch 6/20\n",
      "1719/1719 - 7s - loss: 0.8343 - accuracy: 0.7418 - val_loss: 0.7448 - val_accuracy: 0.7774 - 7s/epoch - 4ms/step\n",
      "Epoch 7/20\n",
      "1719/1719 - 7s - loss: 0.8072 - accuracy: 0.7471 - val_loss: 0.7217 - val_accuracy: 0.7834 - 7s/epoch - 4ms/step\n",
      "Epoch 8/20\n",
      "1719/1719 - 7s - loss: 0.7859 - accuracy: 0.7537 - val_loss: 0.6990 - val_accuracy: 0.7908 - 7s/epoch - 4ms/step\n",
      "Epoch 9/20\n",
      "1719/1719 - 7s - loss: 0.7695 - accuracy: 0.7561 - val_loss: 0.6827 - val_accuracy: 0.7956 - 7s/epoch - 4ms/step\n",
      "Epoch 10/20\n",
      "1719/1719 - 7s - loss: 0.7563 - accuracy: 0.7608 - val_loss: 0.6779 - val_accuracy: 0.7912 - 7s/epoch - 4ms/step\n",
      "Epoch 11/20\n",
      "1719/1719 - 7s - loss: 0.7430 - accuracy: 0.7653 - val_loss: 0.6557 - val_accuracy: 0.8046 - 7s/epoch - 4ms/step\n",
      "Epoch 12/20\n",
      "1719/1719 - 7s - loss: 0.7321 - accuracy: 0.7679 - val_loss: 0.6503 - val_accuracy: 0.8020 - 7s/epoch - 4ms/step\n",
      "Epoch 13/20\n",
      "1719/1719 - 7s - loss: 0.7219 - accuracy: 0.7712 - val_loss: 0.6447 - val_accuracy: 0.8050 - 7s/epoch - 4ms/step\n",
      "Epoch 14/20\n",
      "1719/1719 - 8s - loss: 0.7139 - accuracy: 0.7737 - val_loss: 0.6282 - val_accuracy: 0.8128 - 8s/epoch - 4ms/step\n",
      "Epoch 15/20\n",
      "1719/1719 - 7s - loss: 0.7055 - accuracy: 0.7755 - val_loss: 0.6296 - val_accuracy: 0.8098 - 7s/epoch - 4ms/step\n",
      "Epoch 16/20\n",
      "1719/1719 - 7s - loss: 0.6988 - accuracy: 0.7782 - val_loss: 0.6171 - val_accuracy: 0.8118 - 7s/epoch - 4ms/step\n",
      "Epoch 17/20\n",
      "1719/1719 - 7s - loss: 0.6914 - accuracy: 0.7793 - val_loss: 0.6121 - val_accuracy: 0.8136 - 7s/epoch - 4ms/step\n",
      "Epoch 18/20\n",
      "1719/1719 - 7s - loss: 0.6856 - accuracy: 0.7807 - val_loss: 0.5991 - val_accuracy: 0.8204 - 7s/epoch - 4ms/step\n",
      "Epoch 19/20\n",
      "1719/1719 - 7s - loss: 0.6802 - accuracy: 0.7841 - val_loss: 0.6016 - val_accuracy: 0.8204 - 7s/epoch - 4ms/step\n",
      "Epoch 20/20\n",
      "1719/1719 - 7s - loss: 0.6742 - accuracy: 0.7851 - val_loss: 0.5887 - val_accuracy: 0.8222 - 7s/epoch - 4ms/step\n",
      "\n",
      "Baseline test accuracy: \n",
      "20/20 [==============================] - 1s 14ms/step - loss: 0.6258 - accuracy: 0.8029\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 31000\n",
      "Weights that can be pruned: 29844\n",
      "Left parameters: 1156\n",
      "Unactive neurons: 0\n",
      "Parameter reduction of the model: 96%\n",
      "Parameter reduction of the morph layers: 99%\n",
      "\n",
      "Extreme pruned model with a TEP threshold of 20% . Test acuraccy\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.6642 - accuracy: 0.7863\n",
      "Epoch 1/30\n",
      "108/108 [==============================] - 3s 18ms/step - loss: 4.5174 - accuracy: 0.1558 - val_loss: 2.3558 - val_accuracy: 0.2210\n",
      "Epoch 2/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 2.1099 - accuracy: 0.2667 - val_loss: 1.9986 - val_accuracy: 0.3330\n",
      "Epoch 3/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.9461 - accuracy: 0.3421 - val_loss: 1.8678 - val_accuracy: 0.3814\n",
      "Epoch 4/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.8395 - accuracy: 0.3806 - val_loss: 1.7726 - val_accuracy: 0.4024\n",
      "Epoch 5/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.7710 - accuracy: 0.4031 - val_loss: 1.7123 - val_accuracy: 0.4182\n",
      "Epoch 6/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.7216 - accuracy: 0.4171 - val_loss: 1.6671 - val_accuracy: 0.4300\n",
      "Epoch 7/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.6819 - accuracy: 0.4287 - val_loss: 1.6315 - val_accuracy: 0.4374\n",
      "Epoch 8/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.6475 - accuracy: 0.4363 - val_loss: 1.5968 - val_accuracy: 0.4454\n",
      "Epoch 9/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.6169 - accuracy: 0.4456 - val_loss: 1.5687 - val_accuracy: 0.4510\n",
      "Epoch 10/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.5928 - accuracy: 0.4531 - val_loss: 1.5438 - val_accuracy: 0.4602\n",
      "Epoch 11/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.5711 - accuracy: 0.4609 - val_loss: 1.5252 - val_accuracy: 0.4688\n",
      "Epoch 12/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.5504 - accuracy: 0.4681 - val_loss: 1.5009 - val_accuracy: 0.4746\n",
      "Epoch 13/30\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 1.5246 - accuracy: 0.4778 - val_loss: 1.4694 - val_accuracy: 0.4938\n",
      "Epoch 14/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.5039 - accuracy: 0.4851 - val_loss: 1.4494 - val_accuracy: 0.4982\n",
      "Epoch 15/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.4853 - accuracy: 0.4922 - val_loss: 1.4273 - val_accuracy: 0.5048\n",
      "Epoch 16/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.4666 - accuracy: 0.4997 - val_loss: 1.4077 - val_accuracy: 0.5130\n",
      "Epoch 17/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.4493 - accuracy: 0.5059 - val_loss: 1.3905 - val_accuracy: 0.5228\n",
      "Epoch 18/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.4323 - accuracy: 0.5121 - val_loss: 1.3698 - val_accuracy: 0.5322\n",
      "Epoch 19/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.4155 - accuracy: 0.5181 - val_loss: 1.3519 - val_accuracy: 0.5372\n",
      "Epoch 20/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.3992 - accuracy: 0.5257 - val_loss: 1.3329 - val_accuracy: 0.5454\n",
      "Epoch 21/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.3836 - accuracy: 0.5318 - val_loss: 1.3154 - val_accuracy: 0.5470\n",
      "Epoch 22/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.3686 - accuracy: 0.5386 - val_loss: 1.2983 - val_accuracy: 0.5560\n",
      "Epoch 23/30\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 1.3541 - accuracy: 0.5437 - val_loss: 1.2832 - val_accuracy: 0.5620\n",
      "Epoch 24/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.3396 - accuracy: 0.5501 - val_loss: 1.2652 - val_accuracy: 0.5666\n",
      "Epoch 25/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.3260 - accuracy: 0.5550 - val_loss: 1.2516 - val_accuracy: 0.5756\n",
      "Epoch 26/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.3123 - accuracy: 0.5612 - val_loss: 1.2349 - val_accuracy: 0.5812\n",
      "Epoch 27/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.2992 - accuracy: 0.5654 - val_loss: 1.2233 - val_accuracy: 0.5894\n",
      "Epoch 28/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.2869 - accuracy: 0.5712 - val_loss: 1.2068 - val_accuracy: 0.5916\n",
      "Epoch 29/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.2750 - accuracy: 0.5759 - val_loss: 1.1945 - val_accuracy: 0.6026\n",
      "Epoch 30/30\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 1.2627 - accuracy: 0.5813 - val_loss: 1.1793 - val_accuracy: 0.6062\n",
      "Epoch 1/30\n",
      "108/108 - 1s - loss: 1.2514 - accuracy: 0.5863 - val_loss: 1.1655 - val_accuracy: 0.6108 - 570ms/epoch - 5ms/step\n",
      "Epoch 2/30\n",
      "108/108 - 0s - loss: 1.2401 - accuracy: 0.5895 - val_loss: 1.1540 - val_accuracy: 0.6156 - 403ms/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "108/108 - 0s - loss: 1.2302 - accuracy: 0.5943 - val_loss: 1.1423 - val_accuracy: 0.6236 - 401ms/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "108/108 - 0s - loss: 1.2185 - accuracy: 0.5974 - val_loss: 1.1307 - val_accuracy: 0.6286 - 396ms/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "108/108 - 0s - loss: 1.2093 - accuracy: 0.6014 - val_loss: 1.1203 - val_accuracy: 0.6264 - 394ms/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "108/108 - 0s - loss: 1.1979 - accuracy: 0.6066 - val_loss: 1.1098 - val_accuracy: 0.6370 - 391ms/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "108/108 - 0s - loss: 1.1888 - accuracy: 0.6082 - val_loss: 1.0981 - val_accuracy: 0.6396 - 390ms/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "108/108 - 0s - loss: 1.1793 - accuracy: 0.6117 - val_loss: 1.0922 - val_accuracy: 0.6374 - 394ms/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "108/108 - 0s - loss: 1.1698 - accuracy: 0.6150 - val_loss: 1.0803 - val_accuracy: 0.6452 - 405ms/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "108/108 - 0s - loss: 1.1614 - accuracy: 0.6170 - val_loss: 1.0667 - val_accuracy: 0.6484 - 393ms/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "108/108 - 0s - loss: 1.1529 - accuracy: 0.6205 - val_loss: 1.0579 - val_accuracy: 0.6532 - 412ms/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "108/108 - 0s - loss: 1.1437 - accuracy: 0.6236 - val_loss: 1.0498 - val_accuracy: 0.6550 - 435ms/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "108/108 - 0s - loss: 1.1359 - accuracy: 0.6262 - val_loss: 1.0414 - val_accuracy: 0.6562 - 427ms/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "108/108 - 0s - loss: 1.1271 - accuracy: 0.6293 - val_loss: 1.0349 - val_accuracy: 0.6592 - 423ms/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "108/108 - 0s - loss: 1.1191 - accuracy: 0.6306 - val_loss: 1.0260 - val_accuracy: 0.6596 - 431ms/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "108/108 - 0s - loss: 1.1112 - accuracy: 0.6346 - val_loss: 1.0189 - val_accuracy: 0.6620 - 481ms/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "108/108 - 0s - loss: 1.1035 - accuracy: 0.6370 - val_loss: 1.0153 - val_accuracy: 0.6608 - 427ms/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "108/108 - 0s - loss: 1.0963 - accuracy: 0.6383 - val_loss: 1.0036 - val_accuracy: 0.6680 - 420ms/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "108/108 - 0s - loss: 1.0895 - accuracy: 0.6403 - val_loss: 0.9983 - val_accuracy: 0.6688 - 420ms/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "108/108 - 0s - loss: 1.0818 - accuracy: 0.6432 - val_loss: 0.9883 - val_accuracy: 0.6680 - 432ms/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "108/108 - 0s - loss: 1.0754 - accuracy: 0.6454 - val_loss: 0.9829 - val_accuracy: 0.6742 - 423ms/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "108/108 - 0s - loss: 1.0691 - accuracy: 0.6478 - val_loss: 0.9771 - val_accuracy: 0.6720 - 428ms/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "108/108 - 0s - loss: 1.0626 - accuracy: 0.6501 - val_loss: 0.9733 - val_accuracy: 0.6690 - 423ms/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "108/108 - 0s - loss: 1.0563 - accuracy: 0.6518 - val_loss: 0.9624 - val_accuracy: 0.6784 - 417ms/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "108/108 - 0s - loss: 1.0501 - accuracy: 0.6540 - val_loss: 0.9596 - val_accuracy: 0.6808 - 435ms/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "108/108 - 0s - loss: 1.0447 - accuracy: 0.6563 - val_loss: 0.9512 - val_accuracy: 0.6814 - 445ms/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "108/108 - 0s - loss: 1.0384 - accuracy: 0.6587 - val_loss: 0.9459 - val_accuracy: 0.6852 - 436ms/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "108/108 - 0s - loss: 1.0331 - accuracy: 0.6603 - val_loss: 0.9411 - val_accuracy: 0.6856 - 423ms/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "108/108 - 0s - loss: 1.0283 - accuracy: 0.6626 - val_loss: 0.9376 - val_accuracy: 0.6852 - 415ms/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "108/108 - 0s - loss: 1.0234 - accuracy: 0.6643 - val_loss: 0.9313 - val_accuracy: 0.6882 - 433ms/epoch - 4ms/step\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.9602 - accuracy: 0.6785\n"
     ]
    }
   ],
   "source": [
    "pruned, model_hp1, model_ep1 = pruning_tool_MLP_v4_1.pruning_MLP(baselineModel, x_train, y_train, x_val, y_val, x_test, y_test, batch_size=512, morph_epochs=20, mlp_epochs=30, mlp_epochs_refit=30, p=20, optimizer_config=tf.optimizers.serialize(optimizer), extreme=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineModel = tf.keras.models.load_model('../models/paper/MLP_MNIST_300_100_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training morphological model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min (SoftMaxMin)   (55000, 300)              235200    \n",
      "                                                                 \n",
      " dense (Dense)               (55000, 10)               3000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238200 (930.47 KB)\n",
      "Trainable params: 238200 (930.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 10:52:32.197775: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x24581680 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-05 10:52:32.197846: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P40, Compute Capability 6.1\n",
      "2023-12-05 10:52:32.197862: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla P40, Compute Capability 6.1\n",
      "2023-12-05 10:52:32.214013: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-05 10:52:32.684701: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2023-12-05 10:52:32.801368: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-05 10:52:33.002769: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 - 12s - loss: 0.8523 - accuracy: 0.7648 - val_loss: 0.2679 - val_accuracy: 0.9310 - 12s/epoch - 7ms/step\n",
      "Epoch 2/30\n",
      "1719/1719 - 8s - loss: 0.2856 - accuracy: 0.9174 - val_loss: 0.1912 - val_accuracy: 0.9492 - 8s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1719/1719 - 8s - loss: 0.2213 - accuracy: 0.9361 - val_loss: 0.1539 - val_accuracy: 0.9562 - 8s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1719/1719 - 8s - loss: 0.1855 - accuracy: 0.9466 - val_loss: 0.1408 - val_accuracy: 0.9632 - 8s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1719/1719 - 8s - loss: 0.1621 - accuracy: 0.9536 - val_loss: 0.1293 - val_accuracy: 0.9656 - 8s/epoch - 5ms/step\n",
      "Epoch 6/30\n",
      "1719/1719 - 8s - loss: 0.1459 - accuracy: 0.9580 - val_loss: 0.1203 - val_accuracy: 0.9686 - 8s/epoch - 5ms/step\n",
      "Epoch 7/30\n",
      "1719/1719 - 8s - loss: 0.1332 - accuracy: 0.9612 - val_loss: 0.1047 - val_accuracy: 0.9718 - 8s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1719/1719 - 8s - loss: 0.1221 - accuracy: 0.9651 - val_loss: 0.0998 - val_accuracy: 0.9760 - 8s/epoch - 5ms/step\n",
      "Epoch 9/30\n",
      "1719/1719 - 8s - loss: 0.1127 - accuracy: 0.9680 - val_loss: 0.0941 - val_accuracy: 0.9750 - 8s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1719/1719 - 8s - loss: 0.1043 - accuracy: 0.9702 - val_loss: 0.0958 - val_accuracy: 0.9754 - 8s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1719/1719 - 8s - loss: 0.0984 - accuracy: 0.9724 - val_loss: 0.0917 - val_accuracy: 0.9746 - 8s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1719/1719 - 8s - loss: 0.0924 - accuracy: 0.9737 - val_loss: 0.0835 - val_accuracy: 0.9766 - 8s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1719/1719 - 8s - loss: 0.0882 - accuracy: 0.9751 - val_loss: 0.0890 - val_accuracy: 0.9758 - 8s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1719/1719 - 8s - loss: 0.0826 - accuracy: 0.9773 - val_loss: 0.0843 - val_accuracy: 0.9772 - 8s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1719/1719 - 8s - loss: 0.0790 - accuracy: 0.9773 - val_loss: 0.0877 - val_accuracy: 0.9738 - 8s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1719/1719 - 8s - loss: 0.0749 - accuracy: 0.9788 - val_loss: 0.0778 - val_accuracy: 0.9782 - 8s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "1719/1719 - 7s - loss: 0.0716 - accuracy: 0.9799 - val_loss: 0.0799 - val_accuracy: 0.9778 - 7s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1719/1719 - 7s - loss: 0.0684 - accuracy: 0.9810 - val_loss: 0.0800 - val_accuracy: 0.9760 - 7s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1719/1719 - 8s - loss: 0.0659 - accuracy: 0.9811 - val_loss: 0.0713 - val_accuracy: 0.9796 - 8s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "1719/1719 - 8s - loss: 0.0628 - accuracy: 0.9826 - val_loss: 0.0741 - val_accuracy: 0.9806 - 8s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1719/1719 - 8s - loss: 0.0605 - accuracy: 0.9831 - val_loss: 0.0726 - val_accuracy: 0.9802 - 8s/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "1719/1719 - 8s - loss: 0.0583 - accuracy: 0.9839 - val_loss: 0.0714 - val_accuracy: 0.9808 - 8s/epoch - 5ms/step\n",
      "Epoch 23/30\n",
      "1719/1719 - 8s - loss: 0.0554 - accuracy: 0.9842 - val_loss: 0.0719 - val_accuracy: 0.9800 - 8s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1719/1719 - 8s - loss: 0.0534 - accuracy: 0.9854 - val_loss: 0.0740 - val_accuracy: 0.9808 - 8s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1719/1719 - 8s - loss: 0.0519 - accuracy: 0.9863 - val_loss: 0.0716 - val_accuracy: 0.9804 - 8s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1719/1719 - 8s - loss: 0.0499 - accuracy: 0.9865 - val_loss: 0.0777 - val_accuracy: 0.9778 - 8s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1719/1719 - 8s - loss: 0.0482 - accuracy: 0.9871 - val_loss: 0.0728 - val_accuracy: 0.9786 - 8s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1719/1719 - 8s - loss: 0.0464 - accuracy: 0.9875 - val_loss: 0.0764 - val_accuracy: 0.9798 - 8s/epoch - 5ms/step\n",
      "Epoch 29/30\n",
      "1719/1719 - 8s - loss: 0.0451 - accuracy: 0.9881 - val_loss: 0.0745 - val_accuracy: 0.9772 - 8s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "1719/1719 - 8s - loss: 0.0429 - accuracy: 0.9887 - val_loss: 0.0672 - val_accuracy: 0.9810 - 8s/epoch - 4ms/step\n",
      "Pruning morphological model...\n",
      "\n",
      "Baseline test accuracy: \n",
      "20/20 [==============================] - 1s 25ms/step - loss: 0.0804 - accuracy: 0.9753\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 238200\n",
      "Weights that can be pruned: 233785\n",
      "Left parameters: 4415\n",
      "Unactive neurons: 0\n",
      "Parameter reduction of the model: 98%\n",
      "Parameter reduction of the morph layers: 99%\n",
      "\n",
      "Extreme pruned model with a TEP threshold of 5% . Test acuraccy\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1559 - accuracy: 0.9508\n",
      "Retraining MLP dense model...\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-05 10:58:09.626699: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. sequential/modelLayer_1_0/dropout/random_uniform/RandomUniform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 5s 29ms/step - loss: 1.0346 - accuracy: 0.7053 - val_loss: 0.3679 - val_accuracy: 0.9084\n",
      "Epoch 2/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8739 - val_loss: 0.2543 - val_accuracy: 0.9322\n",
      "Epoch 3/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3394 - accuracy: 0.8992 - val_loss: 0.2104 - val_accuracy: 0.9444\n",
      "Epoch 4/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2889 - accuracy: 0.9147 - val_loss: 0.1820 - val_accuracy: 0.9492\n",
      "Epoch 5/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2578 - accuracy: 0.9237 - val_loss: 0.1630 - val_accuracy: 0.9544\n",
      "Epoch 6/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2316 - accuracy: 0.9295 - val_loss: 0.1445 - val_accuracy: 0.9586\n",
      "Epoch 7/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2127 - accuracy: 0.9365 - val_loss: 0.1333 - val_accuracy: 0.9640\n",
      "Epoch 8/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1938 - accuracy: 0.9422 - val_loss: 0.1223 - val_accuracy: 0.9650\n",
      "Epoch 9/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1823 - accuracy: 0.9445 - val_loss: 0.1143 - val_accuracy: 0.9670\n",
      "Epoch 10/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1704 - accuracy: 0.9483 - val_loss: 0.1085 - val_accuracy: 0.9688\n",
      "Epoch 11/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1607 - accuracy: 0.9519 - val_loss: 0.1041 - val_accuracy: 0.9714\n",
      "Epoch 12/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1536 - accuracy: 0.9532 - val_loss: 0.1000 - val_accuracy: 0.9730\n",
      "Epoch 13/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1466 - accuracy: 0.9553 - val_loss: 0.0981 - val_accuracy: 0.9728\n",
      "Epoch 14/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1412 - accuracy: 0.9574 - val_loss: 0.0943 - val_accuracy: 0.9740\n",
      "Epoch 15/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1338 - accuracy: 0.9586 - val_loss: 0.0913 - val_accuracy: 0.9750\n",
      "Epoch 16/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1278 - accuracy: 0.9614 - val_loss: 0.0900 - val_accuracy: 0.9752\n",
      "Epoch 17/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1218 - accuracy: 0.9627 - val_loss: 0.0853 - val_accuracy: 0.9762\n",
      "Epoch 18/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1202 - accuracy: 0.9625 - val_loss: 0.0835 - val_accuracy: 0.9776\n",
      "Epoch 19/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1124 - accuracy: 0.9659 - val_loss: 0.0797 - val_accuracy: 0.9782\n",
      "Epoch 20/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1101 - accuracy: 0.9662 - val_loss: 0.0809 - val_accuracy: 0.9778\n",
      "Epoch 21/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1070 - accuracy: 0.9670 - val_loss: 0.0773 - val_accuracy: 0.9780\n",
      "Epoch 22/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1030 - accuracy: 0.9680 - val_loss: 0.0783 - val_accuracy: 0.9786\n",
      "Epoch 23/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0994 - accuracy: 0.9691 - val_loss: 0.0755 - val_accuracy: 0.9782\n",
      "Epoch 24/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0977 - accuracy: 0.9691 - val_loss: 0.0753 - val_accuracy: 0.9788\n",
      "Epoch 25/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0944 - accuracy: 0.9706 - val_loss: 0.0744 - val_accuracy: 0.9800\n",
      "Epoch 26/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0920 - accuracy: 0.9709 - val_loss: 0.0735 - val_accuracy: 0.9780\n",
      "Epoch 27/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0887 - accuracy: 0.9722 - val_loss: 0.0727 - val_accuracy: 0.9786\n",
      "Epoch 28/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0871 - accuracy: 0.9725 - val_loss: 0.0715 - val_accuracy: 0.9800\n",
      "Epoch 29/30\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0855 - accuracy: 0.9734 - val_loss: 0.0725 - val_accuracy: 0.9794\n",
      "Epoch 30/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0828 - accuracy: 0.9739 - val_loss: 0.0728 - val_accuracy: 0.9802\n",
      "Training morphological model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min (SoftMaxMin)   (55000, 100)              30000     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (55000, 10)               1000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31000 (121.09 KB)\n",
      "Trainable params: 31000 (121.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1719/1719 - 10s - loss: 1.2284 - accuracy: 0.6894 - val_loss: 0.6466 - val_accuracy: 0.8730 - 10s/epoch - 6ms/step\n",
      "Epoch 2/30\n",
      "1719/1719 - 7s - loss: 0.6022 - accuracy: 0.8620 - val_loss: 0.4356 - val_accuracy: 0.9140 - 7s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1719/1719 - 7s - loss: 0.4652 - accuracy: 0.8886 - val_loss: 0.3523 - val_accuracy: 0.9286 - 7s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1719/1719 - 7s - loss: 0.3973 - accuracy: 0.9004 - val_loss: 0.3031 - val_accuracy: 0.9336 - 7s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1719/1719 - 7s - loss: 0.3550 - accuracy: 0.9092 - val_loss: 0.2745 - val_accuracy: 0.9394 - 7s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1719/1719 - 7s - loss: 0.3268 - accuracy: 0.9140 - val_loss: 0.2525 - val_accuracy: 0.9458 - 7s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1719/1719 - 7s - loss: 0.3060 - accuracy: 0.9193 - val_loss: 0.2530 - val_accuracy: 0.9396 - 7s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1719/1719 - 7s - loss: 0.2892 - accuracy: 0.9230 - val_loss: 0.2225 - val_accuracy: 0.9518 - 7s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1719/1719 - 7s - loss: 0.2760 - accuracy: 0.9260 - val_loss: 0.2125 - val_accuracy: 0.9500 - 7s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1719/1719 - 7s - loss: 0.2642 - accuracy: 0.9291 - val_loss: 0.2042 - val_accuracy: 0.9528 - 7s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1719/1719 - 7s - loss: 0.2541 - accuracy: 0.9317 - val_loss: 0.2012 - val_accuracy: 0.9526 - 7s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1719/1719 - 7s - loss: 0.2455 - accuracy: 0.9333 - val_loss: 0.1945 - val_accuracy: 0.9548 - 7s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1719/1719 - 7s - loss: 0.2381 - accuracy: 0.9353 - val_loss: 0.1893 - val_accuracy: 0.9550 - 7s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1719/1719 - 7s - loss: 0.2316 - accuracy: 0.9367 - val_loss: 0.1815 - val_accuracy: 0.9544 - 7s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1719/1719 - 7s - loss: 0.2251 - accuracy: 0.9384 - val_loss: 0.1771 - val_accuracy: 0.9556 - 7s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1719/1719 - 7s - loss: 0.2189 - accuracy: 0.9409 - val_loss: 0.1704 - val_accuracy: 0.9558 - 7s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "1719/1719 - 7s - loss: 0.2139 - accuracy: 0.9419 - val_loss: 0.1676 - val_accuracy: 0.9586 - 7s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1719/1719 - 7s - loss: 0.2093 - accuracy: 0.9423 - val_loss: 0.1663 - val_accuracy: 0.9580 - 7s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1719/1719 - 7s - loss: 0.2049 - accuracy: 0.9435 - val_loss: 0.1631 - val_accuracy: 0.9578 - 7s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "1719/1719 - 7s - loss: 0.2014 - accuracy: 0.9435 - val_loss: 0.1594 - val_accuracy: 0.9602 - 7s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1719/1719 - 7s - loss: 0.1973 - accuracy: 0.9454 - val_loss: 0.1565 - val_accuracy: 0.9580 - 7s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1719/1719 - 7s - loss: 0.1941 - accuracy: 0.9463 - val_loss: 0.1564 - val_accuracy: 0.9602 - 7s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1719/1719 - 7s - loss: 0.1909 - accuracy: 0.9466 - val_loss: 0.1519 - val_accuracy: 0.9614 - 7s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1719/1719 - 7s - loss: 0.1878 - accuracy: 0.9475 - val_loss: 0.1493 - val_accuracy: 0.9624 - 7s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1719/1719 - 7s - loss: 0.1856 - accuracy: 0.9483 - val_loss: 0.1484 - val_accuracy: 0.9612 - 7s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1719/1719 - 7s - loss: 0.1825 - accuracy: 0.9490 - val_loss: 0.1488 - val_accuracy: 0.9618 - 7s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1719/1719 - 7s - loss: 0.1802 - accuracy: 0.9491 - val_loss: 0.1442 - val_accuracy: 0.9610 - 7s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1719/1719 - 7s - loss: 0.1781 - accuracy: 0.9503 - val_loss: 0.1445 - val_accuracy: 0.9612 - 7s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "1719/1719 - 7s - loss: 0.1755 - accuracy: 0.9507 - val_loss: 0.1456 - val_accuracy: 0.9622 - 7s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "1719/1719 - 7s - loss: 0.1735 - accuracy: 0.9511 - val_loss: 0.1394 - val_accuracy: 0.9632 - 7s/epoch - 4ms/step\n",
      "Pruning morphological model...\n",
      "\n",
      "Baseline test accuracy: \n",
      "20/20 [==============================] - 1s 17ms/step - loss: 0.1730 - accuracy: 0.9496\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 31000\n",
      "Weights that can be pruned: 29597\n",
      "Left parameters: 1403\n",
      "Unactive neurons: 0\n",
      "Parameter reduction of the model: 95%\n",
      "Parameter reduction of the morph layers: 98%\n",
      "\n",
      "Extreme pruned model with a TEP threshold of 5% . Test acuraccy\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1918 - accuracy: 0.9423\n",
      "Retraining MLP dense model...\n",
      "Epoch 1/30\n",
      "108/108 [==============================] - 4s 24ms/step - loss: 1.7854 - accuracy: 0.4943 - val_loss: 1.2455 - val_accuracy: 0.8010\n",
      "Epoch 2/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 1.0426 - accuracy: 0.7404 - val_loss: 0.6317 - val_accuracy: 0.8744\n",
      "Epoch 3/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7066 - accuracy: 0.8015 - val_loss: 0.4331 - val_accuracy: 0.8994\n",
      "Epoch 4/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5753 - accuracy: 0.8315 - val_loss: 0.3494 - val_accuracy: 0.9124\n",
      "Epoch 5/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.8473 - val_loss: 0.3048 - val_accuracy: 0.9224\n",
      "Epoch 6/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4670 - accuracy: 0.8593 - val_loss: 0.2747 - val_accuracy: 0.9270\n",
      "Epoch 7/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8703 - val_loss: 0.2524 - val_accuracy: 0.9326\n",
      "Epoch 8/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4094 - accuracy: 0.8770 - val_loss: 0.2346 - val_accuracy: 0.9370\n",
      "Epoch 9/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3916 - accuracy: 0.8814 - val_loss: 0.2228 - val_accuracy: 0.9392\n",
      "Epoch 10/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3725 - accuracy: 0.8887 - val_loss: 0.2112 - val_accuracy: 0.9416\n",
      "Epoch 11/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3569 - accuracy: 0.8929 - val_loss: 0.2008 - val_accuracy: 0.9432\n",
      "Epoch 12/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3453 - accuracy: 0.8949 - val_loss: 0.1929 - val_accuracy: 0.9440\n",
      "Epoch 13/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3356 - accuracy: 0.8987 - val_loss: 0.1879 - val_accuracy: 0.9454\n",
      "Epoch 14/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3276 - accuracy: 0.9004 - val_loss: 0.1811 - val_accuracy: 0.9488\n",
      "Epoch 15/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3187 - accuracy: 0.9040 - val_loss: 0.1752 - val_accuracy: 0.9490\n",
      "Epoch 16/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3112 - accuracy: 0.9058 - val_loss: 0.1704 - val_accuracy: 0.9504\n",
      "Epoch 17/30\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3045 - accuracy: 0.9080 - val_loss: 0.1668 - val_accuracy: 0.9514\n",
      "Epoch 18/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2997 - accuracy: 0.9088 - val_loss: 0.1627 - val_accuracy: 0.9530\n",
      "Epoch 19/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2929 - accuracy: 0.9109 - val_loss: 0.1588 - val_accuracy: 0.9538\n",
      "Epoch 20/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2918 - accuracy: 0.9110 - val_loss: 0.1577 - val_accuracy: 0.9528\n",
      "Epoch 21/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2846 - accuracy: 0.9131 - val_loss: 0.1554 - val_accuracy: 0.9532\n",
      "Epoch 22/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2814 - accuracy: 0.9139 - val_loss: 0.1516 - val_accuracy: 0.9548\n",
      "Epoch 23/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2769 - accuracy: 0.9157 - val_loss: 0.1498 - val_accuracy: 0.9550\n",
      "Epoch 24/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2730 - accuracy: 0.9172 - val_loss: 0.1480 - val_accuracy: 0.9552\n",
      "Epoch 25/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2690 - accuracy: 0.9176 - val_loss: 0.1457 - val_accuracy: 0.9574\n",
      "Epoch 26/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2682 - accuracy: 0.9185 - val_loss: 0.1448 - val_accuracy: 0.9572\n",
      "Epoch 27/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2627 - accuracy: 0.9198 - val_loss: 0.1437 - val_accuracy: 0.9580\n",
      "Epoch 28/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2597 - accuracy: 0.9193 - val_loss: 0.1414 - val_accuracy: 0.9586\n",
      "Epoch 29/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2575 - accuracy: 0.9214 - val_loss: 0.1400 - val_accuracy: 0.9594\n",
      "Epoch 30/30\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2543 - accuracy: 0.9227 - val_loss: 0.1373 - val_accuracy: 0.9602\n",
      "Retraining MLP model...\n",
      "Epoch 1/30\n",
      "108/108 - 1s - loss: 0.2527 - accuracy: 0.9219 - val_loss: 0.1376 - val_accuracy: 0.9598 - 515ms/epoch - 5ms/step\n",
      "Epoch 2/30\n",
      "108/108 - 0s - loss: 0.2513 - accuracy: 0.9235 - val_loss: 0.1369 - val_accuracy: 0.9602 - 429ms/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "108/108 - 0s - loss: 0.2493 - accuracy: 0.9235 - val_loss: 0.1356 - val_accuracy: 0.9596 - 430ms/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "108/108 - 0s - loss: 0.2471 - accuracy: 0.9254 - val_loss: 0.1335 - val_accuracy: 0.9608 - 435ms/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "108/108 - 0s - loss: 0.2440 - accuracy: 0.9248 - val_loss: 0.1333 - val_accuracy: 0.9608 - 437ms/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "108/108 - 0s - loss: 0.2430 - accuracy: 0.9252 - val_loss: 0.1309 - val_accuracy: 0.9620 - 437ms/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "108/108 - 0s - loss: 0.2423 - accuracy: 0.9267 - val_loss: 0.1304 - val_accuracy: 0.9616 - 470ms/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "108/108 - 0s - loss: 0.2393 - accuracy: 0.9277 - val_loss: 0.1317 - val_accuracy: 0.9626 - 460ms/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "108/108 - 0s - loss: 0.2357 - accuracy: 0.9275 - val_loss: 0.1308 - val_accuracy: 0.9630 - 458ms/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "108/108 - 0s - loss: 0.2366 - accuracy: 0.9269 - val_loss: 0.1296 - val_accuracy: 0.9626 - 411ms/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "108/108 - 0s - loss: 0.2346 - accuracy: 0.9279 - val_loss: 0.1283 - val_accuracy: 0.9630 - 426ms/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "108/108 - 0s - loss: 0.2339 - accuracy: 0.9288 - val_loss: 0.1272 - val_accuracy: 0.9626 - 421ms/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "108/108 - 0s - loss: 0.2308 - accuracy: 0.9293 - val_loss: 0.1264 - val_accuracy: 0.9648 - 423ms/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "108/108 - 0s - loss: 0.2328 - accuracy: 0.9294 - val_loss: 0.1265 - val_accuracy: 0.9618 - 420ms/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "108/108 - 0s - loss: 0.2305 - accuracy: 0.9295 - val_loss: 0.1256 - val_accuracy: 0.9642 - 417ms/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "108/108 - 0s - loss: 0.2303 - accuracy: 0.9293 - val_loss: 0.1248 - val_accuracy: 0.9632 - 430ms/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "108/108 - 0s - loss: 0.2257 - accuracy: 0.9313 - val_loss: 0.1238 - val_accuracy: 0.9628 - 404ms/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "108/108 - 0s - loss: 0.2275 - accuracy: 0.9310 - val_loss: 0.1243 - val_accuracy: 0.9632 - 406ms/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "108/108 - 0s - loss: 0.2250 - accuracy: 0.9314 - val_loss: 0.1226 - val_accuracy: 0.9648 - 442ms/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "108/108 - 0s - loss: 0.2249 - accuracy: 0.9321 - val_loss: 0.1222 - val_accuracy: 0.9632 - 434ms/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "108/108 - 0s - loss: 0.2215 - accuracy: 0.9324 - val_loss: 0.1221 - val_accuracy: 0.9640 - 421ms/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "108/108 - 0s - loss: 0.2252 - accuracy: 0.9311 - val_loss: 0.1223 - val_accuracy: 0.9630 - 422ms/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "108/108 - 0s - loss: 0.2234 - accuracy: 0.9322 - val_loss: 0.1220 - val_accuracy: 0.9632 - 490ms/epoch - 5ms/step\n",
      "Epoch 24/30\n",
      "108/108 - 0s - loss: 0.2209 - accuracy: 0.9327 - val_loss: 0.1197 - val_accuracy: 0.9656 - 468ms/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "108/108 - 0s - loss: 0.2197 - accuracy: 0.9334 - val_loss: 0.1201 - val_accuracy: 0.9640 - 439ms/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "108/108 - 0s - loss: 0.2203 - accuracy: 0.9317 - val_loss: 0.1199 - val_accuracy: 0.9644 - 445ms/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "108/108 - 0s - loss: 0.2215 - accuracy: 0.9320 - val_loss: 0.1195 - val_accuracy: 0.9650 - 434ms/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "108/108 - 0s - loss: 0.2185 - accuracy: 0.9331 - val_loss: 0.1190 - val_accuracy: 0.9662 - 420ms/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "108/108 - 0s - loss: 0.2172 - accuracy: 0.9332 - val_loss: 0.1193 - val_accuracy: 0.9656 - 417ms/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "108/108 - 0s - loss: 0.2160 - accuracy: 0.9335 - val_loss: 0.1183 - val_accuracy: 0.9660 - 417ms/epoch - 4ms/step\n",
      "Accuracy of the MLP model:\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.1452 - accuracy: 0.9563\n",
      "# Parameters of the model: 266610\n",
      "# Parameters pruned: 263382\n",
      "Remaining weights (%): 1.2107572859232587\n"
     ]
    }
   ],
   "source": [
    "pruned, model_hp1, model_ep1 = pruning_tool_MLP_v4_1.pruning_MLP(baselineModel, x_train, y_train, x_val, y_val, x_test, y_test, batch_size=512, morph_epochs=30, mlp_epochs=30, mlp_epochs_refit=30, p=5, optimizer_config=tf.optimizers.serialize(optimizer), extreme=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros mdoelo sin prunar: 266610\n",
      "Parámetros mdoelo prunado: 3222\n",
      "Pesos restantes: 1.2085068076966357%\n"
     ]
    }
   ],
   "source": [
    "w0 = pruned.layers[0].get_weights()[0]\n",
    "w1 = pruned.layers[2].get_weights()[0]\n",
    "params_prunedModel = pruned.count_params() - (w0.size - np.count_nonzero(w0) + w1.size - np.count_nonzero(w1))\n",
    "print(\"Parámetros mdoelo sin prunar: \" + str(pruned.count_params()))\n",
    "print(\"Parámetros mdoelo prunado: \" + str(params_prunedModel))\n",
    "print(\"Pesos restantes: \" + str(params_prunedModel/pruned.count_params()*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p=3 MNIST 300-100 v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineModel = tf.keras.models.load_model('../models/paper/MLP_MNIST_300_100_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training morphological model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min (SoftMaxMin)   (55000, 300)              235200    \n",
      "                                                                 \n",
      " dense (Dense)               (55000, 10)               3000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238200 (930.47 KB)\n",
      "Trainable params: 238200 (930.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 13:58:01.795404: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f8c1297a230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-12-11 13:58:01.795462: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P40, Compute Capability 6.1\n",
      "2023-12-11 13:58:01.795488: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (1): Tesla P40, Compute Capability 6.1\n",
      "2023-12-11 13:58:01.811675: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-12-11 13:58:02.025434: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8902\n",
      "2023-12-11 13:58:02.145155: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-12-11 13:58:02.344486: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 - 12s - loss: 0.8409 - accuracy: 0.7654 - val_loss: 0.2663 - val_accuracy: 0.9266 - 12s/epoch - 7ms/step\n",
      "Epoch 2/30\n",
      "1719/1719 - 8s - loss: 0.2852 - accuracy: 0.9170 - val_loss: 0.1874 - val_accuracy: 0.9466 - 8s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1719/1719 - 8s - loss: 0.2187 - accuracy: 0.9373 - val_loss: 0.1538 - val_accuracy: 0.9576 - 8s/epoch - 5ms/step\n",
      "Epoch 4/30\n",
      "1719/1719 - 8s - loss: 0.1839 - accuracy: 0.9477 - val_loss: 0.1414 - val_accuracy: 0.9596 - 8s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1719/1719 - 8s - loss: 0.1612 - accuracy: 0.9540 - val_loss: 0.1241 - val_accuracy: 0.9674 - 8s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1719/1719 - 8s - loss: 0.1436 - accuracy: 0.9594 - val_loss: 0.1130 - val_accuracy: 0.9696 - 8s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1719/1719 - 8s - loss: 0.1308 - accuracy: 0.9623 - val_loss: 0.1075 - val_accuracy: 0.9714 - 8s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1719/1719 - 8s - loss: 0.1201 - accuracy: 0.9662 - val_loss: 0.1013 - val_accuracy: 0.9736 - 8s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1719/1719 - 8s - loss: 0.1113 - accuracy: 0.9679 - val_loss: 0.0916 - val_accuracy: 0.9766 - 8s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1719/1719 - 8s - loss: 0.1032 - accuracy: 0.9701 - val_loss: 0.0935 - val_accuracy: 0.9748 - 8s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1719/1719 - 8s - loss: 0.0973 - accuracy: 0.9725 - val_loss: 0.0929 - val_accuracy: 0.9744 - 8s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1719/1719 - 8s - loss: 0.0917 - accuracy: 0.9741 - val_loss: 0.0842 - val_accuracy: 0.9760 - 8s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1719/1719 - 8s - loss: 0.0868 - accuracy: 0.9759 - val_loss: 0.0843 - val_accuracy: 0.9768 - 8s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1719/1719 - 8s - loss: 0.0815 - accuracy: 0.9774 - val_loss: 0.0877 - val_accuracy: 0.9752 - 8s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1719/1719 - 8s - loss: 0.0773 - accuracy: 0.9783 - val_loss: 0.0857 - val_accuracy: 0.9762 - 8s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1719/1719 - 8s - loss: 0.0744 - accuracy: 0.9787 - val_loss: 0.0752 - val_accuracy: 0.9794 - 8s/epoch - 5ms/step\n",
      "Epoch 17/30\n",
      "1719/1719 - 8s - loss: 0.0708 - accuracy: 0.9801 - val_loss: 0.0779 - val_accuracy: 0.9786 - 8s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1719/1719 - 8s - loss: 0.0679 - accuracy: 0.9809 - val_loss: 0.0754 - val_accuracy: 0.9800 - 8s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1719/1719 - 8s - loss: 0.0648 - accuracy: 0.9816 - val_loss: 0.0714 - val_accuracy: 0.9792 - 8s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "1719/1719 - 8s - loss: 0.0625 - accuracy: 0.9823 - val_loss: 0.0722 - val_accuracy: 0.9798 - 8s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1719/1719 - 8s - loss: 0.0598 - accuracy: 0.9836 - val_loss: 0.0761 - val_accuracy: 0.9790 - 8s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1719/1719 - 8s - loss: 0.0566 - accuracy: 0.9845 - val_loss: 0.0761 - val_accuracy: 0.9780 - 8s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1719/1719 - 8s - loss: 0.0553 - accuracy: 0.9853 - val_loss: 0.0687 - val_accuracy: 0.9828 - 8s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1719/1719 - 8s - loss: 0.0525 - accuracy: 0.9855 - val_loss: 0.0722 - val_accuracy: 0.9786 - 8s/epoch - 5ms/step\n",
      "Epoch 25/30\n",
      "1719/1719 - 8s - loss: 0.0515 - accuracy: 0.9855 - val_loss: 0.0757 - val_accuracy: 0.9782 - 8s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1719/1719 - 8s - loss: 0.0496 - accuracy: 0.9869 - val_loss: 0.0729 - val_accuracy: 0.9800 - 8s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1719/1719 - 8s - loss: 0.0475 - accuracy: 0.9868 - val_loss: 0.0747 - val_accuracy: 0.9788 - 8s/epoch - 5ms/step\n",
      "Epoch 28/30\n",
      "1719/1719 - 8s - loss: 0.0459 - accuracy: 0.9876 - val_loss: 0.0715 - val_accuracy: 0.9792 - 8s/epoch - 5ms/step\n",
      "Epoch 29/30\n",
      "1719/1719 - 8s - loss: 0.0447 - accuracy: 0.9879 - val_loss: 0.0758 - val_accuracy: 0.9800 - 8s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "1719/1719 - 8s - loss: 0.0426 - accuracy: 0.9885 - val_loss: 0.0665 - val_accuracy: 0.9824 - 8s/epoch - 4ms/step\n",
      "Pruning morphological model...\n",
      "\n",
      "Baseline test accuracy: \n",
      "20/20 [==============================] - 1s 25ms/step - loss: 0.0751 - accuracy: 0.9767\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 238200\n",
      "Weights that can be pruned: 233148\n",
      "Left parameters: 5052\n",
      "Unactive neurons: 0\n",
      "Parameter reduction of the model: 97%\n",
      "Parameter reduction of the morph layers: 99%\n",
      "\n",
      "Extreme pruned model with a TEP threshold of 3% . Test acuraccy\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.1209 - accuracy: 0.9629\n",
      "Retraining MLP dense model...\n",
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-11 14:03:39.852408: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. sequential/modelLayer_1_0/dropout/random_uniform/RandomUniform\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "108/108 [==============================] - 5s 28ms/step - loss: 0.8856 - accuracy: 0.7576 - val_loss: 0.3109 - val_accuracy: 0.9140\n",
      "Epoch 2/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3777 - accuracy: 0.8882 - val_loss: 0.2204 - val_accuracy: 0.9390\n",
      "Epoch 3/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3014 - accuracy: 0.9110 - val_loss: 0.1828 - val_accuracy: 0.9510\n",
      "Epoch 4/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2569 - accuracy: 0.9232 - val_loss: 0.1563 - val_accuracy: 0.9564\n",
      "Epoch 5/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2255 - accuracy: 0.9335 - val_loss: 0.1402 - val_accuracy: 0.9614\n",
      "Epoch 6/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2033 - accuracy: 0.9389 - val_loss: 0.1234 - val_accuracy: 0.9674\n",
      "Epoch 7/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1853 - accuracy: 0.9444 - val_loss: 0.1146 - val_accuracy: 0.9706\n",
      "Epoch 8/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1721 - accuracy: 0.9489 - val_loss: 0.1067 - val_accuracy: 0.9722\n",
      "Epoch 9/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1580 - accuracy: 0.9526 - val_loss: 0.1015 - val_accuracy: 0.9730\n",
      "Epoch 10/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1498 - accuracy: 0.9549 - val_loss: 0.0958 - val_accuracy: 0.9758\n",
      "Epoch 11/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1420 - accuracy: 0.9565 - val_loss: 0.0909 - val_accuracy: 0.9772\n",
      "Epoch 12/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.9599 - val_loss: 0.0877 - val_accuracy: 0.9784\n",
      "Epoch 13/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1250 - accuracy: 0.9625 - val_loss: 0.0836 - val_accuracy: 0.9782\n",
      "Epoch 14/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1187 - accuracy: 0.9636 - val_loss: 0.0825 - val_accuracy: 0.9790\n",
      "Epoch 15/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1151 - accuracy: 0.9655 - val_loss: 0.0807 - val_accuracy: 0.9796\n",
      "Epoch 16/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1101 - accuracy: 0.9659 - val_loss: 0.0777 - val_accuracy: 0.9804\n",
      "Epoch 17/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.9673 - val_loss: 0.0766 - val_accuracy: 0.9812\n",
      "Epoch 18/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1023 - accuracy: 0.9687 - val_loss: 0.0746 - val_accuracy: 0.9814\n",
      "Epoch 19/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0983 - accuracy: 0.9692 - val_loss: 0.0734 - val_accuracy: 0.9824\n",
      "Epoch 20/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0937 - accuracy: 0.9706 - val_loss: 0.0725 - val_accuracy: 0.9814\n",
      "Epoch 21/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0911 - accuracy: 0.9718 - val_loss: 0.0706 - val_accuracy: 0.9816\n",
      "Epoch 22/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0884 - accuracy: 0.9726 - val_loss: 0.0712 - val_accuracy: 0.9816\n",
      "Epoch 23/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9733 - val_loss: 0.0693 - val_accuracy: 0.9820\n",
      "Epoch 24/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0835 - accuracy: 0.9737 - val_loss: 0.0679 - val_accuracy: 0.9830\n",
      "Epoch 25/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.9747 - val_loss: 0.0660 - val_accuracy: 0.9840\n",
      "Epoch 26/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0766 - accuracy: 0.9758 - val_loss: 0.0662 - val_accuracy: 0.9838\n",
      "Epoch 27/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0754 - accuracy: 0.9768 - val_loss: 0.0647 - val_accuracy: 0.9828\n",
      "Epoch 28/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0728 - accuracy: 0.9771 - val_loss: 0.0653 - val_accuracy: 0.9828\n",
      "Epoch 29/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0722 - accuracy: 0.9771 - val_loss: 0.0644 - val_accuracy: 0.9832\n",
      "Epoch 30/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9782 - val_loss: 0.0660 - val_accuracy: 0.9826\n",
      "Epoch 31/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0679 - accuracy: 0.9784 - val_loss: 0.0640 - val_accuracy: 0.9826\n",
      "Epoch 32/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9791 - val_loss: 0.0601 - val_accuracy: 0.9850\n",
      "Epoch 33/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0631 - accuracy: 0.9799 - val_loss: 0.0611 - val_accuracy: 0.9840\n",
      "Epoch 34/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.9806 - val_loss: 0.0597 - val_accuracy: 0.9828\n",
      "Epoch 35/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0610 - accuracy: 0.9803 - val_loss: 0.0608 - val_accuracy: 0.9842\n",
      "Epoch 36/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.9810 - val_loss: 0.0602 - val_accuracy: 0.9842\n",
      "Epoch 37/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9806 - val_loss: 0.0598 - val_accuracy: 0.9836\n",
      "Epoch 38/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9819 - val_loss: 0.0603 - val_accuracy: 0.9838\n",
      "Epoch 39/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9826 - val_loss: 0.0601 - val_accuracy: 0.9840\n",
      "Epoch 40/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0540 - accuracy: 0.9827 - val_loss: 0.0634 - val_accuracy: 0.9832\n",
      "Training morphological model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min (SoftMaxMin)   (55000, 100)              30000     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (55000, 10)               1000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31000 (121.09 KB)\n",
      "Trainable params: 31000 (121.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1719/1719 - 11s - loss: 1.1424 - accuracy: 0.7252 - val_loss: 0.5570 - val_accuracy: 0.8924 - 11s/epoch - 6ms/step\n",
      "Epoch 2/30\n",
      "1719/1719 - 7s - loss: 0.5318 - accuracy: 0.8770 - val_loss: 0.3790 - val_accuracy: 0.9164 - 7s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1719/1719 - 7s - loss: 0.4111 - accuracy: 0.9003 - val_loss: 0.3086 - val_accuracy: 0.9312 - 7s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1719/1719 - 7s - loss: 0.3499 - accuracy: 0.9143 - val_loss: 0.2663 - val_accuracy: 0.9398 - 7s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1719/1719 - 7s - loss: 0.3117 - accuracy: 0.9219 - val_loss: 0.2360 - val_accuracy: 0.9462 - 7s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1719/1719 - 7s - loss: 0.2848 - accuracy: 0.9280 - val_loss: 0.2163 - val_accuracy: 0.9512 - 7s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1719/1719 - 7s - loss: 0.2636 - accuracy: 0.9322 - val_loss: 0.2006 - val_accuracy: 0.9542 - 7s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1719/1719 - 7s - loss: 0.2465 - accuracy: 0.9368 - val_loss: 0.1901 - val_accuracy: 0.9536 - 7s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1719/1719 - 7s - loss: 0.2336 - accuracy: 0.9386 - val_loss: 0.1777 - val_accuracy: 0.9578 - 7s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1719/1719 - 7s - loss: 0.2222 - accuracy: 0.9417 - val_loss: 0.1715 - val_accuracy: 0.9568 - 7s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1719/1719 - 7s - loss: 0.2137 - accuracy: 0.9433 - val_loss: 0.1669 - val_accuracy: 0.9598 - 7s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1719/1719 - 7s - loss: 0.2061 - accuracy: 0.9452 - val_loss: 0.1570 - val_accuracy: 0.9630 - 7s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1719/1719 - 7s - loss: 0.1991 - accuracy: 0.9468 - val_loss: 0.1533 - val_accuracy: 0.9622 - 7s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1719/1719 - 7s - loss: 0.1931 - accuracy: 0.9482 - val_loss: 0.1497 - val_accuracy: 0.9610 - 7s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1719/1719 - 7s - loss: 0.1876 - accuracy: 0.9493 - val_loss: 0.1506 - val_accuracy: 0.9620 - 7s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1719/1719 - 7s - loss: 0.1827 - accuracy: 0.9505 - val_loss: 0.1416 - val_accuracy: 0.9638 - 7s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "1719/1719 - 7s - loss: 0.1784 - accuracy: 0.9515 - val_loss: 0.1406 - val_accuracy: 0.9650 - 7s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1719/1719 - 7s - loss: 0.1743 - accuracy: 0.9527 - val_loss: 0.1378 - val_accuracy: 0.9646 - 7s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1719/1719 - 7s - loss: 0.1710 - accuracy: 0.9533 - val_loss: 0.1334 - val_accuracy: 0.9658 - 7s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "1719/1719 - 7s - loss: 0.1672 - accuracy: 0.9543 - val_loss: 0.1338 - val_accuracy: 0.9664 - 7s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1719/1719 - 7s - loss: 0.1642 - accuracy: 0.9548 - val_loss: 0.1271 - val_accuracy: 0.9670 - 7s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1719/1719 - 7s - loss: 0.1611 - accuracy: 0.9556 - val_loss: 0.1253 - val_accuracy: 0.9668 - 7s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1719/1719 - 7s - loss: 0.1583 - accuracy: 0.9561 - val_loss: 0.1244 - val_accuracy: 0.9674 - 7s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1719/1719 - 7s - loss: 0.1556 - accuracy: 0.9568 - val_loss: 0.1299 - val_accuracy: 0.9656 - 7s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1719/1719 - 7s - loss: 0.1534 - accuracy: 0.9576 - val_loss: 0.1245 - val_accuracy: 0.9678 - 7s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1719/1719 - 7s - loss: 0.1509 - accuracy: 0.9576 - val_loss: 0.1199 - val_accuracy: 0.9686 - 7s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1719/1719 - 7s - loss: 0.1489 - accuracy: 0.9583 - val_loss: 0.1207 - val_accuracy: 0.9676 - 7s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1719/1719 - 7s - loss: 0.1473 - accuracy: 0.9589 - val_loss: 0.1153 - val_accuracy: 0.9690 - 7s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "1719/1719 - 7s - loss: 0.1448 - accuracy: 0.9595 - val_loss: 0.1165 - val_accuracy: 0.9696 - 7s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "1719/1719 - 7s - loss: 0.1432 - accuracy: 0.9598 - val_loss: 0.1177 - val_accuracy: 0.9680 - 7s/epoch - 4ms/step\n",
      "Pruning morphological model...\n",
      "\n",
      "Baseline test accuracy: \n",
      "20/20 [==============================] - 1s 21ms/step - loss: 0.1450 - accuracy: 0.9588\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 31000\n",
      "Weights that can be pruned: 29447\n",
      "Left parameters: 1553\n",
      "Unactive neurons: 0\n",
      "Parameter reduction of the model: 94%\n",
      "Parameter reduction of the morph layers: 98%\n",
      "\n",
      "Extreme pruned model with a TEP threshold of 3% . Test acuraccy\n",
      "20/20 [==============================] - 0s 4ms/step - loss: 0.1566 - accuracy: 0.9540\n",
      "Retraining MLP dense model...\n",
      "Epoch 1/40\n",
      "108/108 [==============================] - 4s 22ms/step - loss: 1.5827 - accuracy: 0.5920 - val_loss: 0.9183 - val_accuracy: 0.8518\n",
      "Epoch 2/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.7966 - accuracy: 0.7908 - val_loss: 0.4459 - val_accuracy: 0.9070\n",
      "Epoch 3/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.5563 - accuracy: 0.8369 - val_loss: 0.3219 - val_accuracy: 0.9224\n",
      "Epoch 4/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4682 - accuracy: 0.8597 - val_loss: 0.2715 - val_accuracy: 0.9300\n",
      "Epoch 5/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.8743 - val_loss: 0.2420 - val_accuracy: 0.9342\n",
      "Epoch 6/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3870 - accuracy: 0.8846 - val_loss: 0.2214 - val_accuracy: 0.9398\n",
      "Epoch 7/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.8897 - val_loss: 0.2074 - val_accuracy: 0.9432\n",
      "Epoch 8/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3423 - accuracy: 0.8961 - val_loss: 0.1959 - val_accuracy: 0.9478\n",
      "Epoch 9/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3299 - accuracy: 0.9004 - val_loss: 0.1869 - val_accuracy: 0.9494\n",
      "Epoch 10/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3160 - accuracy: 0.9049 - val_loss: 0.1796 - val_accuracy: 0.9524\n",
      "Epoch 11/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3029 - accuracy: 0.9090 - val_loss: 0.1725 - val_accuracy: 0.9548\n",
      "Epoch 12/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2993 - accuracy: 0.9094 - val_loss: 0.1670 - val_accuracy: 0.9540\n",
      "Epoch 13/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2883 - accuracy: 0.9132 - val_loss: 0.1611 - val_accuracy: 0.9560\n",
      "Epoch 14/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2792 - accuracy: 0.9163 - val_loss: 0.1561 - val_accuracy: 0.9584\n",
      "Epoch 15/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2717 - accuracy: 0.9183 - val_loss: 0.1525 - val_accuracy: 0.9596\n",
      "Epoch 16/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2663 - accuracy: 0.9188 - val_loss: 0.1470 - val_accuracy: 0.9610\n",
      "Epoch 17/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2586 - accuracy: 0.9221 - val_loss: 0.1439 - val_accuracy: 0.9610\n",
      "Epoch 18/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2552 - accuracy: 0.9220 - val_loss: 0.1401 - val_accuracy: 0.9618\n",
      "Epoch 19/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2505 - accuracy: 0.9231 - val_loss: 0.1375 - val_accuracy: 0.9626\n",
      "Epoch 20/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2454 - accuracy: 0.9248 - val_loss: 0.1357 - val_accuracy: 0.9630\n",
      "Epoch 21/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2415 - accuracy: 0.9274 - val_loss: 0.1326 - val_accuracy: 0.9632\n",
      "Epoch 22/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2374 - accuracy: 0.9272 - val_loss: 0.1293 - val_accuracy: 0.9644\n",
      "Epoch 23/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2311 - accuracy: 0.9289 - val_loss: 0.1260 - val_accuracy: 0.9660\n",
      "Epoch 24/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2300 - accuracy: 0.9294 - val_loss: 0.1251 - val_accuracy: 0.9656\n",
      "Epoch 25/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2255 - accuracy: 0.9309 - val_loss: 0.1230 - val_accuracy: 0.9662\n",
      "Epoch 26/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2257 - accuracy: 0.9304 - val_loss: 0.1207 - val_accuracy: 0.9676\n",
      "Epoch 27/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2201 - accuracy: 0.9315 - val_loss: 0.1197 - val_accuracy: 0.9676\n",
      "Epoch 28/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2191 - accuracy: 0.9330 - val_loss: 0.1183 - val_accuracy: 0.9676\n",
      "Epoch 29/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2151 - accuracy: 0.9336 - val_loss: 0.1160 - val_accuracy: 0.9688\n",
      "Epoch 30/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2155 - accuracy: 0.9341 - val_loss: 0.1162 - val_accuracy: 0.9692\n",
      "Epoch 31/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2116 - accuracy: 0.9350 - val_loss: 0.1140 - val_accuracy: 0.9696\n",
      "Epoch 32/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2069 - accuracy: 0.9359 - val_loss: 0.1139 - val_accuracy: 0.9686\n",
      "Epoch 33/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2070 - accuracy: 0.9363 - val_loss: 0.1120 - val_accuracy: 0.9702\n",
      "Epoch 34/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2043 - accuracy: 0.9380 - val_loss: 0.1108 - val_accuracy: 0.9702\n",
      "Epoch 35/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2019 - accuracy: 0.9379 - val_loss: 0.1103 - val_accuracy: 0.9696\n",
      "Epoch 36/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2026 - accuracy: 0.9369 - val_loss: 0.1103 - val_accuracy: 0.9702\n",
      "Epoch 37/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1976 - accuracy: 0.9395 - val_loss: 0.1082 - val_accuracy: 0.9706\n",
      "Epoch 38/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1983 - accuracy: 0.9391 - val_loss: 0.1074 - val_accuracy: 0.9722\n",
      "Epoch 39/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1970 - accuracy: 0.9395 - val_loss: 0.1072 - val_accuracy: 0.9716\n",
      "Epoch 40/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1960 - accuracy: 0.9397 - val_loss: 0.1062 - val_accuracy: 0.9718\n",
      "Retraining MLP model...\n",
      "Epoch 1/10\n",
      "108/108 - 0s - loss: 0.1954 - accuracy: 0.9403 - val_loss: 0.1048 - val_accuracy: 0.9720 - 454ms/epoch - 4ms/step\n",
      "Epoch 2/10\n",
      "108/108 - 0s - loss: 0.1977 - accuracy: 0.9382 - val_loss: 0.1046 - val_accuracy: 0.9722 - 401ms/epoch - 4ms/step\n",
      "Epoch 3/10\n",
      "108/108 - 0s - loss: 0.1927 - accuracy: 0.9401 - val_loss: 0.1047 - val_accuracy: 0.9726 - 411ms/epoch - 4ms/step\n",
      "Epoch 4/10\n",
      "108/108 - 0s - loss: 0.1910 - accuracy: 0.9406 - val_loss: 0.1042 - val_accuracy: 0.9724 - 408ms/epoch - 4ms/step\n",
      "Epoch 5/10\n",
      "108/108 - 0s - loss: 0.1899 - accuracy: 0.9408 - val_loss: 0.1035 - val_accuracy: 0.9718 - 413ms/epoch - 4ms/step\n",
      "Epoch 6/10\n",
      "108/108 - 0s - loss: 0.1901 - accuracy: 0.9419 - val_loss: 0.1029 - val_accuracy: 0.9722 - 422ms/epoch - 4ms/step\n",
      "Epoch 7/10\n",
      "108/108 - 0s - loss: 0.1897 - accuracy: 0.9405 - val_loss: 0.1021 - val_accuracy: 0.9732 - 419ms/epoch - 4ms/step\n",
      "Epoch 8/10\n",
      "108/108 - 0s - loss: 0.1878 - accuracy: 0.9409 - val_loss: 0.1025 - val_accuracy: 0.9720 - 409ms/epoch - 4ms/step\n",
      "Epoch 9/10\n",
      "108/108 - 0s - loss: 0.1859 - accuracy: 0.9426 - val_loss: 0.1018 - val_accuracy: 0.9720 - 421ms/epoch - 4ms/step\n",
      "Epoch 10/10\n",
      "108/108 - 0s - loss: 0.1859 - accuracy: 0.9420 - val_loss: 0.1007 - val_accuracy: 0.9736 - 411ms/epoch - 4ms/step\n",
      "Accuracy of the MLP model:\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.1305 - accuracy: 0.9611\n",
      "# Parameters of the model: 266610\n",
      "# Parameters pruned: 262595\n",
      "Remaining weights (%): 1.5059450133153294\n"
     ]
    }
   ],
   "source": [
    "pruned, model_hp1, model_ep1 = pruning_tool_MLP_v4_1.pruning_MLP(baselineModel, x_train, y_train, x_val, y_val, x_test, y_test, batch_size=512, morph_epochs=30, mlp_epochs=10, mlp_epochs_refit=40, p=3, optimizer_config=tf.optimizers.serialize(optimizer), extreme=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "pruned.compile(optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'],\n",
    "              jit_compile=True\n",
    "            ) #from logits = Ture if no activation function on the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "430/430 [==============================] - 5s 8ms/step - loss: 0.1879 - accuracy: 0.9422 - val_loss: 0.1019 - val_accuracy: 0.9734\n",
      "Epoch 2/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1833 - accuracy: 0.9419 - val_loss: 0.1007 - val_accuracy: 0.9722\n",
      "Epoch 3/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1821 - accuracy: 0.9440 - val_loss: 0.1005 - val_accuracy: 0.9716\n",
      "Epoch 4/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1800 - accuracy: 0.9445 - val_loss: 0.0989 - val_accuracy: 0.9720\n",
      "Epoch 5/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1802 - accuracy: 0.9441 - val_loss: 0.0984 - val_accuracy: 0.9724\n",
      "Epoch 6/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1811 - accuracy: 0.9438 - val_loss: 0.0982 - val_accuracy: 0.9722\n",
      "Epoch 7/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1778 - accuracy: 0.9449 - val_loss: 0.0984 - val_accuracy: 0.9722\n",
      "Epoch 8/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1769 - accuracy: 0.9449 - val_loss: 0.0978 - val_accuracy: 0.9722\n",
      "Epoch 9/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1753 - accuracy: 0.9443 - val_loss: 0.0965 - val_accuracy: 0.9744\n",
      "Epoch 10/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1741 - accuracy: 0.9452 - val_loss: 0.0949 - val_accuracy: 0.9728\n",
      "Epoch 11/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1712 - accuracy: 0.9471 - val_loss: 0.0968 - val_accuracy: 0.9738\n",
      "Epoch 12/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1731 - accuracy: 0.9463 - val_loss: 0.0952 - val_accuracy: 0.9740\n",
      "Epoch 13/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1721 - accuracy: 0.9458 - val_loss: 0.0964 - val_accuracy: 0.9742\n",
      "Epoch 14/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1698 - accuracy: 0.9466 - val_loss: 0.0939 - val_accuracy: 0.9740\n",
      "Epoch 15/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1673 - accuracy: 0.9470 - val_loss: 0.0952 - val_accuracy: 0.9738\n",
      "Epoch 16/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1696 - accuracy: 0.9471 - val_loss: 0.0938 - val_accuracy: 0.9752\n",
      "Epoch 17/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1675 - accuracy: 0.9464 - val_loss: 0.0920 - val_accuracy: 0.9726\n",
      "Epoch 18/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1687 - accuracy: 0.9467 - val_loss: 0.0919 - val_accuracy: 0.9752\n",
      "Epoch 19/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1691 - accuracy: 0.9477 - val_loss: 0.0932 - val_accuracy: 0.9742\n",
      "Epoch 20/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1670 - accuracy: 0.9477 - val_loss: 0.0927 - val_accuracy: 0.9746\n",
      "Epoch 21/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1656 - accuracy: 0.9483 - val_loss: 0.0918 - val_accuracy: 0.9748\n",
      "Epoch 22/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1656 - accuracy: 0.9476 - val_loss: 0.0928 - val_accuracy: 0.9750\n",
      "Epoch 23/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1636 - accuracy: 0.9481 - val_loss: 0.0916 - val_accuracy: 0.9756\n",
      "Epoch 24/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1634 - accuracy: 0.9479 - val_loss: 0.0936 - val_accuracy: 0.9744\n",
      "Epoch 25/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1643 - accuracy: 0.9485 - val_loss: 0.0940 - val_accuracy: 0.9738\n",
      "Epoch 26/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1611 - accuracy: 0.9487 - val_loss: 0.0924 - val_accuracy: 0.9748\n",
      "Epoch 27/40\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.1615 - accuracy: 0.9499 - val_loss: 0.0918 - val_accuracy: 0.9754\n",
      "Epoch 28/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1624 - accuracy: 0.9482 - val_loss: 0.0912 - val_accuracy: 0.9754\n",
      "Epoch 29/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1613 - accuracy: 0.9492 - val_loss: 0.0935 - val_accuracy: 0.9750\n",
      "Epoch 30/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1599 - accuracy: 0.9501 - val_loss: 0.0903 - val_accuracy: 0.9744\n",
      "Epoch 31/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1605 - accuracy: 0.9489 - val_loss: 0.0903 - val_accuracy: 0.9762\n",
      "Epoch 32/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1604 - accuracy: 0.9496 - val_loss: 0.0914 - val_accuracy: 0.9748\n",
      "Epoch 33/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1581 - accuracy: 0.9498 - val_loss: 0.0913 - val_accuracy: 0.9746\n",
      "Epoch 34/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1599 - accuracy: 0.9488 - val_loss: 0.0899 - val_accuracy: 0.9758\n",
      "Epoch 35/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1604 - accuracy: 0.9497 - val_loss: 0.0901 - val_accuracy: 0.9762\n",
      "Epoch 36/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1589 - accuracy: 0.9503 - val_loss: 0.0904 - val_accuracy: 0.9760\n",
      "Epoch 37/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1569 - accuracy: 0.9506 - val_loss: 0.0903 - val_accuracy: 0.9766\n",
      "Epoch 38/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1582 - accuracy: 0.9501 - val_loss: 0.0891 - val_accuracy: 0.9768\n",
      "Epoch 39/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1585 - accuracy: 0.9500 - val_loss: 0.0901 - val_accuracy: 0.9752\n",
      "Epoch 40/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1575 - accuracy: 0.9509 - val_loss: 0.0901 - val_accuracy: 0.9754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f92d48cf4f0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=40, batch_size=128, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1168 - accuracy: 0.9667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11683344841003418, 0.96670001745224]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p=3 Mnist 300-100 v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineModel = tf.keras.models.load_model('../models/MLP_MNIST_300_100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0890 - accuracy: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08896878361701965, 0.9821000099182129]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselineModel.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = baselineModel.layers[0].get_weights()[0]\n",
    "b = baselineModel.layers[0].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.multiply(w, (w > 10e-38))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineModel.layers[0].set_weights([w, b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15702"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 40.8009 - accuracy: 0.2468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[40.80094528198242, 0.2468000054359436]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselineModel.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "baselineModel.compile(optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'],\n",
    "              jit_compile=True\n",
    "            ) #from logits = Ture if no activation function on the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "430/430 [==============================] - 5s 9ms/step - loss: 0.7668 - accuracy: 0.8846 - val_loss: 0.1837 - val_accuracy: 0.9572\n",
      "Epoch 2/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.1608 - accuracy: 0.9529 - val_loss: 0.1595 - val_accuracy: 0.9608\n",
      "Epoch 3/40\n",
      "430/430 [==============================] - 2s 3ms/step - loss: 0.1289 - accuracy: 0.9612 - val_loss: 0.1399 - val_accuracy: 0.9652\n",
      "Epoch 4/40\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.1048 - accuracy: 0.9692 - val_loss: 0.1343 - val_accuracy: 0.9702\n",
      "Epoch 5/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0859 - accuracy: 0.9741 - val_loss: 0.1343 - val_accuracy: 0.9712\n",
      "Epoch 6/40\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0715 - accuracy: 0.9790 - val_loss: 0.1238 - val_accuracy: 0.9726\n",
      "Epoch 7/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0624 - accuracy: 0.9818 - val_loss: 0.1260 - val_accuracy: 0.9736\n",
      "Epoch 8/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0489 - accuracy: 0.9859 - val_loss: 0.1208 - val_accuracy: 0.9750\n",
      "Epoch 9/40\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0422 - accuracy: 0.9882 - val_loss: 0.1193 - val_accuracy: 0.9788\n",
      "Epoch 10/40\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0352 - accuracy: 0.9907 - val_loss: 0.1251 - val_accuracy: 0.9776\n",
      "Epoch 11/40\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0315 - accuracy: 0.9923 - val_loss: 0.1199 - val_accuracy: 0.9786\n",
      "Epoch 12/40\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0302 - accuracy: 0.9923 - val_loss: 0.1299 - val_accuracy: 0.9784\n",
      "Epoch 13/40\n",
      "430/430 [==============================] - 2s 3ms/step - loss: 0.0309 - accuracy: 0.9924 - val_loss: 0.1307 - val_accuracy: 0.9776\n",
      "Epoch 14/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0320 - accuracy: 0.9922 - val_loss: 0.1435 - val_accuracy: 0.9760\n",
      "Epoch 15/40\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0299 - accuracy: 0.9927 - val_loss: 0.1294 - val_accuracy: 0.9806\n",
      "Epoch 16/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0311 - accuracy: 0.9929 - val_loss: 0.1399 - val_accuracy: 0.9788\n",
      "Epoch 17/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0320 - accuracy: 0.9929 - val_loss: 0.1158 - val_accuracy: 0.9804\n",
      "Epoch 18/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0288 - accuracy: 0.9937 - val_loss: 0.1483 - val_accuracy: 0.9786\n",
      "Epoch 19/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0308 - accuracy: 0.9933 - val_loss: 0.1447 - val_accuracy: 0.9778\n",
      "Epoch 20/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0267 - accuracy: 0.9954 - val_loss: 0.1602 - val_accuracy: 0.9764\n",
      "Epoch 21/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0314 - accuracy: 0.9937 - val_loss: 0.1465 - val_accuracy: 0.9776\n",
      "Epoch 22/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0313 - accuracy: 0.9939 - val_loss: 0.1549 - val_accuracy: 0.9786\n",
      "Epoch 23/40\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0252 - accuracy: 0.9959 - val_loss: 0.1516 - val_accuracy: 0.9802\n",
      "Epoch 24/40\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0279 - accuracy: 0.9953 - val_loss: 0.1731 - val_accuracy: 0.9772\n",
      "Epoch 25/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0382 - accuracy: 0.9924 - val_loss: 0.1659 - val_accuracy: 0.9780\n",
      "Epoch 26/40\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0321 - accuracy: 0.9941 - val_loss: 0.1706 - val_accuracy: 0.9754\n",
      "Epoch 27/40\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0284 - accuracy: 0.9954 - val_loss: 0.1537 - val_accuracy: 0.9812\n",
      "Epoch 28/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9950 - val_loss: 0.1823 - val_accuracy: 0.9764\n",
      "Epoch 29/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0360 - accuracy: 0.9936 - val_loss: 0.1928 - val_accuracy: 0.9770\n",
      "Epoch 30/40\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0331 - accuracy: 0.9949 - val_loss: 0.1841 - val_accuracy: 0.9774\n",
      "Epoch 31/40\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0306 - accuracy: 0.9953 - val_loss: 0.2195 - val_accuracy: 0.9708\n",
      "Epoch 32/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0351 - accuracy: 0.9942 - val_loss: 0.1751 - val_accuracy: 0.9778\n",
      "Epoch 33/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0307 - accuracy: 0.9955 - val_loss: 0.1786 - val_accuracy: 0.9806\n",
      "Epoch 34/40\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.0335 - accuracy: 0.9943 - val_loss: 0.1789 - val_accuracy: 0.9760\n",
      "Epoch 35/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0301 - accuracy: 0.9959 - val_loss: 0.1953 - val_accuracy: 0.9742\n",
      "Epoch 36/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0288 - accuracy: 0.9961 - val_loss: 0.1649 - val_accuracy: 0.9804\n",
      "Epoch 37/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.0351 - accuracy: 0.9947 - val_loss: 0.1764 - val_accuracy: 0.9774\n",
      "Epoch 37: early stopping\n",
      "313/313 [==============================] - 2s 5ms/step - loss: 0.1807 - accuracy: 0.9715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1807369887828827, 0.9714999794960022]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselineModel.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=40, batch_size=128, callbacks=[es])\n",
    "baselineModel.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1807 - accuracy: 0.9715\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.1807369887828827, 0.9714999794960022]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselineModel.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33602"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.count_nonzero(baselineModel.layers[0].get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " modelLayer_1_0 (Dense)      (None, 100)               30100     \n",
      "                                                                 \n",
      " modelLayer_2_1 (Dense)      (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baselineModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training morphological model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min (SoftMaxMin)   (55000, 300)              235200    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (55000, 10)               3000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238200 (930.47 KB)\n",
      "Trainable params: 238200 (930.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1719/1719 - 11s - loss: 0.8400 - accuracy: 0.7685 - val_loss: 0.2732 - val_accuracy: 0.9258 - 11s/epoch - 7ms/step\n",
      "Epoch 2/30\n",
      "1719/1719 - 9s - loss: 0.2851 - accuracy: 0.9177 - val_loss: 0.1963 - val_accuracy: 0.9460 - 9s/epoch - 5ms/step\n",
      "Epoch 3/30\n",
      "1719/1719 - 9s - loss: 0.2199 - accuracy: 0.9361 - val_loss: 0.1591 - val_accuracy: 0.9570 - 9s/epoch - 5ms/step\n",
      "Epoch 4/30\n",
      "1719/1719 - 9s - loss: 0.1842 - accuracy: 0.9473 - val_loss: 0.1370 - val_accuracy: 0.9630 - 9s/epoch - 5ms/step\n",
      "Epoch 5/30\n",
      "1719/1719 - 9s - loss: 0.1606 - accuracy: 0.9538 - val_loss: 0.1206 - val_accuracy: 0.9678 - 9s/epoch - 5ms/step\n",
      "Epoch 6/30\n",
      "1719/1719 - 9s - loss: 0.1434 - accuracy: 0.9585 - val_loss: 0.1088 - val_accuracy: 0.9730 - 9s/epoch - 5ms/step\n",
      "Epoch 7/30\n",
      "1719/1719 - 8s - loss: 0.1302 - accuracy: 0.9629 - val_loss: 0.1071 - val_accuracy: 0.9710 - 8s/epoch - 5ms/step\n",
      "Epoch 8/30\n",
      "1719/1719 - 9s - loss: 0.1198 - accuracy: 0.9656 - val_loss: 0.0972 - val_accuracy: 0.9758 - 9s/epoch - 5ms/step\n",
      "Epoch 9/30\n",
      "1719/1719 - 9s - loss: 0.1117 - accuracy: 0.9674 - val_loss: 0.0983 - val_accuracy: 0.9728 - 9s/epoch - 5ms/step\n",
      "Epoch 10/30\n",
      "1719/1719 - 9s - loss: 0.1038 - accuracy: 0.9703 - val_loss: 0.1020 - val_accuracy: 0.9720 - 9s/epoch - 5ms/step\n",
      "Epoch 11/30\n",
      "1719/1719 - 9s - loss: 0.0975 - accuracy: 0.9726 - val_loss: 0.0953 - val_accuracy: 0.9750 - 9s/epoch - 5ms/step\n",
      "Epoch 12/30\n",
      "1719/1719 - 9s - loss: 0.0917 - accuracy: 0.9737 - val_loss: 0.0854 - val_accuracy: 0.9758 - 9s/epoch - 5ms/step\n",
      "Epoch 13/30\n",
      "1719/1719 - 9s - loss: 0.0858 - accuracy: 0.9760 - val_loss: 0.0891 - val_accuracy: 0.9758 - 9s/epoch - 5ms/step\n",
      "Epoch 14/30\n",
      "1719/1719 - 9s - loss: 0.0823 - accuracy: 0.9765 - val_loss: 0.0826 - val_accuracy: 0.9774 - 9s/epoch - 5ms/step\n",
      "Epoch 15/30\n",
      "1719/1719 - 9s - loss: 0.0768 - accuracy: 0.9781 - val_loss: 0.0911 - val_accuracy: 0.9740 - 9s/epoch - 5ms/step\n",
      "Epoch 16/30\n",
      "1719/1719 - 9s - loss: 0.0734 - accuracy: 0.9790 - val_loss: 0.0830 - val_accuracy: 0.9760 - 9s/epoch - 5ms/step\n",
      "Epoch 17/30\n",
      "1719/1719 - 8s - loss: 0.0694 - accuracy: 0.9809 - val_loss: 0.0842 - val_accuracy: 0.9766 - 8s/epoch - 5ms/step\n",
      "Epoch 18/30\n",
      "1719/1719 - 9s - loss: 0.0675 - accuracy: 0.9808 - val_loss: 0.0827 - val_accuracy: 0.9770 - 9s/epoch - 5ms/step\n",
      "Epoch 19/30\n",
      "1719/1719 - 9s - loss: 0.0644 - accuracy: 0.9821 - val_loss: 0.0785 - val_accuracy: 0.9768 - 9s/epoch - 5ms/step\n",
      "Epoch 20/30\n",
      "1719/1719 - 9s - loss: 0.0612 - accuracy: 0.9830 - val_loss: 0.0733 - val_accuracy: 0.9802 - 9s/epoch - 5ms/step\n",
      "Epoch 21/30\n",
      "1719/1719 - 9s - loss: 0.0585 - accuracy: 0.9835 - val_loss: 0.0740 - val_accuracy: 0.9792 - 9s/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "1719/1719 - 9s - loss: 0.0565 - accuracy: 0.9842 - val_loss: 0.0725 - val_accuracy: 0.9800 - 9s/epoch - 5ms/step\n",
      "Epoch 23/30\n",
      "1719/1719 - 9s - loss: 0.0543 - accuracy: 0.9850 - val_loss: 0.0947 - val_accuracy: 0.9724 - 9s/epoch - 5ms/step\n",
      "Epoch 24/30\n",
      "1719/1719 - 9s - loss: 0.0525 - accuracy: 0.9850 - val_loss: 0.0768 - val_accuracy: 0.9784 - 9s/epoch - 5ms/step\n",
      "Epoch 25/30\n",
      "1719/1719 - 9s - loss: 0.0504 - accuracy: 0.9861 - val_loss: 0.0667 - val_accuracy: 0.9812 - 9s/epoch - 5ms/step\n",
      "Epoch 26/30\n",
      "1719/1719 - 9s - loss: 0.0483 - accuracy: 0.9867 - val_loss: 0.0681 - val_accuracy: 0.9798 - 9s/epoch - 5ms/step\n",
      "Epoch 27/30\n",
      "1719/1719 - 9s - loss: 0.0466 - accuracy: 0.9875 - val_loss: 0.0685 - val_accuracy: 0.9804 - 9s/epoch - 5ms/step\n",
      "Epoch 28/30\n",
      "1719/1719 - 8s - loss: 0.0452 - accuracy: 0.9876 - val_loss: 0.0706 - val_accuracy: 0.9792 - 8s/epoch - 5ms/step\n",
      "Epoch 29/30\n",
      "1719/1719 - 9s - loss: 0.0430 - accuracy: 0.9883 - val_loss: 0.0740 - val_accuracy: 0.9774 - 9s/epoch - 5ms/step\n",
      "Epoch 30/30\n",
      "1719/1719 - 9s - loss: 0.0417 - accuracy: 0.9884 - val_loss: 0.0668 - val_accuracy: 0.9804 - 9s/epoch - 5ms/step\n",
      "Pruning morphological model...\n",
      "\n",
      "Baseline test accuracy: \n",
      "20/20 [==============================] - 1s 19ms/step - loss: 0.0818 - accuracy: 0.9754\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 238200\n",
      "Weights that can be pruned: 233213\n",
      "Left parameters: 4987\n",
      "Unactive neurons: 0\n",
      "Parameter reduction of the model: 97%\n",
      "Parameter reduction of the morph layers: 99%\n",
      "\n",
      "Extreme pruned model with a TEP threshold of 3% . Test acuraccy\n",
      "20/20 [==============================] - 0s 8ms/step - loss: 0.1330 - accuracy: 0.9603\n",
      "Retraining MLP dense model...\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " modelLayer_0_0 (Dense)      (55000, 300)              235500    \n",
      "                                                                 \n",
      " modelLayer_1_0 (Dense)      multiple                  30100     \n",
      "                                                                 \n",
      " modelLayer_2_0 (Dense)      multiple                  1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/40\n",
      "108/108 [==============================] - 4s 23ms/step - loss: 1.7418 - accuracy: 0.5065 - val_loss: 0.8367 - val_accuracy: 0.7416\n",
      "Epoch 2/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.7897 - accuracy: 0.7508 - val_loss: 0.5693 - val_accuracy: 0.8316\n",
      "Epoch 3/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.6181 - accuracy: 0.8089 - val_loss: 0.4597 - val_accuracy: 0.8624\n",
      "Epoch 4/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.5331 - accuracy: 0.8364 - val_loss: 0.3998 - val_accuracy: 0.8840\n",
      "Epoch 5/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4800 - accuracy: 0.8540 - val_loss: 0.3626 - val_accuracy: 0.8950\n",
      "Epoch 6/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4452 - accuracy: 0.8659 - val_loss: 0.3369 - val_accuracy: 0.8998\n",
      "Epoch 7/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.4194 - accuracy: 0.8720 - val_loss: 0.3167 - val_accuracy: 0.9072\n",
      "Epoch 8/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3983 - accuracy: 0.8796 - val_loss: 0.3096 - val_accuracy: 0.9116\n",
      "Epoch 9/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3836 - accuracy: 0.8841 - val_loss: 0.2956 - val_accuracy: 0.9126\n",
      "Epoch 10/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3707 - accuracy: 0.8878 - val_loss: 0.2781 - val_accuracy: 0.9214\n",
      "Epoch 11/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3603 - accuracy: 0.8910 - val_loss: 0.2788 - val_accuracy: 0.9232\n",
      "Epoch 12/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3488 - accuracy: 0.8946 - val_loss: 0.2706 - val_accuracy: 0.9240\n",
      "Epoch 13/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3366 - accuracy: 0.8985 - val_loss: 0.2502 - val_accuracy: 0.9280\n",
      "Epoch 14/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3247 - accuracy: 0.9016 - val_loss: 0.2420 - val_accuracy: 0.9318\n",
      "Epoch 15/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3143 - accuracy: 0.9049 - val_loss: 0.2456 - val_accuracy: 0.9294\n",
      "Epoch 16/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.3063 - accuracy: 0.9073 - val_loss: 0.2364 - val_accuracy: 0.9298\n",
      "Epoch 17/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2986 - accuracy: 0.9099 - val_loss: 0.2276 - val_accuracy: 0.9344\n",
      "Epoch 18/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2917 - accuracy: 0.9115 - val_loss: 0.2277 - val_accuracy: 0.9348\n",
      "Epoch 19/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2857 - accuracy: 0.9147 - val_loss: 0.2210 - val_accuracy: 0.9350\n",
      "Epoch 20/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2778 - accuracy: 0.9168 - val_loss: 0.2169 - val_accuracy: 0.9360\n",
      "Epoch 21/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2729 - accuracy: 0.9182 - val_loss: 0.2127 - val_accuracy: 0.9376\n",
      "Epoch 22/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2691 - accuracy: 0.9193 - val_loss: 0.2085 - val_accuracy: 0.9414\n",
      "Epoch 23/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2634 - accuracy: 0.9209 - val_loss: 0.1999 - val_accuracy: 0.9422\n",
      "Epoch 24/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2583 - accuracy: 0.9225 - val_loss: 0.1974 - val_accuracy: 0.9438\n",
      "Epoch 25/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2534 - accuracy: 0.9235 - val_loss: 0.1962 - val_accuracy: 0.9440\n",
      "Epoch 26/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2504 - accuracy: 0.9249 - val_loss: 0.1986 - val_accuracy: 0.9404\n",
      "Epoch 27/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2479 - accuracy: 0.9260 - val_loss: 0.1965 - val_accuracy: 0.9428\n",
      "Epoch 28/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2427 - accuracy: 0.9271 - val_loss: 0.1894 - val_accuracy: 0.9458\n",
      "Epoch 29/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2377 - accuracy: 0.9283 - val_loss: 0.1880 - val_accuracy: 0.9446\n",
      "Epoch 30/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2363 - accuracy: 0.9289 - val_loss: 0.1830 - val_accuracy: 0.9460\n",
      "Epoch 31/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2337 - accuracy: 0.9301 - val_loss: 0.1845 - val_accuracy: 0.9468\n",
      "Epoch 32/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2300 - accuracy: 0.9303 - val_loss: 0.1822 - val_accuracy: 0.9466\n",
      "Epoch 33/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2280 - accuracy: 0.9315 - val_loss: 0.1808 - val_accuracy: 0.9486\n",
      "Epoch 34/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2265 - accuracy: 0.9317 - val_loss: 0.1747 - val_accuracy: 0.9496\n",
      "Epoch 35/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2219 - accuracy: 0.9332 - val_loss: 0.1750 - val_accuracy: 0.9504\n",
      "Epoch 36/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2205 - accuracy: 0.9339 - val_loss: 0.1733 - val_accuracy: 0.9496\n",
      "Epoch 37/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2167 - accuracy: 0.9345 - val_loss: 0.1725 - val_accuracy: 0.9506\n",
      "Epoch 38/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2152 - accuracy: 0.9349 - val_loss: 0.1728 - val_accuracy: 0.9504\n",
      "Epoch 39/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2147 - accuracy: 0.9346 - val_loss: 0.1768 - val_accuracy: 0.9496\n",
      "Epoch 40/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.2123 - accuracy: 0.9359 - val_loss: 0.1755 - val_accuracy: 0.9488\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.2110 - accuracy: 0.9372\n",
      "Training morphological model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min (SoftMaxMin)   (55000, 100)              30000     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (55000, 10)               1000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31000 (121.09 KB)\n",
      "Trainable params: 31000 (121.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/lluc/lluc_tensorflow_1/paper/lenet300_mnist.ipynb Cell 41\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B130.206.30.107/home/lluc/lluc_tensorflow_1/paper/lenet300_mnist.ipynb#X61sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m pruned, model_hp1, model_ep1 \u001b[39m=\u001b[39m pruning_tool_MLP_v4_1\u001b[39m.\u001b[39;49mpruning_MLP(baselineModel, x_train, y_train, x_val, y_val, x_test, y_test, batch_size\u001b[39m=\u001b[39;49m\u001b[39m512\u001b[39;49m, morph_epochs\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m, mlp_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, mlp_epochs_refit\u001b[39m=\u001b[39;49m\u001b[39m40\u001b[39;49m, p\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m, optimizer_config\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49moptimizers\u001b[39m.\u001b[39;49mserialize(optimizer), extreme\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/lluc_tensorflow_1/paper/./../maxine/tools/pruning_tool_MLP_v4_1.py:100\u001b[0m, in \u001b[0;36mpruning_MLP\u001b[0;34m(model, x_train, y_train, x_val, y_val, x_test, y_test, batch_size, morph_epochs, mlp_epochs, mlp_epochs_refit, p, ommit_layers, optimizer_config, extreme)\u001b[0m\n\u001b[1;32m     97\u001b[0m morph_model\u001b[39m.\u001b[39mbuild(input_shape\u001b[39m=\u001b[39mtrain_data_morph\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     98\u001b[0m morph_model\u001b[39m.\u001b[39msummary()\n\u001b[0;32m--> 100\u001b[0m morph_model\u001b[39m.\u001b[39;49mfit(train_data_morph, y_train, validation_data\u001b[39m=\u001b[39;49m(val_data_morph, y_val), epochs\u001b[39m=\u001b[39;49mmorph_epochs, verbose\u001b[39m=\u001b[39;49m\u001b[39m2\u001b[39;49m)\n\u001b[1;32m    102\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mPruning morphological model...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    103\u001b[0m _, hp_masc, ep_masc \u001b[39m=\u001b[39m pruning_tool_v4\u001b[39m.\u001b[39mpruning_morphological(morph_model, train_data_morph, y_train, val_data_morph, y_val, test_data_morph, y_test, p\u001b[39m=\u001b[39mp, batch_size\u001b[39m=\u001b[39mbatch_size, extreme\u001b[39m=\u001b[39mextreme, optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m], finetuning\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1743\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[39mreturn\u001b[39;00m concrete_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m    149\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mconcrete_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function(\u001b[39m*\u001b[39;49margs))\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    197\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    198\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    199\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    200\u001b[0m     )\n\u001b[1;32m    201\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\u001b[39mself\u001b[39m, \u001b[39mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1458\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1459\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1460\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1461\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1462\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1463\u001b[0m   )\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/envs/tf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pruned, model_hp1, model_ep1 = pruning_tool_MLP_v4_1.pruning_MLP(baselineModel, x_train, y_train, x_val, y_val, x_test, y_test, batch_size=512, morph_epochs=30, mlp_epochs=10, mlp_epochs_refit=40, p=3, optimizer_config=tf.optimizers.serialize(optimizer), extreme=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "pruned.compile(optimizer,\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "              metrics=['accuracy'],\n",
    "              jit_compile=True\n",
    "            ) #from logits = Ture if no activation function on the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "430/430 [==============================] - 4s 7ms/step - loss: 0.4544 - accuracy: 0.8588 - val_loss: 0.3576 - val_accuracy: 0.8912\n",
      "Epoch 2/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4506 - accuracy: 0.8596 - val_loss: 0.3496 - val_accuracy: 0.8946\n",
      "Epoch 3/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4470 - accuracy: 0.8610 - val_loss: 0.3542 - val_accuracy: 0.8938\n",
      "Epoch 4/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4443 - accuracy: 0.8620 - val_loss: 0.3543 - val_accuracy: 0.8920\n",
      "Epoch 5/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4414 - accuracy: 0.8625 - val_loss: 0.3480 - val_accuracy: 0.8968\n",
      "Epoch 6/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4361 - accuracy: 0.8639 - val_loss: 0.3420 - val_accuracy: 0.8940\n",
      "Epoch 7/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4344 - accuracy: 0.8652 - val_loss: 0.3390 - val_accuracy: 0.8964\n",
      "Epoch 8/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4310 - accuracy: 0.8663 - val_loss: 0.3341 - val_accuracy: 0.9004\n",
      "Epoch 9/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4280 - accuracy: 0.8666 - val_loss: 0.3396 - val_accuracy: 0.8942\n",
      "Epoch 10/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4250 - accuracy: 0.8685 - val_loss: 0.3347 - val_accuracy: 0.8968\n",
      "Epoch 11/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4237 - accuracy: 0.8686 - val_loss: 0.3316 - val_accuracy: 0.8990\n",
      "Epoch 12/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4218 - accuracy: 0.8692 - val_loss: 0.3318 - val_accuracy: 0.9006\n",
      "Epoch 13/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4187 - accuracy: 0.8703 - val_loss: 0.3251 - val_accuracy: 0.9016\n",
      "Epoch 14/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4174 - accuracy: 0.8712 - val_loss: 0.3265 - val_accuracy: 0.9002\n",
      "Epoch 15/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4151 - accuracy: 0.8721 - val_loss: 0.3266 - val_accuracy: 0.9000\n",
      "Epoch 16/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4143 - accuracy: 0.8726 - val_loss: 0.3214 - val_accuracy: 0.9042\n",
      "Epoch 17/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4124 - accuracy: 0.8723 - val_loss: 0.3227 - val_accuracy: 0.9016\n",
      "Epoch 18/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4108 - accuracy: 0.8740 - val_loss: 0.3195 - val_accuracy: 0.9022\n",
      "Epoch 19/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4096 - accuracy: 0.8735 - val_loss: 0.3193 - val_accuracy: 0.9052\n",
      "Epoch 20/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4088 - accuracy: 0.8737 - val_loss: 0.3270 - val_accuracy: 0.9004\n",
      "Epoch 21/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4068 - accuracy: 0.8746 - val_loss: 0.3161 - val_accuracy: 0.9056\n",
      "Epoch 22/40\n",
      "430/430 [==============================] - 2s 4ms/step - loss: 0.4053 - accuracy: 0.8743 - val_loss: 0.3197 - val_accuracy: 0.9026\n",
      "Epoch 23/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4041 - accuracy: 0.8743 - val_loss: 0.3211 - val_accuracy: 0.9028\n",
      "Epoch 24/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4042 - accuracy: 0.8749 - val_loss: 0.3174 - val_accuracy: 0.9050\n",
      "Epoch 25/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4022 - accuracy: 0.8756 - val_loss: 0.3170 - val_accuracy: 0.9020\n",
      "Epoch 26/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.4011 - accuracy: 0.8756 - val_loss: 0.3087 - val_accuracy: 0.9056\n",
      "Epoch 27/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3997 - accuracy: 0.8761 - val_loss: 0.3123 - val_accuracy: 0.9036\n",
      "Epoch 28/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3987 - accuracy: 0.8765 - val_loss: 0.3125 - val_accuracy: 0.9050\n",
      "Epoch 29/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3982 - accuracy: 0.8765 - val_loss: 0.3090 - val_accuracy: 0.9050\n",
      "Epoch 30/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3969 - accuracy: 0.8767 - val_loss: 0.3113 - val_accuracy: 0.9030\n",
      "Epoch 31/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3968 - accuracy: 0.8778 - val_loss: 0.3149 - val_accuracy: 0.9054\n",
      "Epoch 32/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3951 - accuracy: 0.8778 - val_loss: 0.3079 - val_accuracy: 0.9068\n",
      "Epoch 33/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3945 - accuracy: 0.8783 - val_loss: 0.3067 - val_accuracy: 0.9060\n",
      "Epoch 34/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3944 - accuracy: 0.8783 - val_loss: 0.3071 - val_accuracy: 0.9058\n",
      "Epoch 35/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3934 - accuracy: 0.8783 - val_loss: 0.3040 - val_accuracy: 0.9054\n",
      "Epoch 36/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3918 - accuracy: 0.8779 - val_loss: 0.3065 - val_accuracy: 0.9050\n",
      "Epoch 37/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3916 - accuracy: 0.8793 - val_loss: 0.3036 - val_accuracy: 0.9072\n",
      "Epoch 38/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3904 - accuracy: 0.8786 - val_loss: 0.3052 - val_accuracy: 0.9070\n",
      "Epoch 39/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3903 - accuracy: 0.8796 - val_loss: 0.3018 - val_accuracy: 0.9082\n",
      "Epoch 40/40\n",
      "430/430 [==============================] - 1s 3ms/step - loss: 0.3897 - accuracy: 0.8787 - val_loss: 0.3153 - val_accuracy: 0.9000\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3817 - accuracy: 0.8802\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.38168570399284363, 0.8802000284194946]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=40, batch_size=128, callbacks=[es])\n",
    "pruned.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineModel = tf.keras.models.load_model('../models/paper/MLP_MNIST_300_100_v2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training morphological model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min (SoftMaxMin)   (55000, 300)              235200    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (55000, 10)               3000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238200 (930.47 KB)\n",
      "Trainable params: 238200 (930.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1719/1719 - 10s - loss: 0.8438 - accuracy: 0.7690 - val_loss: 0.2771 - val_accuracy: 0.9254 - 10s/epoch - 6ms/step\n",
      "Epoch 2/30\n",
      "1719/1719 - 8s - loss: 0.2831 - accuracy: 0.9180 - val_loss: 0.1844 - val_accuracy: 0.9502 - 8s/epoch - 5ms/step\n",
      "Epoch 3/30\n",
      "1719/1719 - 8s - loss: 0.2168 - accuracy: 0.9377 - val_loss: 0.1540 - val_accuracy: 0.9562 - 8s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1719/1719 - 8s - loss: 0.1825 - accuracy: 0.9476 - val_loss: 0.1331 - val_accuracy: 0.9648 - 8s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1719/1719 - 8s - loss: 0.1598 - accuracy: 0.9538 - val_loss: 0.1254 - val_accuracy: 0.9650 - 8s/epoch - 5ms/step\n",
      "Epoch 6/30\n",
      "1719/1719 - 8s - loss: 0.1442 - accuracy: 0.9579 - val_loss: 0.1060 - val_accuracy: 0.9732 - 8s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1719/1719 - 8s - loss: 0.1303 - accuracy: 0.9627 - val_loss: 0.0991 - val_accuracy: 0.9756 - 8s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1719/1719 - 8s - loss: 0.1200 - accuracy: 0.9653 - val_loss: 0.1090 - val_accuracy: 0.9706 - 8s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1719/1719 - 8s - loss: 0.1112 - accuracy: 0.9679 - val_loss: 0.0964 - val_accuracy: 0.9750 - 8s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1719/1719 - 8s - loss: 0.1029 - accuracy: 0.9706 - val_loss: 0.0912 - val_accuracy: 0.9760 - 8s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1719/1719 - 8s - loss: 0.0986 - accuracy: 0.9718 - val_loss: 0.0863 - val_accuracy: 0.9780 - 8s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1719/1719 - 8s - loss: 0.0916 - accuracy: 0.9741 - val_loss: 0.0856 - val_accuracy: 0.9750 - 8s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1719/1719 - 8s - loss: 0.0870 - accuracy: 0.9756 - val_loss: 0.0802 - val_accuracy: 0.9794 - 8s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1719/1719 - 8s - loss: 0.0830 - accuracy: 0.9768 - val_loss: 0.0792 - val_accuracy: 0.9774 - 8s/epoch - 5ms/step\n",
      "Epoch 15/30\n",
      "1719/1719 - 8s - loss: 0.0780 - accuracy: 0.9773 - val_loss: 0.0839 - val_accuracy: 0.9770 - 8s/epoch - 5ms/step\n",
      "Epoch 16/30\n",
      "1719/1719 - 8s - loss: 0.0743 - accuracy: 0.9785 - val_loss: 0.0839 - val_accuracy: 0.9764 - 8s/epoch - 5ms/step\n",
      "Epoch 17/30\n",
      "1719/1719 - 8s - loss: 0.0701 - accuracy: 0.9801 - val_loss: 0.0814 - val_accuracy: 0.9786 - 8s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1719/1719 - 8s - loss: 0.0676 - accuracy: 0.9809 - val_loss: 0.0744 - val_accuracy: 0.9798 - 8s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1719/1719 - 8s - loss: 0.0654 - accuracy: 0.9812 - val_loss: 0.0761 - val_accuracy: 0.9780 - 8s/epoch - 5ms/step\n",
      "Epoch 20/30\n",
      "1719/1719 - 8s - loss: 0.0625 - accuracy: 0.9822 - val_loss: 0.0742 - val_accuracy: 0.9790 - 8s/epoch - 5ms/step\n",
      "Epoch 21/30\n",
      "1719/1719 - 8s - loss: 0.0593 - accuracy: 0.9832 - val_loss: 0.0734 - val_accuracy: 0.9758 - 8s/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "1719/1719 - 8s - loss: 0.0568 - accuracy: 0.9838 - val_loss: 0.0723 - val_accuracy: 0.9784 - 8s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1719/1719 - 8s - loss: 0.0548 - accuracy: 0.9844 - val_loss: 0.0671 - val_accuracy: 0.9812 - 8s/epoch - 5ms/step\n",
      "Epoch 24/30\n",
      "1719/1719 - 8s - loss: 0.0531 - accuracy: 0.9854 - val_loss: 0.0719 - val_accuracy: 0.9794 - 8s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1719/1719 - 8s - loss: 0.0502 - accuracy: 0.9860 - val_loss: 0.0683 - val_accuracy: 0.9792 - 8s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1719/1719 - 8s - loss: 0.0495 - accuracy: 0.9861 - val_loss: 0.0670 - val_accuracy: 0.9820 - 8s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1719/1719 - 8s - loss: 0.0475 - accuracy: 0.9870 - val_loss: 0.0653 - val_accuracy: 0.9822 - 8s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1719/1719 - 8s - loss: 0.0454 - accuracy: 0.9878 - val_loss: 0.0696 - val_accuracy: 0.9806 - 8s/epoch - 5ms/step\n",
      "Epoch 29/30\n",
      "1719/1719 - 8s - loss: 0.0445 - accuracy: 0.9877 - val_loss: 0.0735 - val_accuracy: 0.9790 - 8s/epoch - 5ms/step\n",
      "Epoch 30/30\n",
      "1719/1719 - 8s - loss: 0.0429 - accuracy: 0.9885 - val_loss: 0.0740 - val_accuracy: 0.9762 - 8s/epoch - 5ms/step\n",
      "Pruning morphological model...\n",
      "\n",
      "Baseline test accuracy: \n",
      "20/20 [==============================] - 1s 20ms/step - loss: 0.0862 - accuracy: 0.9717\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 238200\n",
      "Weights that can be pruned: 231881\n",
      "Left parameters: 6319\n",
      "Unactive neurons: 0\n",
      "Parameter reduction of the model: 97%\n",
      "Parameter reduction of the morph layers: 98%\n",
      "\n",
      "Extreme pruned model with a TEP threshold of 1% . Test acuraccy\n",
      "20/20 [==============================] - 0s 7ms/step - loss: 0.0938 - accuracy: 0.9688\n",
      "Retraining MLP dense model...\n",
      "Epoch 1/40\n",
      "108/108 [==============================] - 4s 26ms/step - loss: 0.8466 - accuracy: 0.7467 - val_loss: 0.2776 - val_accuracy: 0.9286\n",
      "Epoch 2/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3351 - accuracy: 0.9009 - val_loss: 0.1953 - val_accuracy: 0.9498\n",
      "Epoch 3/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2598 - accuracy: 0.9230 - val_loss: 0.1583 - val_accuracy: 0.9582\n",
      "Epoch 4/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2182 - accuracy: 0.9349 - val_loss: 0.1375 - val_accuracy: 0.9638\n",
      "Epoch 5/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1915 - accuracy: 0.9425 - val_loss: 0.1226 - val_accuracy: 0.9658\n",
      "Epoch 6/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1690 - accuracy: 0.9496 - val_loss: 0.1100 - val_accuracy: 0.9684\n",
      "Epoch 7/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1538 - accuracy: 0.9540 - val_loss: 0.1015 - val_accuracy: 0.9696\n",
      "Epoch 8/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.9572 - val_loss: 0.0953 - val_accuracy: 0.9744\n",
      "Epoch 9/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1322 - accuracy: 0.9601 - val_loss: 0.0893 - val_accuracy: 0.9758\n",
      "Epoch 10/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1250 - accuracy: 0.9620 - val_loss: 0.0856 - val_accuracy: 0.9758\n",
      "Epoch 11/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1175 - accuracy: 0.9645 - val_loss: 0.0811 - val_accuracy: 0.9772\n",
      "Epoch 12/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1120 - accuracy: 0.9657 - val_loss: 0.0803 - val_accuracy: 0.9772\n",
      "Epoch 13/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1059 - accuracy: 0.9673 - val_loss: 0.0787 - val_accuracy: 0.9784\n",
      "Epoch 14/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1012 - accuracy: 0.9687 - val_loss: 0.0734 - val_accuracy: 0.9796\n",
      "Epoch 15/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0982 - accuracy: 0.9708 - val_loss: 0.0737 - val_accuracy: 0.9786\n",
      "Epoch 16/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0923 - accuracy: 0.9723 - val_loss: 0.0693 - val_accuracy: 0.9816\n",
      "Epoch 17/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0902 - accuracy: 0.9719 - val_loss: 0.0684 - val_accuracy: 0.9818\n",
      "Epoch 18/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0858 - accuracy: 0.9735 - val_loss: 0.0664 - val_accuracy: 0.9822\n",
      "Epoch 19/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0823 - accuracy: 0.9745 - val_loss: 0.0651 - val_accuracy: 0.9826\n",
      "Epoch 20/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0823 - accuracy: 0.9741 - val_loss: 0.0654 - val_accuracy: 0.9818\n",
      "Epoch 21/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0770 - accuracy: 0.9757 - val_loss: 0.0653 - val_accuracy: 0.9828\n",
      "Epoch 22/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0765 - accuracy: 0.9760 - val_loss: 0.0638 - val_accuracy: 0.9836\n",
      "Epoch 23/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 0.9765 - val_loss: 0.0621 - val_accuracy: 0.9838\n",
      "Epoch 24/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0707 - accuracy: 0.9779 - val_loss: 0.0606 - val_accuracy: 0.9856\n",
      "Epoch 25/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0689 - accuracy: 0.9782 - val_loss: 0.0617 - val_accuracy: 0.9836\n",
      "Epoch 26/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9787 - val_loss: 0.0587 - val_accuracy: 0.9850\n",
      "Epoch 27/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0660 - accuracy: 0.9794 - val_loss: 0.0601 - val_accuracy: 0.9848\n",
      "Epoch 28/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9796 - val_loss: 0.0607 - val_accuracy: 0.9844\n",
      "Epoch 29/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0618 - accuracy: 0.9804 - val_loss: 0.0587 - val_accuracy: 0.9848\n",
      "Epoch 30/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.0583 - val_accuracy: 0.9842\n",
      "Epoch 31/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0584 - accuracy: 0.9817 - val_loss: 0.0582 - val_accuracy: 0.9856\n",
      "Epoch 32/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0558 - accuracy: 0.9819 - val_loss: 0.0576 - val_accuracy: 0.9852\n",
      "Epoch 33/40\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0556 - accuracy: 0.9819 - val_loss: 0.0573 - val_accuracy: 0.9852\n",
      "Epoch 34/40\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.0534 - accuracy: 0.9828 - val_loss: 0.0570 - val_accuracy: 0.9856\n",
      "Epoch 35/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9831 - val_loss: 0.0552 - val_accuracy: 0.9862\n",
      "Epoch 36/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0516 - accuracy: 0.9835 - val_loss: 0.0565 - val_accuracy: 0.9858\n",
      "Epoch 37/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0511 - accuracy: 0.9839 - val_loss: 0.0572 - val_accuracy: 0.9850\n",
      "Epoch 38/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0479 - accuracy: 0.9844 - val_loss: 0.0576 - val_accuracy: 0.9860\n",
      "Epoch 39/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9840 - val_loss: 0.0551 - val_accuracy: 0.9856\n",
      "Epoch 40/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.0467 - accuracy: 0.9845 - val_loss: 0.0555 - val_accuracy: 0.9854\n",
      "Training morphological model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min (SoftMaxMin)   (55000, 100)              30000     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (55000, 10)               1000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31000 (121.09 KB)\n",
      "Trainable params: 31000 (121.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1719/1719 - 10s - loss: 1.1682 - accuracy: 0.7346 - val_loss: 0.5620 - val_accuracy: 0.9024 - 10s/epoch - 6ms/step\n",
      "Epoch 2/30\n",
      "1719/1719 - 7s - loss: 0.5185 - accuracy: 0.8861 - val_loss: 0.3647 - val_accuracy: 0.9274 - 7s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1719/1719 - 7s - loss: 0.3913 - accuracy: 0.9070 - val_loss: 0.2918 - val_accuracy: 0.9368 - 7s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1719/1719 - 7s - loss: 0.3284 - accuracy: 0.9197 - val_loss: 0.2548 - val_accuracy: 0.9434 - 7s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1719/1719 - 7s - loss: 0.2904 - accuracy: 0.9270 - val_loss: 0.2239 - val_accuracy: 0.9464 - 7s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1719/1719 - 7s - loss: 0.2634 - accuracy: 0.9325 - val_loss: 0.2034 - val_accuracy: 0.9504 - 7s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1719/1719 - 7s - loss: 0.2435 - accuracy: 0.9371 - val_loss: 0.1917 - val_accuracy: 0.9526 - 7s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1719/1719 - 7s - loss: 0.2282 - accuracy: 0.9402 - val_loss: 0.1809 - val_accuracy: 0.9524 - 7s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1719/1719 - 7s - loss: 0.2152 - accuracy: 0.9432 - val_loss: 0.1692 - val_accuracy: 0.9586 - 7s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1719/1719 - 7s - loss: 0.2046 - accuracy: 0.9454 - val_loss: 0.1691 - val_accuracy: 0.9544 - 7s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1719/1719 - 8s - loss: 0.1958 - accuracy: 0.9480 - val_loss: 0.1592 - val_accuracy: 0.9590 - 8s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1719/1719 - 7s - loss: 0.1885 - accuracy: 0.9494 - val_loss: 0.1516 - val_accuracy: 0.9624 - 7s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1719/1719 - 7s - loss: 0.1813 - accuracy: 0.9508 - val_loss: 0.1459 - val_accuracy: 0.9616 - 7s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1719/1719 - 7s - loss: 0.1756 - accuracy: 0.9524 - val_loss: 0.1469 - val_accuracy: 0.9600 - 7s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1719/1719 - 7s - loss: 0.1708 - accuracy: 0.9532 - val_loss: 0.1404 - val_accuracy: 0.9620 - 7s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1719/1719 - 7s - loss: 0.1657 - accuracy: 0.9551 - val_loss: 0.1347 - val_accuracy: 0.9628 - 7s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "1719/1719 - 7s - loss: 0.1615 - accuracy: 0.9553 - val_loss: 0.1314 - val_accuracy: 0.9640 - 7s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1719/1719 - 7s - loss: 0.1577 - accuracy: 0.9568 - val_loss: 0.1282 - val_accuracy: 0.9658 - 7s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1719/1719 - 7s - loss: 0.1537 - accuracy: 0.9577 - val_loss: 0.1261 - val_accuracy: 0.9660 - 7s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "1719/1719 - 7s - loss: 0.1506 - accuracy: 0.9584 - val_loss: 0.1249 - val_accuracy: 0.9652 - 7s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1719/1719 - 7s - loss: 0.1474 - accuracy: 0.9587 - val_loss: 0.1233 - val_accuracy: 0.9668 - 7s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1719/1719 - 7s - loss: 0.1443 - accuracy: 0.9602 - val_loss: 0.1194 - val_accuracy: 0.9692 - 7s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1719/1719 - 7s - loss: 0.1418 - accuracy: 0.9608 - val_loss: 0.1207 - val_accuracy: 0.9672 - 7s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1719/1719 - 7s - loss: 0.1397 - accuracy: 0.9615 - val_loss: 0.1187 - val_accuracy: 0.9678 - 7s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1719/1719 - 7s - loss: 0.1372 - accuracy: 0.9616 - val_loss: 0.1144 - val_accuracy: 0.9708 - 7s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1719/1719 - 7s - loss: 0.1352 - accuracy: 0.9620 - val_loss: 0.1182 - val_accuracy: 0.9670 - 7s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1719/1719 - 7s - loss: 0.1330 - accuracy: 0.9626 - val_loss: 0.1138 - val_accuracy: 0.9696 - 7s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1719/1719 - 7s - loss: 0.1306 - accuracy: 0.9637 - val_loss: 0.1134 - val_accuracy: 0.9712 - 7s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "1719/1719 - 7s - loss: 0.1290 - accuracy: 0.9637 - val_loss: 0.1093 - val_accuracy: 0.9722 - 7s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "1719/1719 - 7s - loss: 0.1271 - accuracy: 0.9643 - val_loss: 0.1098 - val_accuracy: 0.9720 - 7s/epoch - 4ms/step\n",
      "Pruning morphological model...\n",
      "\n",
      "Baseline test accuracy: \n",
      "20/20 [==============================] - 1s 14ms/step - loss: 0.1369 - accuracy: 0.9624\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 31000\n",
      "Weights that can be pruned: 29231\n",
      "Left parameters: 1769\n",
      "Unactive neurons: 0\n",
      "Parameter reduction of the model: 94%\n",
      "Parameter reduction of the morph layers: 97%\n",
      "\n",
      "Extreme pruned model with a TEP threshold of 1% . Test acuraccy\n",
      "20/20 [==============================] - 0s 3ms/step - loss: 0.1370 - accuracy: 0.9617\n",
      "Retraining MLP dense model...\n",
      "Epoch 1/40\n",
      "108/108 [==============================] - 4s 23ms/step - loss: 1.4455 - accuracy: 0.6063 - val_loss: 0.7085 - val_accuracy: 0.8926\n",
      "Epoch 2/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.6421 - accuracy: 0.8417 - val_loss: 0.3436 - val_accuracy: 0.9220\n",
      "Epoch 3/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.8746 - val_loss: 0.2538 - val_accuracy: 0.9352\n",
      "Epoch 4/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3757 - accuracy: 0.8915 - val_loss: 0.2145 - val_accuracy: 0.9408\n",
      "Epoch 5/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3337 - accuracy: 0.9021 - val_loss: 0.1903 - val_accuracy: 0.9478\n",
      "Epoch 6/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.3067 - accuracy: 0.9090 - val_loss: 0.1751 - val_accuracy: 0.9520\n",
      "Epoch 7/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2847 - accuracy: 0.9161 - val_loss: 0.1614 - val_accuracy: 0.9546\n",
      "Epoch 8/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2710 - accuracy: 0.9176 - val_loss: 0.1524 - val_accuracy: 0.9572\n",
      "Epoch 9/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2555 - accuracy: 0.9238 - val_loss: 0.1444 - val_accuracy: 0.9590\n",
      "Epoch 10/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2434 - accuracy: 0.9274 - val_loss: 0.1384 - val_accuracy: 0.9602\n",
      "Epoch 11/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2383 - accuracy: 0.9284 - val_loss: 0.1330 - val_accuracy: 0.9622\n",
      "Epoch 12/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2284 - accuracy: 0.9306 - val_loss: 0.1273 - val_accuracy: 0.9648\n",
      "Epoch 13/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2197 - accuracy: 0.9341 - val_loss: 0.1233 - val_accuracy: 0.9654\n",
      "Epoch 14/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2155 - accuracy: 0.9340 - val_loss: 0.1205 - val_accuracy: 0.9654\n",
      "Epoch 15/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2098 - accuracy: 0.9361 - val_loss: 0.1173 - val_accuracy: 0.9666\n",
      "Epoch 16/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.2060 - accuracy: 0.9381 - val_loss: 0.1144 - val_accuracy: 0.9664\n",
      "Epoch 17/40\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.2029 - accuracy: 0.9394 - val_loss: 0.1123 - val_accuracy: 0.9678\n",
      "Epoch 18/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1978 - accuracy: 0.9386 - val_loss: 0.1099 - val_accuracy: 0.9676\n",
      "Epoch 19/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1917 - accuracy: 0.9410 - val_loss: 0.1087 - val_accuracy: 0.9684\n",
      "Epoch 20/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1901 - accuracy: 0.9420 - val_loss: 0.1067 - val_accuracy: 0.9696\n",
      "Epoch 21/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1838 - accuracy: 0.9445 - val_loss: 0.1049 - val_accuracy: 0.9696\n",
      "Epoch 22/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1841 - accuracy: 0.9437 - val_loss: 0.1040 - val_accuracy: 0.9694\n",
      "Epoch 23/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1824 - accuracy: 0.9434 - val_loss: 0.1017 - val_accuracy: 0.9700\n",
      "Epoch 24/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1761 - accuracy: 0.9463 - val_loss: 0.0997 - val_accuracy: 0.9708\n",
      "Epoch 25/40\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.1755 - accuracy: 0.9461 - val_loss: 0.0984 - val_accuracy: 0.9704\n",
      "Epoch 26/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1748 - accuracy: 0.9455 - val_loss: 0.0967 - val_accuracy: 0.9716\n",
      "Epoch 27/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1715 - accuracy: 0.9469 - val_loss: 0.0959 - val_accuracy: 0.9712\n",
      "Epoch 28/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1721 - accuracy: 0.9484 - val_loss: 0.0964 - val_accuracy: 0.9718\n",
      "Epoch 29/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1685 - accuracy: 0.9483 - val_loss: 0.0953 - val_accuracy: 0.9722\n",
      "Epoch 30/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1659 - accuracy: 0.9482 - val_loss: 0.0935 - val_accuracy: 0.9716\n",
      "Epoch 31/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1657 - accuracy: 0.9492 - val_loss: 0.0930 - val_accuracy: 0.9732\n",
      "Epoch 32/40\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.1617 - accuracy: 0.9502 - val_loss: 0.0922 - val_accuracy: 0.9732\n",
      "Epoch 33/40\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.1593 - accuracy: 0.9506 - val_loss: 0.0909 - val_accuracy: 0.9726\n",
      "Epoch 34/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.9512 - val_loss: 0.0896 - val_accuracy: 0.9738\n",
      "Epoch 35/40\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.1594 - accuracy: 0.9511 - val_loss: 0.0896 - val_accuracy: 0.9732\n",
      "Epoch 36/40\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.1573 - accuracy: 0.9509 - val_loss: 0.0893 - val_accuracy: 0.9730\n",
      "Epoch 37/40\n",
      "108/108 [==============================] - 1s 5ms/step - loss: 0.1561 - accuracy: 0.9518 - val_loss: 0.0886 - val_accuracy: 0.9734\n",
      "Epoch 38/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1543 - accuracy: 0.9526 - val_loss: 0.0880 - val_accuracy: 0.9734\n",
      "Epoch 39/40\n",
      "108/108 [==============================] - 0s 4ms/step - loss: 0.1532 - accuracy: 0.9528 - val_loss: 0.0886 - val_accuracy: 0.9730\n",
      "Epoch 40/40\n",
      "108/108 [==============================] - 0s 5ms/step - loss: 0.1548 - accuracy: 0.9518 - val_loss: 0.0886 - val_accuracy: 0.9734\n",
      "Retraining MLP model...\n",
      "Epoch 1/30\n",
      "108/108 - 0s - loss: 0.1523 - accuracy: 0.9526 - val_loss: 0.0866 - val_accuracy: 0.9732 - 465ms/epoch - 4ms/step\n",
      "Epoch 2/30\n",
      "108/108 - 0s - loss: 0.1511 - accuracy: 0.9526 - val_loss: 0.0870 - val_accuracy: 0.9748 - 412ms/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "108/108 - 0s - loss: 0.1499 - accuracy: 0.9534 - val_loss: 0.0860 - val_accuracy: 0.9734 - 400ms/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "108/108 - 0s - loss: 0.1473 - accuracy: 0.9546 - val_loss: 0.0867 - val_accuracy: 0.9750 - 411ms/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "108/108 - 0s - loss: 0.1501 - accuracy: 0.9525 - val_loss: 0.0852 - val_accuracy: 0.9748 - 403ms/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "108/108 - 0s - loss: 0.1472 - accuracy: 0.9546 - val_loss: 0.0853 - val_accuracy: 0.9748 - 406ms/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "108/108 - 0s - loss: 0.1443 - accuracy: 0.9542 - val_loss: 0.0840 - val_accuracy: 0.9752 - 405ms/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "108/108 - 0s - loss: 0.1447 - accuracy: 0.9547 - val_loss: 0.0849 - val_accuracy: 0.9754 - 397ms/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "108/108 - 0s - loss: 0.1442 - accuracy: 0.9551 - val_loss: 0.0833 - val_accuracy: 0.9754 - 398ms/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "108/108 - 0s - loss: 0.1389 - accuracy: 0.9563 - val_loss: 0.0837 - val_accuracy: 0.9756 - 401ms/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "108/108 - 0s - loss: 0.1409 - accuracy: 0.9551 - val_loss: 0.0836 - val_accuracy: 0.9762 - 400ms/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "108/108 - 0s - loss: 0.1432 - accuracy: 0.9553 - val_loss: 0.0839 - val_accuracy: 0.9756 - 402ms/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "108/108 - 0s - loss: 0.1401 - accuracy: 0.9565 - val_loss: 0.0826 - val_accuracy: 0.9754 - 399ms/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "108/108 - 0s - loss: 0.1392 - accuracy: 0.9560 - val_loss: 0.0833 - val_accuracy: 0.9762 - 403ms/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "108/108 - 0s - loss: 0.1399 - accuracy: 0.9562 - val_loss: 0.0826 - val_accuracy: 0.9760 - 399ms/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "108/108 - 0s - loss: 0.1410 - accuracy: 0.9552 - val_loss: 0.0827 - val_accuracy: 0.9766 - 405ms/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "108/108 - 0s - loss: 0.1351 - accuracy: 0.9580 - val_loss: 0.0816 - val_accuracy: 0.9772 - 402ms/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "108/108 - 0s - loss: 0.1365 - accuracy: 0.9579 - val_loss: 0.0826 - val_accuracy: 0.9774 - 411ms/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "108/108 - 0s - loss: 0.1363 - accuracy: 0.9569 - val_loss: 0.0812 - val_accuracy: 0.9772 - 410ms/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "108/108 - 0s - loss: 0.1378 - accuracy: 0.9573 - val_loss: 0.0819 - val_accuracy: 0.9754 - 398ms/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "108/108 - 0s - loss: 0.1331 - accuracy: 0.9589 - val_loss: 0.0820 - val_accuracy: 0.9774 - 400ms/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "108/108 - 0s - loss: 0.1355 - accuracy: 0.9584 - val_loss: 0.0828 - val_accuracy: 0.9778 - 402ms/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "108/108 - 0s - loss: 0.1365 - accuracy: 0.9567 - val_loss: 0.0821 - val_accuracy: 0.9764 - 409ms/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "108/108 - 0s - loss: 0.1372 - accuracy: 0.9571 - val_loss: 0.0818 - val_accuracy: 0.9778 - 413ms/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "108/108 - 0s - loss: 0.1344 - accuracy: 0.9586 - val_loss: 0.0825 - val_accuracy: 0.9766 - 403ms/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "108/108 - 0s - loss: 0.1340 - accuracy: 0.9589 - val_loss: 0.0817 - val_accuracy: 0.9760 - 402ms/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "108/108 - 0s - loss: 0.1339 - accuracy: 0.9579 - val_loss: 0.0821 - val_accuracy: 0.9762 - 402ms/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "108/108 - 0s - loss: 0.1339 - accuracy: 0.9580 - val_loss: 0.0819 - val_accuracy: 0.9764 - 446ms/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "108/108 - 0s - loss: 0.1314 - accuracy: 0.9585 - val_loss: 0.0810 - val_accuracy: 0.9784 - 407ms/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "108/108 - 0s - loss: 0.1312 - accuracy: 0.9593 - val_loss: 0.0804 - val_accuracy: 0.9770 - 409ms/epoch - 4ms/step\n",
      "Accuracy of the MLP model:\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0971 - accuracy: 0.9708\n",
      "# Parameters of the model: 266610\n",
      "# Parameters pruned: 261112\n",
      "Remaining weights (%): 2.062188214995687\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "pruned, model_hp1, model_ep1 = pruning_tool_MLP_v4_1.pruning_MLP(baselineModel, x_train, y_train, x_val, y_val, x_test, y_test, batch_size=512, morph_epochs=30, mlp_epochs=30, mlp_epochs_refit=40, p=1, optimizer_config=tf.optimizers.serialize(optimizer), extreme=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parámetros mdoelo sin prunar: 266610\n",
      "Parámetros mdoelo prunado: 5112\n",
      "Pesos restantes: 1.91740744908293%\n"
     ]
    }
   ],
   "source": [
    "w0 = pruned.layers[0].get_weights()[0]\n",
    "w1 = pruned.layers[1].get_weights()[0]\n",
    "params_prunedModel = pruned.count_params() - (w0.size - np.count_nonzero(w0) + w1.size - np.count_nonzero(w1))\n",
    "print(\"Parámetros mdoelo sin prunar: \" + str(pruned.count_params()))\n",
    "print(\"Parámetros mdoelo prunado: \" + str(params_prunedModel))\n",
    "print(\"Pesos restantes: \" + str(params_prunedModel/pruned.count_params()*100) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST MODEL 300-100 v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineModel = tf.keras.models.load_model('../models/paper/MLP_MNIST_300_100_v2/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 300)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               30100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 100)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "baselineModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "235200\n",
      "235200\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "w = baselineModel.layers[0].get_weights()[0]\n",
    "b = baselineModel.layers[0].get_weights()[1]\n",
    "print(w.size)\n",
    "print(np.count_nonzero(w))\n",
    "print(np.count_nonzero(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineModel2 = keras.Sequential([\n",
    "    keras.layers.Input(shape=784),\n",
    "    keras.layers.Dense(300, activation=\"relu\"),\n",
    "    keras.layers.Dense(100, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselineModel2.set_weights(baselineModel.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "baselineModel2.compile(optimizer=optimizer,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=['accuracy'],\n",
    "        jit_compile=True\n",
    "    ) #from logits = Ture if no activation function on the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 3ms/step - loss: 0.0628 - accuracy: 0.9819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06277354061603546, 0.9818999767303467]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselineModel2.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training morphological model...\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min (SoftMaxMin)   (55000, 300)              235200    \n",
      "                                                                 \n",
      " dense_4 (Dense)             (55000, 10)               3000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238200 (930.47 KB)\n",
      "Trainable params: 238200 (930.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1719/1719 - 10s - loss: 0.8425 - accuracy: 0.7669 - val_loss: 0.2688 - val_accuracy: 0.9318 - 10s/epoch - 6ms/step\n",
      "Epoch 2/30\n",
      "1719/1719 - 8s - loss: 0.2849 - accuracy: 0.9183 - val_loss: 0.1962 - val_accuracy: 0.9490 - 8s/epoch - 5ms/step\n",
      "Epoch 3/30\n",
      "1719/1719 - 8s - loss: 0.2210 - accuracy: 0.9371 - val_loss: 0.1613 - val_accuracy: 0.9572 - 8s/epoch - 5ms/step\n",
      "Epoch 4/30\n",
      "1719/1719 - 8s - loss: 0.1855 - accuracy: 0.9468 - val_loss: 0.1379 - val_accuracy: 0.9628 - 8s/epoch - 5ms/step\n",
      "Epoch 5/30\n",
      "1719/1719 - 8s - loss: 0.1617 - accuracy: 0.9535 - val_loss: 0.1259 - val_accuracy: 0.9676 - 8s/epoch - 5ms/step\n",
      "Epoch 6/30\n",
      "1719/1719 - 8s - loss: 0.1435 - accuracy: 0.9591 - val_loss: 0.1129 - val_accuracy: 0.9704 - 8s/epoch - 5ms/step\n",
      "Epoch 7/30\n",
      "1719/1719 - 8s - loss: 0.1310 - accuracy: 0.9630 - val_loss: 0.1093 - val_accuracy: 0.9708 - 8s/epoch - 5ms/step\n",
      "Epoch 8/30\n",
      "1719/1719 - 8s - loss: 0.1204 - accuracy: 0.9657 - val_loss: 0.1022 - val_accuracy: 0.9716 - 8s/epoch - 5ms/step\n",
      "Epoch 9/30\n",
      "1719/1719 - 8s - loss: 0.1115 - accuracy: 0.9676 - val_loss: 0.0942 - val_accuracy: 0.9760 - 8s/epoch - 5ms/step\n",
      "Epoch 10/30\n",
      "1719/1719 - 8s - loss: 0.1037 - accuracy: 0.9702 - val_loss: 0.1046 - val_accuracy: 0.9710 - 8s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1719/1719 - 8s - loss: 0.0964 - accuracy: 0.9726 - val_loss: 0.0941 - val_accuracy: 0.9736 - 8s/epoch - 5ms/step\n",
      "Epoch 12/30\n",
      "1719/1719 - 8s - loss: 0.0913 - accuracy: 0.9743 - val_loss: 0.0866 - val_accuracy: 0.9778 - 8s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1719/1719 - 8s - loss: 0.0854 - accuracy: 0.9756 - val_loss: 0.0889 - val_accuracy: 0.9774 - 8s/epoch - 5ms/step\n",
      "Epoch 14/30\n",
      "1719/1719 - 8s - loss: 0.0811 - accuracy: 0.9772 - val_loss: 0.0856 - val_accuracy: 0.9776 - 8s/epoch - 5ms/step\n",
      "Epoch 15/30\n",
      "1719/1719 - 8s - loss: 0.0772 - accuracy: 0.9785 - val_loss: 0.0806 - val_accuracy: 0.9788 - 8s/epoch - 5ms/step\n",
      "Epoch 16/30\n",
      "1719/1719 - 8s - loss: 0.0739 - accuracy: 0.9796 - val_loss: 0.0935 - val_accuracy: 0.9742 - 8s/epoch - 5ms/step\n",
      "Epoch 17/30\n",
      "1719/1719 - 8s - loss: 0.0705 - accuracy: 0.9799 - val_loss: 0.0827 - val_accuracy: 0.9774 - 8s/epoch - 5ms/step\n",
      "Epoch 18/30\n",
      "1719/1719 - 8s - loss: 0.0665 - accuracy: 0.9816 - val_loss: 0.0750 - val_accuracy: 0.9776 - 8s/epoch - 5ms/step\n",
      "Epoch 19/30\n",
      "1719/1719 - 8s - loss: 0.0641 - accuracy: 0.9819 - val_loss: 0.0893 - val_accuracy: 0.9738 - 8s/epoch - 5ms/step\n",
      "Epoch 20/30\n",
      "1719/1719 - 8s - loss: 0.0614 - accuracy: 0.9829 - val_loss: 0.0789 - val_accuracy: 0.9780 - 8s/epoch - 5ms/step\n",
      "Epoch 21/30\n",
      "1719/1719 - 8s - loss: 0.0590 - accuracy: 0.9835 - val_loss: 0.0762 - val_accuracy: 0.9770 - 8s/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "1719/1719 - 8s - loss: 0.0561 - accuracy: 0.9844 - val_loss: 0.0770 - val_accuracy: 0.9770 - 8s/epoch - 5ms/step\n",
      "Epoch 23/30\n",
      "1719/1719 - 8s - loss: 0.0538 - accuracy: 0.9854 - val_loss: 0.0842 - val_accuracy: 0.9756 - 8s/epoch - 5ms/step\n",
      "Epoch 24/30\n",
      "1719/1719 - 8s - loss: 0.0523 - accuracy: 0.9857 - val_loss: 0.0700 - val_accuracy: 0.9786 - 8s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1719/1719 - 8s - loss: 0.0503 - accuracy: 0.9861 - val_loss: 0.0724 - val_accuracy: 0.9798 - 8s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1719/1719 - 8s - loss: 0.0483 - accuracy: 0.9864 - val_loss: 0.0719 - val_accuracy: 0.9796 - 8s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1719/1719 - 8s - loss: 0.0463 - accuracy: 0.9878 - val_loss: 0.0882 - val_accuracy: 0.9736 - 8s/epoch - 5ms/step\n",
      "Epoch 28/30\n",
      "1719/1719 - 8s - loss: 0.0452 - accuracy: 0.9878 - val_loss: 0.0814 - val_accuracy: 0.9774 - 8s/epoch - 5ms/step\n",
      "Epoch 29/30\n",
      "1719/1719 - 8s - loss: 0.0439 - accuracy: 0.9883 - val_loss: 0.0725 - val_accuracy: 0.9794 - 8s/epoch - 5ms/step\n",
      "Epoch 30/30\n",
      "1719/1719 - 8s - loss: 0.0416 - accuracy: 0.9894 - val_loss: 0.0694 - val_accuracy: 0.9800 - 8s/epoch - 4ms/step\n",
      "Pruning morphological model...\n",
      "\n",
      "Baseline test accuracy: \n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.0781 - accuracy: 0.9759\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 238200\n",
      "Weights that can be pruned: 221832\n",
      "Left parameters: 16368\n",
      "Unactive neurons: 0\n",
      "Parameter reduction of the model: 93%\n",
      "Parameter reduction of the morph layers: 94%\n",
      "\n",
      "Hard pruned model. Test acuraccy\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.0781 - accuracy: 0.9760\n",
      "Retraining MLP dense model...\n",
      "Epoch 1/40\n",
      "860/860 [==============================] - 5s 5ms/step - loss: 0.2789 - accuracy: 0.9185 - val_loss: 0.1404 - val_accuracy: 0.9596\n",
      "Epoch 2/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.1244 - accuracy: 0.9629 - val_loss: 0.0973 - val_accuracy: 0.9706\n",
      "Epoch 3/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0887 - accuracy: 0.9725 - val_loss: 0.0926 - val_accuracy: 0.9722\n",
      "Epoch 4/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0701 - accuracy: 0.9784 - val_loss: 0.0868 - val_accuracy: 0.9754\n",
      "Epoch 5/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0562 - accuracy: 0.9826 - val_loss: 0.0845 - val_accuracy: 0.9756\n",
      "Epoch 6/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0457 - accuracy: 0.9861 - val_loss: 0.0792 - val_accuracy: 0.9790\n",
      "Epoch 7/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0379 - accuracy: 0.9885 - val_loss: 0.0841 - val_accuracy: 0.9768\n",
      "Epoch 8/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0313 - accuracy: 0.9902 - val_loss: 0.0836 - val_accuracy: 0.9768\n",
      "Epoch 9/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0263 - accuracy: 0.9918 - val_loss: 0.0858 - val_accuracy: 0.9776\n",
      "Epoch 10/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0214 - accuracy: 0.9938 - val_loss: 0.0919 - val_accuracy: 0.9752\n",
      "Epoch 11/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0183 - accuracy: 0.9943 - val_loss: 0.0845 - val_accuracy: 0.9788\n",
      "Epoch 12/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0143 - accuracy: 0.9958 - val_loss: 0.1093 - val_accuracy: 0.9744\n",
      "Epoch 13/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0142 - accuracy: 0.9955 - val_loss: 0.0991 - val_accuracy: 0.9768\n",
      "Epoch 14/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0111 - accuracy: 0.9969 - val_loss: 0.1049 - val_accuracy: 0.9766\n",
      "Epoch 15/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0093 - accuracy: 0.9972 - val_loss: 0.1082 - val_accuracy: 0.9762\n",
      "Epoch 16/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0080 - accuracy: 0.9978 - val_loss: 0.1096 - val_accuracy: 0.9754\n",
      "Epoch 17/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0075 - accuracy: 0.9979 - val_loss: 0.1087 - val_accuracy: 0.9774\n",
      "Epoch 18/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.1149 - val_accuracy: 0.9770\n",
      "Epoch 19/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.1215 - val_accuracy: 0.9752\n",
      "Epoch 20/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0062 - accuracy: 0.9981 - val_loss: 0.1179 - val_accuracy: 0.9768\n",
      "Epoch 21/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0045 - accuracy: 0.9987 - val_loss: 0.1549 - val_accuracy: 0.9740\n",
      "Epoch 22/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0042 - accuracy: 0.9989 - val_loss: 0.1178 - val_accuracy: 0.9776\n",
      "Epoch 23/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0054 - accuracy: 0.9980 - val_loss: 0.1460 - val_accuracy: 0.9754\n",
      "Epoch 24/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0040 - accuracy: 0.9990 - val_loss: 0.1262 - val_accuracy: 0.9796\n",
      "Epoch 25/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0026 - accuracy: 0.9993 - val_loss: 0.1272 - val_accuracy: 0.9778\n",
      "Epoch 26/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0065 - accuracy: 0.9980 - val_loss: 0.1445 - val_accuracy: 0.9778\n",
      "Epoch 27/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0038 - accuracy: 0.9987 - val_loss: 0.1251 - val_accuracy: 0.9804\n",
      "Epoch 28/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 0.1344 - val_accuracy: 0.9780\n",
      "Epoch 29/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9995 - val_loss: 0.1390 - val_accuracy: 0.9790\n",
      "Epoch 30/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0070 - accuracy: 0.9975 - val_loss: 0.1415 - val_accuracy: 0.9768\n",
      "Epoch 31/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0022 - accuracy: 0.9994 - val_loss: 0.1484 - val_accuracy: 0.9792\n",
      "Epoch 32/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0031 - accuracy: 0.9990 - val_loss: 0.1858 - val_accuracy: 0.9744\n",
      "Epoch 33/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.1393 - val_accuracy: 0.9790\n",
      "Epoch 34/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0037 - accuracy: 0.9987 - val_loss: 0.1591 - val_accuracy: 0.9780\n",
      "Epoch 35/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0020 - accuracy: 0.9994 - val_loss: 0.1438 - val_accuracy: 0.9790\n",
      "Epoch 36/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 0.1755 - val_accuracy: 0.9752\n",
      "Epoch 37/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0034 - accuracy: 0.9990 - val_loss: 0.1873 - val_accuracy: 0.9744\n",
      "Epoch 38/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.1573 - val_accuracy: 0.9768\n",
      "Epoch 39/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0028 - accuracy: 0.9991 - val_loss: 0.1565 - val_accuracy: 0.9762\n",
      "Epoch 40/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0021 - accuracy: 0.9993 - val_loss: 0.1568 - val_accuracy: 0.9792\n",
      "Training morphological model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min (SoftMaxMin)   (55000, 100)              30000     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (55000, 10)               1000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31000 (121.09 KB)\n",
      "Trainable params: 31000 (121.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1719/1719 - 9s - loss: 1.0663 - accuracy: 0.7281 - val_loss: 0.4462 - val_accuracy: 0.8940 - 9s/epoch - 6ms/step\n",
      "Epoch 2/30\n",
      "1719/1719 - 7s - loss: 0.4104 - accuracy: 0.8945 - val_loss: 0.2896 - val_accuracy: 0.9284 - 7s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1719/1719 - 7s - loss: 0.3010 - accuracy: 0.9201 - val_loss: 0.2287 - val_accuracy: 0.9448 - 7s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1719/1719 - 7s - loss: 0.2500 - accuracy: 0.9320 - val_loss: 0.2013 - val_accuracy: 0.9482 - 7s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1719/1719 - 7s - loss: 0.2192 - accuracy: 0.9393 - val_loss: 0.1805 - val_accuracy: 0.9514 - 7s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1719/1719 - 7s - loss: 0.1974 - accuracy: 0.9465 - val_loss: 0.1708 - val_accuracy: 0.9534 - 7s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1719/1719 - 7s - loss: 0.1803 - accuracy: 0.9497 - val_loss: 0.1586 - val_accuracy: 0.9564 - 7s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1719/1719 - 7s - loss: 0.1670 - accuracy: 0.9535 - val_loss: 0.1467 - val_accuracy: 0.9604 - 7s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1719/1719 - 7s - loss: 0.1554 - accuracy: 0.9564 - val_loss: 0.1418 - val_accuracy: 0.9600 - 7s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1719/1719 - 7s - loss: 0.1467 - accuracy: 0.9588 - val_loss: 0.1349 - val_accuracy: 0.9632 - 7s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1719/1719 - 7s - loss: 0.1387 - accuracy: 0.9607 - val_loss: 0.1352 - val_accuracy: 0.9632 - 7s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1719/1719 - 7s - loss: 0.1323 - accuracy: 0.9622 - val_loss: 0.1382 - val_accuracy: 0.9626 - 7s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1719/1719 - 7s - loss: 0.1261 - accuracy: 0.9637 - val_loss: 0.1230 - val_accuracy: 0.9656 - 7s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1719/1719 - 7s - loss: 0.1207 - accuracy: 0.9660 - val_loss: 0.1177 - val_accuracy: 0.9666 - 7s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1719/1719 - 7s - loss: 0.1157 - accuracy: 0.9675 - val_loss: 0.1140 - val_accuracy: 0.9692 - 7s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1719/1719 - 7s - loss: 0.1116 - accuracy: 0.9686 - val_loss: 0.1131 - val_accuracy: 0.9676 - 7s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "1719/1719 - 7s - loss: 0.1076 - accuracy: 0.9692 - val_loss: 0.1122 - val_accuracy: 0.9694 - 7s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1719/1719 - 7s - loss: 0.1037 - accuracy: 0.9704 - val_loss: 0.1097 - val_accuracy: 0.9690 - 7s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1719/1719 - 7s - loss: 0.1008 - accuracy: 0.9712 - val_loss: 0.1084 - val_accuracy: 0.9688 - 7s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "1719/1719 - 7s - loss: 0.0979 - accuracy: 0.9717 - val_loss: 0.1060 - val_accuracy: 0.9696 - 7s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1719/1719 - 7s - loss: 0.0955 - accuracy: 0.9727 - val_loss: 0.1053 - val_accuracy: 0.9704 - 7s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1719/1719 - 7s - loss: 0.0927 - accuracy: 0.9737 - val_loss: 0.1087 - val_accuracy: 0.9710 - 7s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1719/1719 - 7s - loss: 0.0907 - accuracy: 0.9740 - val_loss: 0.1041 - val_accuracy: 0.9704 - 7s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1719/1719 - 7s - loss: 0.0887 - accuracy: 0.9749 - val_loss: 0.1074 - val_accuracy: 0.9696 - 7s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1719/1719 - 7s - loss: 0.0861 - accuracy: 0.9750 - val_loss: 0.1027 - val_accuracy: 0.9712 - 7s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1719/1719 - 7s - loss: 0.0849 - accuracy: 0.9757 - val_loss: 0.1029 - val_accuracy: 0.9700 - 7s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1719/1719 - 7s - loss: 0.0827 - accuracy: 0.9761 - val_loss: 0.1033 - val_accuracy: 0.9702 - 7s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1719/1719 - 7s - loss: 0.0814 - accuracy: 0.9768 - val_loss: 0.1041 - val_accuracy: 0.9690 - 7s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "1719/1719 - 7s - loss: 0.0796 - accuracy: 0.9770 - val_loss: 0.0993 - val_accuracy: 0.9700 - 7s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "1719/1719 - 7s - loss: 0.0787 - accuracy: 0.9772 - val_loss: 0.0980 - val_accuracy: 0.9716 - 7s/epoch - 4ms/step\n",
      "Pruning morphological model...\n",
      "\n",
      "Baseline test accuracy: \n",
      "157/157 [==============================] - 1s 4ms/step - loss: 0.1223 - accuracy: 0.9645\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 31000\n",
      "Weights that can be pruned: 25810\n",
      "Left parameters: 5190\n",
      "Unactive neurons: 0\n",
      "Parameter reduction of the model: 83%\n",
      "Parameter reduction of the morph layers: 86%\n",
      "\n",
      "Hard pruned model. Test acuraccy\n",
      "157/157 [==============================] - 0s 3ms/step - loss: 0.1223 - accuracy: 0.9645\n",
      "Retraining MLP dense model...\n",
      "Epoch 1/40\n",
      "860/860 [==============================] - 5s 4ms/step - loss: 0.1207 - accuracy: 0.9616 - val_loss: 0.1041 - val_accuracy: 0.9718\n",
      "Epoch 2/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0579 - accuracy: 0.9825 - val_loss: 0.0970 - val_accuracy: 0.9734\n",
      "Epoch 3/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0435 - accuracy: 0.9871 - val_loss: 0.0991 - val_accuracy: 0.9734\n",
      "Epoch 4/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0355 - accuracy: 0.9893 - val_loss: 0.0946 - val_accuracy: 0.9782\n",
      "Epoch 5/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0296 - accuracy: 0.9917 - val_loss: 0.0960 - val_accuracy: 0.9776\n",
      "Epoch 6/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0252 - accuracy: 0.9927 - val_loss: 0.0994 - val_accuracy: 0.9770\n",
      "Epoch 7/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.1089 - val_accuracy: 0.9770\n",
      "Epoch 8/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0189 - accuracy: 0.9949 - val_loss: 0.1033 - val_accuracy: 0.9782\n",
      "Epoch 9/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0168 - accuracy: 0.9956 - val_loss: 0.1037 - val_accuracy: 0.9778\n",
      "Epoch 10/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0144 - accuracy: 0.9966 - val_loss: 0.1079 - val_accuracy: 0.9788\n",
      "Epoch 11/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0125 - accuracy: 0.9969 - val_loss: 0.1119 - val_accuracy: 0.9780\n",
      "Epoch 12/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0113 - accuracy: 0.9973 - val_loss: 0.1157 - val_accuracy: 0.9766\n",
      "Epoch 13/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0100 - accuracy: 0.9977 - val_loss: 0.1164 - val_accuracy: 0.9768\n",
      "Epoch 14/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0088 - accuracy: 0.9979 - val_loss: 0.1241 - val_accuracy: 0.9760\n",
      "Epoch 15/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0077 - accuracy: 0.9985 - val_loss: 0.1224 - val_accuracy: 0.9776\n",
      "Epoch 16/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.1301 - val_accuracy: 0.9780\n",
      "Epoch 17/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0055 - accuracy: 0.9991 - val_loss: 0.1353 - val_accuracy: 0.9740\n",
      "Epoch 18/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0057 - accuracy: 0.9988 - val_loss: 0.1333 - val_accuracy: 0.9770\n",
      "Epoch 19/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0053 - accuracy: 0.9990 - val_loss: 0.1373 - val_accuracy: 0.9764\n",
      "Epoch 20/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0042 - accuracy: 0.9994 - val_loss: 0.1407 - val_accuracy: 0.9756\n",
      "Epoch 21/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0038 - accuracy: 0.9993 - val_loss: 0.1383 - val_accuracy: 0.9760\n",
      "Epoch 22/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0029 - accuracy: 0.9997 - val_loss: 0.1528 - val_accuracy: 0.9744\n",
      "Epoch 23/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0055 - accuracy: 0.9987 - val_loss: 0.1409 - val_accuracy: 0.9780\n",
      "Epoch 24/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.1362 - val_accuracy: 0.9782\n",
      "Epoch 25/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.1569 - val_accuracy: 0.9750\n",
      "Epoch 26/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0039 - accuracy: 0.9990 - val_loss: 0.1552 - val_accuracy: 0.9762\n",
      "Epoch 27/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.1538 - val_accuracy: 0.9784\n",
      "Epoch 28/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.1491 - val_accuracy: 0.9776\n",
      "Epoch 29/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.1529 - val_accuracy: 0.9774\n",
      "Epoch 30/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0041 - accuracy: 0.9989 - val_loss: 0.1543 - val_accuracy: 0.9768\n",
      "Epoch 31/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 9.6080e-04 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 0.9762\n",
      "Epoch 32/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 8.6591e-04 - accuracy: 0.9999 - val_loss: 0.1884 - val_accuracy: 0.9714\n",
      "Epoch 33/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0024 - accuracy: 0.9997 - val_loss: 0.1679 - val_accuracy: 0.9746\n",
      "Epoch 34/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 0.1849 - val_accuracy: 0.9746\n",
      "Epoch 35/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.1645 - val_accuracy: 0.9764\n",
      "Epoch 36/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.1727 - val_accuracy: 0.9758\n",
      "Epoch 37/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 0.1781 - val_accuracy: 0.9766\n",
      "Epoch 38/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 7.4983e-04 - accuracy: 0.9999 - val_loss: 0.1725 - val_accuracy: 0.9764\n",
      "Epoch 39/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 3.8473e-04 - accuracy: 1.0000 - val_loss: 0.1763 - val_accuracy: 0.9766\n",
      "Epoch 40/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 2.5442e-04 - accuracy: 1.0000 - val_loss: 0.1808 - val_accuracy: 0.9774\n",
      "Retraining MLP model...\n",
      "Epoch 1/10\n",
      "860/860 - 3s - loss: 6.5051e-04 - accuracy: 0.9998 - val_loss: 0.2433 - val_accuracy: 0.9698 - 3s/epoch - 3ms/step\n",
      "Epoch 2/10\n",
      "860/860 - 2s - loss: 0.0076 - accuracy: 0.9975 - val_loss: 0.1759 - val_accuracy: 0.9766 - 2s/epoch - 3ms/step\n",
      "Epoch 3/10\n",
      "860/860 - 2s - loss: 8.3821e-04 - accuracy: 0.9999 - val_loss: 0.1824 - val_accuracy: 0.9774 - 2s/epoch - 3ms/step\n",
      "Epoch 4/10\n",
      "860/860 - 2s - loss: 2.9273e-04 - accuracy: 1.0000 - val_loss: 0.1836 - val_accuracy: 0.9766 - 2s/epoch - 3ms/step\n",
      "Epoch 5/10\n",
      "860/860 - 3s - loss: 2.1390e-04 - accuracy: 1.0000 - val_loss: 0.1865 - val_accuracy: 0.9768 - 3s/epoch - 3ms/step\n",
      "Epoch 6/10\n",
      "860/860 - 2s - loss: 9.0633e-04 - accuracy: 0.9998 - val_loss: 0.2216 - val_accuracy: 0.9716 - 2s/epoch - 3ms/step\n",
      "Epoch 7/10\n",
      "860/860 - 2s - loss: 0.0069 - accuracy: 0.9979 - val_loss: 0.2004 - val_accuracy: 0.9758 - 2s/epoch - 3ms/step\n",
      "Epoch 8/10\n",
      "860/860 - 2s - loss: 9.5349e-04 - accuracy: 0.9998 - val_loss: 0.1914 - val_accuracy: 0.9744 - 2s/epoch - 3ms/step\n",
      "Epoch 9/10\n",
      "860/860 - 2s - loss: 3.0615e-04 - accuracy: 1.0000 - val_loss: 0.1876 - val_accuracy: 0.9760 - 2s/epoch - 3ms/step\n",
      "Epoch 10/10\n",
      "860/860 - 2s - loss: 1.7109e-04 - accuracy: 1.0000 - val_loss: 0.1872 - val_accuracy: 0.9762 - 2s/epoch - 3ms/step\n",
      "Accuracy of the MLP model:\n",
      "313/313 [==============================] - 2s 4ms/step - loss: 0.1622 - accuracy: 0.9758\n",
      "# Parameters of the model: 266610\n",
      "# Parameters pruned: 247642\n",
      "# Parameters remaining: 18968\n",
      "Remaining weights (%): 7.114511833764675\n"
     ]
    }
   ],
   "source": [
    "pruned, model_hp1, model_ep1 = pruning_tool_MLP_v4_1.pruning_MLP(baselineModel2, x_train, y_train, x_val, y_val, x_test, y_test, batch_size=64, morph_epochs=30, mlp_epochs=10, mlp_epochs_refit=40, p=0, optimizer_config=tf.optimizers.serialize(optimizer), extreme=False)\n",
    "#97.69"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 0.2209 - val_accuracy: 0.9752\n",
      "Epoch 2/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 5.9961e-04 - accuracy: 0.9998 - val_loss: 0.2083 - val_accuracy: 0.9784\n",
      "Epoch 3/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 1.3255e-04 - accuracy: 1.0000 - val_loss: 0.2102 - val_accuracy: 0.9774\n",
      "Epoch 4/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 7.2287e-05 - accuracy: 1.0000 - val_loss: 0.2095 - val_accuracy: 0.9780\n",
      "Epoch 5/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 5.8857e-05 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9782\n",
      "Epoch 6/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 5.0785e-05 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9782\n",
      "Epoch 7/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 5.3147e-05 - accuracy: 1.0000 - val_loss: 0.2158 - val_accuracy: 0.9780\n",
      "Epoch 8/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0070 - accuracy: 0.9977 - val_loss: 0.2223 - val_accuracy: 0.9748\n",
      "Epoch 9/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.2141 - val_accuracy: 0.9780\n",
      "Epoch 10/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 2.9141e-04 - accuracy: 1.0000 - val_loss: 0.2112 - val_accuracy: 0.9782\n",
      "Epoch 11/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 9.7459e-05 - accuracy: 1.0000 - val_loss: 0.2068 - val_accuracy: 0.9786\n",
      "Epoch 12/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 6.4960e-05 - accuracy: 1.0000 - val_loss: 0.2076 - val_accuracy: 0.9786\n",
      "Epoch 13/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 5.2547e-05 - accuracy: 1.0000 - val_loss: 0.2098 - val_accuracy: 0.9782\n",
      "Epoch 14/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 4.4828e-05 - accuracy: 1.0000 - val_loss: 0.2120 - val_accuracy: 0.9780\n",
      "Epoch 15/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 3.7788e-05 - accuracy: 1.0000 - val_loss: 0.2136 - val_accuracy: 0.9778\n",
      "Epoch 16/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 3.2648e-05 - accuracy: 1.0000 - val_loss: 0.2145 - val_accuracy: 0.9784\n",
      "Epoch 17/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 8.3376e-04 - accuracy: 0.9997 - val_loss: 0.2984 - val_accuracy: 0.9692\n",
      "Epoch 18/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.2163 - val_accuracy: 0.9774\n",
      "Epoch 19/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 5.1993e-04 - accuracy: 0.9999 - val_loss: 0.2180 - val_accuracy: 0.9778\n",
      "Epoch 20/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 1.6878e-04 - accuracy: 1.0000 - val_loss: 0.2218 - val_accuracy: 0.9776\n",
      "Epoch 21/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 6.5001e-05 - accuracy: 1.0000 - val_loss: 0.2192 - val_accuracy: 0.9776\n",
      "Epoch 22/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 4.8447e-05 - accuracy: 1.0000 - val_loss: 0.2188 - val_accuracy: 0.9774\n",
      "Epoch 23/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 3.9608e-05 - accuracy: 1.0000 - val_loss: 0.2190 - val_accuracy: 0.9776\n",
      "Epoch 24/40\n",
      "860/860 [==============================] - 2s 3ms/step - loss: 3.3358e-05 - accuracy: 1.0000 - val_loss: 0.2206 - val_accuracy: 0.9772\n",
      "Epoch 25/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 2.8343e-05 - accuracy: 1.0000 - val_loss: 0.2214 - val_accuracy: 0.9774\n",
      "Epoch 26/40\n",
      "860/860 [==============================] - 3s 3ms/step - loss: 2.4100e-05 - accuracy: 1.0000 - val_loss: 0.2250 - val_accuracy: 0.9774\n",
      "Epoch 26: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f58847defd0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "pruned.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=40, batch_size=64, callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.2105 - accuracy: 0.9757\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21047671139240265, 0.9757000207901001]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.0200 - accuracy: 0.9948 - val_loss: 0.1103 - val_accuracy: 0.9764\n",
      "Epoch 2/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0190 - accuracy: 0.9953 - val_loss: 0.1101 - val_accuracy: 0.9764\n",
      "Epoch 3/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0186 - accuracy: 0.9957 - val_loss: 0.1091 - val_accuracy: 0.9762\n",
      "Epoch 4/40\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.0183 - accuracy: 0.9959 - val_loss: 0.1095 - val_accuracy: 0.9758\n",
      "Epoch 5/40\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.0181 - accuracy: 0.9961 - val_loss: 0.1109 - val_accuracy: 0.9764\n",
      "Epoch 6/40\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.0180 - accuracy: 0.9960 - val_loss: 0.1103 - val_accuracy: 0.9770\n",
      "Epoch 7/40\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.0179 - accuracy: 0.9961 - val_loss: 0.1098 - val_accuracy: 0.9762\n",
      "Epoch 8/40\n",
      "1719/1719 [==============================] - 4s 2ms/step - loss: 0.0178 - accuracy: 0.9962 - val_loss: 0.1110 - val_accuracy: 0.9760\n",
      "Epoch 9/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0176 - accuracy: 0.9961 - val_loss: 0.1113 - val_accuracy: 0.9758\n",
      "Epoch 10/40\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.0175 - accuracy: 0.9964 - val_loss: 0.1116 - val_accuracy: 0.9760\n",
      "Epoch 11/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0174 - accuracy: 0.9962 - val_loss: 0.1121 - val_accuracy: 0.9756\n",
      "Epoch 12/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.0173 - accuracy: 0.9964 - val_loss: 0.1109 - val_accuracy: 0.9768\n",
      "Epoch 13/40\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.0173 - accuracy: 0.9965 - val_loss: 0.1116 - val_accuracy: 0.9766\n",
      "Epoch 13: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f5a4e79ba60>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pruned, model_hp1, model_ep1 = pruning_tool_MLP_v4_1.pruning_MLP(baselineModel2, x_train, y_train, x_val, y_val, x_test, y_test, batch_size=64, morph_epochs=30, mlp_epochs=10, mlp_epochs_refit=40, p=1, optimizer_config=tf.optimizers.serialize(optimizer), extreme=True)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "pruned.compile(optimizer=optimizer,\n",
    "        loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        metrics=['accuracy'],\n",
    "        jit_compile=True\n",
    "    ) #from logits = Ture if no activation function on the output\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "pruned.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=40, callbacks=[es])\n",
    "#96.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.1248 - accuracy: 0.9706\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.12476731091737747, 0.9706000089645386]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST 300 100 acc=0.982"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 300)               235500    \n",
      "                                                                 \n",
      " modelLayer_1_0 (Dense)      (None, 100)               30100     \n",
      "                                                                 \n",
      " modelLayer_2_1 (Dense)      (None, 10)                1010      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 266610 (1.02 MB)\n",
      "Trainable params: 266610 (1.02 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0890 - accuracy: 0.9821\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08896878361701965, 0.9821000099182129]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselineModel = tf.keras.models.load_model('../models/MLP_MNIST_300_100')\n",
    "baselineModel.summary()\n",
    "baselineModel.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': {'module': 'keras.optimizers',\n",
       "  'class_name': 'Adam',\n",
       "  'config': {'name': 'Adam',\n",
       "   'weight_decay': None,\n",
       "   'clipnorm': None,\n",
       "   'global_clipnorm': None,\n",
       "   'clipvalue': None,\n",
       "   'use_ema': False,\n",
       "   'ema_momentum': 0.99,\n",
       "   'ema_overwrite_frequency': None,\n",
       "   'jit_compile': True,\n",
       "   'is_legacy_optimizer': False,\n",
       "   'learning_rate': 0.0010000000474974513,\n",
       "   'beta_1': 0.9,\n",
       "   'beta_2': 0.999,\n",
       "   'epsilon': 1e-07,\n",
       "   'amsgrad': False},\n",
       "  'registered_name': None},\n",
       " 'loss': {'module': 'keras.losses',\n",
       "  'class_name': 'SparseCategoricalCrossentropy',\n",
       "  'config': {'reduction': 'auto',\n",
       "   'name': 'sparse_categorical_crossentropy',\n",
       "   'from_logits': False,\n",
       "   'ignore_class': None,\n",
       "   'fn': 'sparse_categorical_crossentropy'},\n",
       "  'registered_name': None},\n",
       " 'metrics': [[{'module': 'keras.metrics',\n",
       "    'class_name': 'MeanMetricWrapper',\n",
       "    'config': {'name': 'accuracy',\n",
       "     'dtype': 'float32',\n",
       "     'fn': {'module': 'builtins',\n",
       "      'class_name': 'function',\n",
       "      'config': 'sparse_categorical_accuracy',\n",
       "      'registered_name': 'function'}},\n",
       "    'registered_name': None}]],\n",
       " 'loss_weights': None,\n",
       " 'weighted_metrics': None,\n",
       " 'run_eagerly': None,\n",
       " 'steps_per_execution': None,\n",
       " 'jit_compile': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baselineModel.get_compile_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=15)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training morphological model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min (SoftMaxMin)   (55000, 300)              235200    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (55000, 10)               3000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 238200 (930.47 KB)\n",
      "Trainable params: 238200 (930.47 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1719/1719 - 10s - loss: 0.8347 - accuracy: 0.7674 - val_loss: 0.2626 - val_accuracy: 0.9300 - 10s/epoch - 6ms/step\n",
      "Epoch 2/30\n",
      "1719/1719 - 8s - loss: 0.2793 - accuracy: 0.9196 - val_loss: 0.1891 - val_accuracy: 0.9466 - 8s/epoch - 5ms/step\n",
      "Epoch 3/30\n",
      "1719/1719 - 8s - loss: 0.2161 - accuracy: 0.9374 - val_loss: 0.1525 - val_accuracy: 0.9580 - 8s/epoch - 5ms/step\n",
      "Epoch 4/30\n",
      "1719/1719 - 8s - loss: 0.1820 - accuracy: 0.9472 - val_loss: 0.1354 - val_accuracy: 0.9654 - 8s/epoch - 5ms/step\n",
      "Epoch 5/30\n",
      "1719/1719 - 8s - loss: 0.1580 - accuracy: 0.9557 - val_loss: 0.1215 - val_accuracy: 0.9690 - 8s/epoch - 5ms/step\n",
      "Epoch 6/30\n",
      "1719/1719 - 8s - loss: 0.1428 - accuracy: 0.9586 - val_loss: 0.1154 - val_accuracy: 0.9698 - 8s/epoch - 5ms/step\n",
      "Epoch 7/30\n",
      "1719/1719 - 8s - loss: 0.1292 - accuracy: 0.9627 - val_loss: 0.1009 - val_accuracy: 0.9740 - 8s/epoch - 5ms/step\n",
      "Epoch 8/30\n",
      "1719/1719 - 8s - loss: 0.1189 - accuracy: 0.9662 - val_loss: 0.1018 - val_accuracy: 0.9712 - 8s/epoch - 5ms/step\n",
      "Epoch 9/30\n",
      "1719/1719 - 8s - loss: 0.1107 - accuracy: 0.9682 - val_loss: 0.0927 - val_accuracy: 0.9776 - 8s/epoch - 5ms/step\n",
      "Epoch 10/30\n",
      "1719/1719 - 8s - loss: 0.1029 - accuracy: 0.9706 - val_loss: 0.0882 - val_accuracy: 0.9762 - 8s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1719/1719 - 8s - loss: 0.0962 - accuracy: 0.9729 - val_loss: 0.0829 - val_accuracy: 0.9780 - 8s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1719/1719 - 8s - loss: 0.0915 - accuracy: 0.9739 - val_loss: 0.0864 - val_accuracy: 0.9766 - 8s/epoch - 5ms/step\n",
      "Epoch 13/30\n",
      "1719/1719 - 8s - loss: 0.0860 - accuracy: 0.9753 - val_loss: 0.0857 - val_accuracy: 0.9758 - 8s/epoch - 5ms/step\n",
      "Epoch 14/30\n",
      "1719/1719 - 8s - loss: 0.0815 - accuracy: 0.9768 - val_loss: 0.0758 - val_accuracy: 0.9772 - 8s/epoch - 5ms/step\n",
      "Epoch 15/30\n",
      "1719/1719 - 8s - loss: 0.0777 - accuracy: 0.9778 - val_loss: 0.0739 - val_accuracy: 0.9794 - 8s/epoch - 5ms/step\n",
      "Epoch 16/30\n",
      "1719/1719 - 8s - loss: 0.0744 - accuracy: 0.9789 - val_loss: 0.0755 - val_accuracy: 0.9794 - 8s/epoch - 5ms/step\n",
      "Epoch 17/30\n",
      "1719/1719 - 8s - loss: 0.0699 - accuracy: 0.9806 - val_loss: 0.0712 - val_accuracy: 0.9806 - 8s/epoch - 5ms/step\n",
      "Epoch 18/30\n",
      "1719/1719 - 8s - loss: 0.0667 - accuracy: 0.9815 - val_loss: 0.0671 - val_accuracy: 0.9816 - 8s/epoch - 5ms/step\n",
      "Epoch 19/30\n",
      "1719/1719 - 8s - loss: 0.0639 - accuracy: 0.9823 - val_loss: 0.0748 - val_accuracy: 0.9778 - 8s/epoch - 5ms/step\n",
      "Epoch 20/30\n",
      "1719/1719 - 8s - loss: 0.0615 - accuracy: 0.9826 - val_loss: 0.0680 - val_accuracy: 0.9804 - 8s/epoch - 5ms/step\n",
      "Epoch 21/30\n",
      "1719/1719 - 8s - loss: 0.0595 - accuracy: 0.9832 - val_loss: 0.0714 - val_accuracy: 0.9796 - 8s/epoch - 5ms/step\n",
      "Epoch 22/30\n",
      "1719/1719 - 8s - loss: 0.0567 - accuracy: 0.9842 - val_loss: 0.0706 - val_accuracy: 0.9800 - 8s/epoch - 5ms/step\n",
      "Epoch 23/30\n",
      "1719/1719 - 8s - loss: 0.0546 - accuracy: 0.9850 - val_loss: 0.0697 - val_accuracy: 0.9800 - 8s/epoch - 5ms/step\n",
      "Epoch 24/30\n",
      "1719/1719 - 8s - loss: 0.0528 - accuracy: 0.9856 - val_loss: 0.0814 - val_accuracy: 0.9764 - 8s/epoch - 5ms/step\n",
      "Epoch 25/30\n",
      "1719/1719 - 8s - loss: 0.0505 - accuracy: 0.9864 - val_loss: 0.0644 - val_accuracy: 0.9826 - 8s/epoch - 5ms/step\n",
      "Epoch 26/30\n",
      "1719/1719 - 8s - loss: 0.0488 - accuracy: 0.9867 - val_loss: 0.0652 - val_accuracy: 0.9812 - 8s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1719/1719 - 8s - loss: 0.0470 - accuracy: 0.9876 - val_loss: 0.0661 - val_accuracy: 0.9826 - 8s/epoch - 5ms/step\n",
      "Epoch 28/30\n",
      "1719/1719 - 8s - loss: 0.0457 - accuracy: 0.9877 - val_loss: 0.0667 - val_accuracy: 0.9808 - 8s/epoch - 5ms/step\n",
      "Epoch 29/30\n",
      "1719/1719 - 8s - loss: 0.0436 - accuracy: 0.9885 - val_loss: 0.0749 - val_accuracy: 0.9806 - 8s/epoch - 5ms/step\n",
      "Epoch 30/30\n",
      "1719/1719 - 8s - loss: 0.0423 - accuracy: 0.9887 - val_loss: 0.0762 - val_accuracy: 0.9788 - 8s/epoch - 5ms/step\n",
      "Pruning morphological model...\n",
      "\n",
      "Baseline test accuracy: \n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.0859 - accuracy: 0.9727\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 238200\n",
      "Weights that can be pruned: 233211\n",
      "Left parameters: 4989\n",
      "Unactive neurons: 0\n",
      "Parameter reduction of the model: 97%\n",
      "Parameter reduction of the morph layers: 99%\n",
      "\n",
      "Extreme pruned model with a TEP threshold of 3% . Test acuraccy\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.1229 - accuracy: 0.9607\n",
      "Retraining MLP dense model...\n",
      "Epoch 1/40\n",
      "1719/1719 [==============================] - 8s 4ms/step - loss: 0.6218 - accuracy: 0.8069 - val_loss: 0.3114 - val_accuracy: 0.9068\n",
      "Epoch 2/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3657 - accuracy: 0.8880 - val_loss: 0.2563 - val_accuracy: 0.9240\n",
      "Epoch 3/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3081 - accuracy: 0.9063 - val_loss: 0.2428 - val_accuracy: 0.9286\n",
      "Epoch 4/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2778 - accuracy: 0.9151 - val_loss: 0.2099 - val_accuracy: 0.9376\n",
      "Epoch 5/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2567 - accuracy: 0.9211 - val_loss: 0.2115 - val_accuracy: 0.9344\n",
      "Epoch 6/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2426 - accuracy: 0.9257 - val_loss: 0.1937 - val_accuracy: 0.9406\n",
      "Epoch 7/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2316 - accuracy: 0.9293 - val_loss: 0.1939 - val_accuracy: 0.9422\n",
      "Epoch 8/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2211 - accuracy: 0.9325 - val_loss: 0.1793 - val_accuracy: 0.9464\n",
      "Epoch 9/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2132 - accuracy: 0.9358 - val_loss: 0.1776 - val_accuracy: 0.9474\n",
      "Epoch 10/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2057 - accuracy: 0.9377 - val_loss: 0.1748 - val_accuracy: 0.9502\n",
      "Epoch 11/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1986 - accuracy: 0.9401 - val_loss: 0.1713 - val_accuracy: 0.9498\n",
      "Epoch 12/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1924 - accuracy: 0.9419 - val_loss: 0.1674 - val_accuracy: 0.9506\n",
      "Epoch 13/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1891 - accuracy: 0.9430 - val_loss: 0.1737 - val_accuracy: 0.9494\n",
      "Epoch 14/40\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.1838 - accuracy: 0.9441 - val_loss: 0.1860 - val_accuracy: 0.9478\n",
      "Epoch 15/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1801 - accuracy: 0.9459 - val_loss: 0.1695 - val_accuracy: 0.9518\n",
      "Epoch 16/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1773 - accuracy: 0.9460 - val_loss: 0.1671 - val_accuracy: 0.9540\n",
      "Epoch 17/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1746 - accuracy: 0.9469 - val_loss: 0.1668 - val_accuracy: 0.9564\n",
      "Epoch 18/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1731 - accuracy: 0.9479 - val_loss: 0.1633 - val_accuracy: 0.9564\n",
      "Epoch 19/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1692 - accuracy: 0.9486 - val_loss: 0.1589 - val_accuracy: 0.9548\n",
      "Epoch 20/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1674 - accuracy: 0.9493 - val_loss: 0.1602 - val_accuracy: 0.9542\n",
      "Epoch 21/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1662 - accuracy: 0.9494 - val_loss: 0.1720 - val_accuracy: 0.9502\n",
      "Epoch 22/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1644 - accuracy: 0.9503 - val_loss: 0.1556 - val_accuracy: 0.9548\n",
      "Epoch 23/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1638 - accuracy: 0.9500 - val_loss: 0.1571 - val_accuracy: 0.9552\n",
      "Epoch 24/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1621 - accuracy: 0.9502 - val_loss: 0.1519 - val_accuracy: 0.9584\n",
      "Epoch 25/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1603 - accuracy: 0.9510 - val_loss: 0.1563 - val_accuracy: 0.9570\n",
      "Epoch 26/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1587 - accuracy: 0.9515 - val_loss: 0.1570 - val_accuracy: 0.9570\n",
      "Epoch 27/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1584 - accuracy: 0.9523 - val_loss: 0.1518 - val_accuracy: 0.9590\n",
      "Epoch 28/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1572 - accuracy: 0.9523 - val_loss: 0.1553 - val_accuracy: 0.9562\n",
      "Epoch 29/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1560 - accuracy: 0.9529 - val_loss: 0.1554 - val_accuracy: 0.9566\n",
      "Epoch 30/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1557 - accuracy: 0.9531 - val_loss: 0.1508 - val_accuracy: 0.9606\n",
      "Epoch 31/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1549 - accuracy: 0.9534 - val_loss: 0.1621 - val_accuracy: 0.9520\n",
      "Epoch 32/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1542 - accuracy: 0.9536 - val_loss: 0.1513 - val_accuracy: 0.9574\n",
      "Epoch 33/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1532 - accuracy: 0.9537 - val_loss: 0.1525 - val_accuracy: 0.9610\n",
      "Epoch 34/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1520 - accuracy: 0.9541 - val_loss: 0.1520 - val_accuracy: 0.9572\n",
      "Epoch 35/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1522 - accuracy: 0.9537 - val_loss: 0.1549 - val_accuracy: 0.9574\n",
      "Epoch 36/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1506 - accuracy: 0.9538 - val_loss: 0.1570 - val_accuracy: 0.9586\n",
      "Epoch 37/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1497 - accuracy: 0.9546 - val_loss: 0.1478 - val_accuracy: 0.9590\n",
      "Epoch 38/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1500 - accuracy: 0.9550 - val_loss: 0.1523 - val_accuracy: 0.9598\n",
      "Epoch 39/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1488 - accuracy: 0.9550 - val_loss: 0.1517 - val_accuracy: 0.9592\n",
      "Epoch 40/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.1485 - accuracy: 0.9548 - val_loss: 0.1480 - val_accuracy: 0.9604\n",
      "Training morphological model...\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " soft_max_min (SoftMaxMin)   (55000, 100)              30000     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (55000, 10)               1000      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 31000 (121.09 KB)\n",
      "Trainable params: 31000 (121.09 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1719/1719 - 10s - loss: 1.1446 - accuracy: 0.7047 - val_loss: 0.5483 - val_accuracy: 0.8724 - 10s/epoch - 6ms/step\n",
      "Epoch 2/30\n",
      "1719/1719 - 7s - loss: 0.5333 - accuracy: 0.8577 - val_loss: 0.3896 - val_accuracy: 0.9020 - 7s/epoch - 4ms/step\n",
      "Epoch 3/30\n",
      "1719/1719 - 7s - loss: 0.4370 - accuracy: 0.8783 - val_loss: 0.3304 - val_accuracy: 0.9152 - 7s/epoch - 4ms/step\n",
      "Epoch 4/30\n",
      "1719/1719 - 7s - loss: 0.3903 - accuracy: 0.8887 - val_loss: 0.2977 - val_accuracy: 0.9238 - 7s/epoch - 4ms/step\n",
      "Epoch 5/30\n",
      "1719/1719 - 7s - loss: 0.3615 - accuracy: 0.8971 - val_loss: 0.2777 - val_accuracy: 0.9272 - 7s/epoch - 4ms/step\n",
      "Epoch 6/30\n",
      "1719/1719 - 7s - loss: 0.3411 - accuracy: 0.9032 - val_loss: 0.2604 - val_accuracy: 0.9292 - 7s/epoch - 4ms/step\n",
      "Epoch 7/30\n",
      "1719/1719 - 7s - loss: 0.3252 - accuracy: 0.9070 - val_loss: 0.2477 - val_accuracy: 0.9340 - 7s/epoch - 4ms/step\n",
      "Epoch 8/30\n",
      "1719/1719 - 7s - loss: 0.3136 - accuracy: 0.9097 - val_loss: 0.2392 - val_accuracy: 0.9340 - 7s/epoch - 4ms/step\n",
      "Epoch 9/30\n",
      "1719/1719 - 7s - loss: 0.3032 - accuracy: 0.9131 - val_loss: 0.2337 - val_accuracy: 0.9332 - 7s/epoch - 4ms/step\n",
      "Epoch 10/30\n",
      "1719/1719 - 7s - loss: 0.2953 - accuracy: 0.9155 - val_loss: 0.2261 - val_accuracy: 0.9394 - 7s/epoch - 4ms/step\n",
      "Epoch 11/30\n",
      "1719/1719 - 7s - loss: 0.2884 - accuracy: 0.9169 - val_loss: 0.2218 - val_accuracy: 0.9382 - 7s/epoch - 4ms/step\n",
      "Epoch 12/30\n",
      "1719/1719 - 7s - loss: 0.2816 - accuracy: 0.9189 - val_loss: 0.2181 - val_accuracy: 0.9384 - 7s/epoch - 4ms/step\n",
      "Epoch 13/30\n",
      "1719/1719 - 7s - loss: 0.2765 - accuracy: 0.9205 - val_loss: 0.2152 - val_accuracy: 0.9418 - 7s/epoch - 4ms/step\n",
      "Epoch 14/30\n",
      "1719/1719 - 7s - loss: 0.2717 - accuracy: 0.9214 - val_loss: 0.2102 - val_accuracy: 0.9406 - 7s/epoch - 4ms/step\n",
      "Epoch 15/30\n",
      "1719/1719 - 7s - loss: 0.2671 - accuracy: 0.9224 - val_loss: 0.2087 - val_accuracy: 0.9422 - 7s/epoch - 4ms/step\n",
      "Epoch 16/30\n",
      "1719/1719 - 7s - loss: 0.2631 - accuracy: 0.9234 - val_loss: 0.2035 - val_accuracy: 0.9436 - 7s/epoch - 4ms/step\n",
      "Epoch 17/30\n",
      "1719/1719 - 7s - loss: 0.2591 - accuracy: 0.9246 - val_loss: 0.2037 - val_accuracy: 0.9436 - 7s/epoch - 4ms/step\n",
      "Epoch 18/30\n",
      "1719/1719 - 7s - loss: 0.2564 - accuracy: 0.9258 - val_loss: 0.1989 - val_accuracy: 0.9444 - 7s/epoch - 4ms/step\n",
      "Epoch 19/30\n",
      "1719/1719 - 7s - loss: 0.2532 - accuracy: 0.9258 - val_loss: 0.1971 - val_accuracy: 0.9448 - 7s/epoch - 4ms/step\n",
      "Epoch 20/30\n",
      "1719/1719 - 7s - loss: 0.2502 - accuracy: 0.9270 - val_loss: 0.1950 - val_accuracy: 0.9470 - 7s/epoch - 4ms/step\n",
      "Epoch 21/30\n",
      "1719/1719 - 7s - loss: 0.2472 - accuracy: 0.9275 - val_loss: 0.1914 - val_accuracy: 0.9478 - 7s/epoch - 4ms/step\n",
      "Epoch 22/30\n",
      "1719/1719 - 7s - loss: 0.2447 - accuracy: 0.9283 - val_loss: 0.1920 - val_accuracy: 0.9462 - 7s/epoch - 4ms/step\n",
      "Epoch 23/30\n",
      "1719/1719 - 7s - loss: 0.2424 - accuracy: 0.9286 - val_loss: 0.1882 - val_accuracy: 0.9486 - 7s/epoch - 4ms/step\n",
      "Epoch 24/30\n",
      "1719/1719 - 7s - loss: 0.2396 - accuracy: 0.9301 - val_loss: 0.1947 - val_accuracy: 0.9428 - 7s/epoch - 4ms/step\n",
      "Epoch 25/30\n",
      "1719/1719 - 7s - loss: 0.2378 - accuracy: 0.9303 - val_loss: 0.1862 - val_accuracy: 0.9462 - 7s/epoch - 4ms/step\n",
      "Epoch 26/30\n",
      "1719/1719 - 7s - loss: 0.2351 - accuracy: 0.9314 - val_loss: 0.1910 - val_accuracy: 0.9470 - 7s/epoch - 4ms/step\n",
      "Epoch 27/30\n",
      "1719/1719 - 7s - loss: 0.2340 - accuracy: 0.9312 - val_loss: 0.1843 - val_accuracy: 0.9474 - 7s/epoch - 4ms/step\n",
      "Epoch 28/30\n",
      "1719/1719 - 7s - loss: 0.2318 - accuracy: 0.9316 - val_loss: 0.1872 - val_accuracy: 0.9464 - 7s/epoch - 4ms/step\n",
      "Epoch 29/30\n",
      "1719/1719 - 7s - loss: 0.2299 - accuracy: 0.9327 - val_loss: 0.1820 - val_accuracy: 0.9454 - 7s/epoch - 4ms/step\n",
      "Epoch 30/30\n",
      "1719/1719 - 7s - loss: 0.2284 - accuracy: 0.9326 - val_loss: 0.1804 - val_accuracy: 0.9472 - 7s/epoch - 4ms/step\n",
      "Pruning morphological model...\n",
      "\n",
      "Baseline test accuracy: \n",
      "313/313 [==============================] - 1s 4ms/step - loss: 0.2124 - accuracy: 0.9365\n",
      "Forward pass started...\n",
      "Forward pass ended...\n",
      "Total paramaters: 31000\n",
      "Weights that can be pruned: 29474\n",
      "Left parameters: 1526\n",
      "Unactive neurons: 0\n",
      "Parameter reduction of the model: 95%\n",
      "Parameter reduction of the morph layers: 98%\n",
      "\n",
      "Extreme pruned model with a TEP threshold of 0.1% . Test acuraccy\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2124 - accuracy: 0.9363\n",
      "Retraining MLP dense model...\n",
      "Epoch 1/40\n",
      "1719/1719 [==============================] - 7s 4ms/step - loss: 0.8052 - accuracy: 0.7608 - val_loss: 0.4271 - val_accuracy: 0.8768\n",
      "Epoch 2/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4787 - accuracy: 0.8540 - val_loss: 0.3570 - val_accuracy: 0.8932\n",
      "Epoch 3/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4321 - accuracy: 0.8697 - val_loss: 0.3433 - val_accuracy: 0.8988\n",
      "Epoch 4/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.4072 - accuracy: 0.8769 - val_loss: 0.3212 - val_accuracy: 0.9066\n",
      "Epoch 5/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3915 - accuracy: 0.8817 - val_loss: 0.3064 - val_accuracy: 0.9094\n",
      "Epoch 6/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3814 - accuracy: 0.8844 - val_loss: 0.2960 - val_accuracy: 0.9106\n",
      "Epoch 7/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3733 - accuracy: 0.8869 - val_loss: 0.2860 - val_accuracy: 0.9146\n",
      "Epoch 8/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3675 - accuracy: 0.8889 - val_loss: 0.2915 - val_accuracy: 0.9126\n",
      "Epoch 9/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3611 - accuracy: 0.8896 - val_loss: 0.2901 - val_accuracy: 0.9124\n",
      "Epoch 10/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3569 - accuracy: 0.8917 - val_loss: 0.2795 - val_accuracy: 0.9142\n",
      "Epoch 11/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3524 - accuracy: 0.8919 - val_loss: 0.2810 - val_accuracy: 0.9144\n",
      "Epoch 12/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3479 - accuracy: 0.8937 - val_loss: 0.2712 - val_accuracy: 0.9188\n",
      "Epoch 13/40\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3439 - accuracy: 0.8954 - val_loss: 0.2724 - val_accuracy: 0.9192\n",
      "Epoch 14/40\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3421 - accuracy: 0.8964 - val_loss: 0.2687 - val_accuracy: 0.9168\n",
      "Epoch 15/40\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.3381 - accuracy: 0.8967 - val_loss: 0.2611 - val_accuracy: 0.9240\n",
      "Epoch 16/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3352 - accuracy: 0.8980 - val_loss: 0.2591 - val_accuracy: 0.9202\n",
      "Epoch 17/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3324 - accuracy: 0.8985 - val_loss: 0.2614 - val_accuracy: 0.9194\n",
      "Epoch 18/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3298 - accuracy: 0.8987 - val_loss: 0.2579 - val_accuracy: 0.9210\n",
      "Epoch 19/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3275 - accuracy: 0.8992 - val_loss: 0.2568 - val_accuracy: 0.9214\n",
      "Epoch 20/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3246 - accuracy: 0.9006 - val_loss: 0.2528 - val_accuracy: 0.9232\n",
      "Epoch 21/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3228 - accuracy: 0.9009 - val_loss: 0.2533 - val_accuracy: 0.9230\n",
      "Epoch 22/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3211 - accuracy: 0.9007 - val_loss: 0.2555 - val_accuracy: 0.9244\n",
      "Epoch 23/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3192 - accuracy: 0.9023 - val_loss: 0.2572 - val_accuracy: 0.9194\n",
      "Epoch 24/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3171 - accuracy: 0.9036 - val_loss: 0.2525 - val_accuracy: 0.9226\n",
      "Epoch 25/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3153 - accuracy: 0.9034 - val_loss: 0.2546 - val_accuracy: 0.9218\n",
      "Epoch 26/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3153 - accuracy: 0.9037 - val_loss: 0.2537 - val_accuracy: 0.9222\n",
      "Epoch 27/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3135 - accuracy: 0.9038 - val_loss: 0.2470 - val_accuracy: 0.9248\n",
      "Epoch 28/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3119 - accuracy: 0.9043 - val_loss: 0.2518 - val_accuracy: 0.9238\n",
      "Epoch 29/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3100 - accuracy: 0.9049 - val_loss: 0.2495 - val_accuracy: 0.9214\n",
      "Epoch 30/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3088 - accuracy: 0.9045 - val_loss: 0.2445 - val_accuracy: 0.9248\n",
      "Epoch 31/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3075 - accuracy: 0.9061 - val_loss: 0.2411 - val_accuracy: 0.9264\n",
      "Epoch 32/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3067 - accuracy: 0.9060 - val_loss: 0.2439 - val_accuracy: 0.9250\n",
      "Epoch 33/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3044 - accuracy: 0.9063 - val_loss: 0.2450 - val_accuracy: 0.9272\n",
      "Epoch 34/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3041 - accuracy: 0.9062 - val_loss: 0.2402 - val_accuracy: 0.9268\n",
      "Epoch 35/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3022 - accuracy: 0.9079 - val_loss: 0.2374 - val_accuracy: 0.9246\n",
      "Epoch 36/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3016 - accuracy: 0.9070 - val_loss: 0.2388 - val_accuracy: 0.9250\n",
      "Epoch 37/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.3005 - accuracy: 0.9080 - val_loss: 0.2392 - val_accuracy: 0.9268\n",
      "Epoch 38/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2997 - accuracy: 0.9075 - val_loss: 0.2457 - val_accuracy: 0.9236\n",
      "Epoch 39/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2981 - accuracy: 0.9086 - val_loss: 0.2343 - val_accuracy: 0.9272\n",
      "Epoch 40/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2968 - accuracy: 0.9089 - val_loss: 0.2398 - val_accuracy: 0.9282\n",
      "Retraining MLP model...\n",
      "1719/1719 - 5s - loss: 0.2951 - accuracy: 0.9103 - val_loss: 0.2335 - val_accuracy: 0.9274 - 5s/epoch - 3ms/step\n",
      "Accuracy of the MLP model:\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2773 - accuracy: 0.9173\n",
      "# Parameters of the model: 266610\n",
      "# Parameters pruned: 262685\n",
      "# Parameters remaining: 3925\n",
      "Remaining weights (%): 1.4721878399159822\n"
     ]
    }
   ],
   "source": [
    "pruned, _, _ = pruning_tool_MLP_v4_2.pruning_MLP(baselineModel, x_train, y_train, x_val, y_val, x_test, y_test, batch_size=32, morph_epochs=30, mlp_epochs=1, mlp_epochs_refit=40, p=0, pList=[3, 0.1], optimizer_config=tf.optimizers.serialize(optimizer), extreme=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2950 - accuracy: 0.9100 - val_loss: 0.2325 - val_accuracy: 0.9300\n",
      "Epoch 2/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2933 - accuracy: 0.9095 - val_loss: 0.2312 - val_accuracy: 0.9266\n",
      "Epoch 3/40\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2925 - accuracy: 0.9097 - val_loss: 0.2351 - val_accuracy: 0.9276\n",
      "Epoch 4/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2923 - accuracy: 0.9097 - val_loss: 0.2319 - val_accuracy: 0.9286\n",
      "Epoch 5/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2906 - accuracy: 0.9103 - val_loss: 0.2271 - val_accuracy: 0.9312\n",
      "Epoch 6/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2894 - accuracy: 0.9107 - val_loss: 0.2316 - val_accuracy: 0.9298\n",
      "Epoch 7/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2886 - accuracy: 0.9122 - val_loss: 0.2254 - val_accuracy: 0.9322\n",
      "Epoch 8/40\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2878 - accuracy: 0.9116 - val_loss: 0.2268 - val_accuracy: 0.9324\n",
      "Epoch 9/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2872 - accuracy: 0.9125 - val_loss: 0.2314 - val_accuracy: 0.9302\n",
      "Epoch 10/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2864 - accuracy: 0.9118 - val_loss: 0.2252 - val_accuracy: 0.9306\n",
      "Epoch 11/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2853 - accuracy: 0.9136 - val_loss: 0.2242 - val_accuracy: 0.9336\n",
      "Epoch 12/40\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2834 - accuracy: 0.9133 - val_loss: 0.2219 - val_accuracy: 0.9352\n",
      "Epoch 13/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2836 - accuracy: 0.9133 - val_loss: 0.2231 - val_accuracy: 0.9328\n",
      "Epoch 14/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2824 - accuracy: 0.9131 - val_loss: 0.2226 - val_accuracy: 0.9324\n",
      "Epoch 15/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2805 - accuracy: 0.9144 - val_loss: 0.2209 - val_accuracy: 0.9342\n",
      "Epoch 16/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2805 - accuracy: 0.9148 - val_loss: 0.2251 - val_accuracy: 0.9346\n",
      "Epoch 17/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2803 - accuracy: 0.9138 - val_loss: 0.2207 - val_accuracy: 0.9372\n",
      "Epoch 18/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2794 - accuracy: 0.9148 - val_loss: 0.2217 - val_accuracy: 0.9346\n",
      "Epoch 19/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2788 - accuracy: 0.9148 - val_loss: 0.2244 - val_accuracy: 0.9346\n",
      "Epoch 20/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2784 - accuracy: 0.9148 - val_loss: 0.2186 - val_accuracy: 0.9356\n",
      "Epoch 21/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2772 - accuracy: 0.9154 - val_loss: 0.2175 - val_accuracy: 0.9376\n",
      "Epoch 22/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2763 - accuracy: 0.9166 - val_loss: 0.2207 - val_accuracy: 0.9350\n",
      "Epoch 23/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2760 - accuracy: 0.9157 - val_loss: 0.2208 - val_accuracy: 0.9346\n",
      "Epoch 24/40\n",
      "1719/1719 [==============================] - 4s 3ms/step - loss: 0.2751 - accuracy: 0.9156 - val_loss: 0.2204 - val_accuracy: 0.9346\n",
      "Epoch 25/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2746 - accuracy: 0.9153 - val_loss: 0.2222 - val_accuracy: 0.9336\n",
      "Epoch 26/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2746 - accuracy: 0.9164 - val_loss: 0.2149 - val_accuracy: 0.9384\n",
      "Epoch 27/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2739 - accuracy: 0.9156 - val_loss: 0.2123 - val_accuracy: 0.9386\n",
      "Epoch 28/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2730 - accuracy: 0.9168 - val_loss: 0.2146 - val_accuracy: 0.9366\n",
      "Epoch 29/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2719 - accuracy: 0.9177 - val_loss: 0.2120 - val_accuracy: 0.9378\n",
      "Epoch 30/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2724 - accuracy: 0.9172 - val_loss: 0.2100 - val_accuracy: 0.9362\n",
      "Epoch 31/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2717 - accuracy: 0.9174 - val_loss: 0.2167 - val_accuracy: 0.9356\n",
      "Epoch 32/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2715 - accuracy: 0.9167 - val_loss: 0.2158 - val_accuracy: 0.9342\n",
      "Epoch 33/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2706 - accuracy: 0.9175 - val_loss: 0.2197 - val_accuracy: 0.9342\n",
      "Epoch 34/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2703 - accuracy: 0.9176 - val_loss: 0.2133 - val_accuracy: 0.9368\n",
      "Epoch 35/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2708 - accuracy: 0.9167 - val_loss: 0.2112 - val_accuracy: 0.9380\n",
      "Epoch 36/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2695 - accuracy: 0.9174 - val_loss: 0.2089 - val_accuracy: 0.9394\n",
      "Epoch 37/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2687 - accuracy: 0.9180 - val_loss: 0.2163 - val_accuracy: 0.9358\n",
      "Epoch 38/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2682 - accuracy: 0.9182 - val_loss: 0.2117 - val_accuracy: 0.9366\n",
      "Epoch 39/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2679 - accuracy: 0.9186 - val_loss: 0.2124 - val_accuracy: 0.9360\n",
      "Epoch 40/40\n",
      "1719/1719 [==============================] - 5s 3ms/step - loss: 0.2681 - accuracy: 0.9185 - val_loss: 0.2107 - val_accuracy: 0.9398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fed1865c2e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned.fit(x_train, y_train, validation_data=(x_val, y_val), epochs=40, callbacks=[es])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
